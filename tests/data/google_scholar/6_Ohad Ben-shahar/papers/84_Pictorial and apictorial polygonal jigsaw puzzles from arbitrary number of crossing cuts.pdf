<!DOCTYPE html>
<html lang="en" class="no-js">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="applicable-device" content="pc,mobile">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        
        
        
            <meta name="robots" content="max-image-preview:large">
            <meta name="access" content="Yes">

        
        <meta name="360-site-verification" content="1268d79b5e96aecf3ff2a7dac04ad990" />

        <title>Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts | International Journal of Computer Vision
        </title>

        
            
            
    
    <meta name="twitter:site" content="@SpringerLink"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts"/>
    <meta name="twitter:description" content="International Journal of Computer Vision - Jigsaw puzzle solving, the problem of constructing a coherent whole from a set of non-overlapping unordered visual fragments, is fundamental to numerous..."/>
    <meta name="twitter:image" content="https://static-content.springer.com/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig1_HTML.png"/>
    <meta name="journal_id" content="11263"/>
    <meta name="dc.title" content="Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts"/>
    <meta name="dc.source" content="International Journal of Computer Vision 2024 132:9"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Springer"/>
    <meta name="dc.date" content="2024-03-22"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2024 The Author(s)"/>
    <meta name="dc.rights" content="2024 The Author(s)"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Jigsaw puzzle solving, the problem of constructing a coherent whole from a set of non-overlapping unordered visual fragments, is fundamental to numerous applications, and yet most of the literature of the last two decades has focused thus far on less realistic puzzles whose pieces are identical squares. Here we formalize a new type of jigsaw puzzle where the pieces are general convex polygons generated by cutting through a global polygonal shape/image with an arbitrary number of straight cuts, a generation model inspired by the celebrated Lazy caterer&#8217;s sequence. We analyze the theoretical properties of such puzzles, including the inherent challenges in solving them once pieces are contaminated with geometrical noise. To cope with such difficulties and obtain tractable solutions, we abstract the problem as a multi-body spring-mass dynamical system endowed with hierarchical loop constraints and a layered reconstruction process. We define evaluation metrics and present experimental results on both apictorial and pictorial puzzles to show that they are solvable completely automatically."/>
    <meta name="prism.issn" content="1573-1405"/>
    <meta name="prism.publicationName" content="International Journal of Computer Vision"/>
    <meta name="prism.publicationDate" content="2024-03-22"/>
    <meta name="prism.volume" content="132"/>
    <meta name="prism.number" content="9"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="3428"/>
    <meta name="prism.endingPage" content="3462"/>
    <meta name="prism.copyright" content="2024 The Author(s)"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s11263-024-02033-7"/>
    <meta name="prism.doi" content="doi:10.1007/s11263-024-02033-7"/>
    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s11263-024-02033-7.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s11263-024-02033-7"/>
    <meta name="citation_journal_title" content="International Journal of Computer Vision"/>
    <meta name="citation_journal_abbrev" content="Int J Comput Vis"/>
    <meta name="citation_publisher" content="Springer US"/>
    <meta name="citation_issn" content="1573-1405"/>
    <meta name="citation_title" content="Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts"/>
    <meta name="citation_volume" content="132"/>
    <meta name="citation_issue" content="9"/>
    <meta name="citation_publication_date" content="2024/09"/>
    <meta name="citation_online_date" content="2024/03/22"/>
    <meta name="citation_firstpage" content="3428"/>
    <meta name="citation_lastpage" content="3462"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_fulltext_world_readable" content=""/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1007/s11263-024-02033-7"/>
    <meta name="DOI" content="10.1007/s11263-024-02033-7"/>
    <meta name="size" content="977376"/>
    <meta name="citation_doi" content="10.1007/s11263-024-02033-7"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1007/s11263-024-02033-7&amp;api_key="/>
    <meta name="description" content="Jigsaw puzzle solving, the problem of constructing a coherent whole from a set of non-overlapping unordered visual fragments, is fundamental to numerous ap"/>
    <meta name="dc.creator" content="Harel, Peleg"/>
    <meta name="dc.creator" content="Shahar, Ofir Itzhak"/>
    <meta name="dc.creator" content="Ben-Shahar, Ohad"/>
    <meta name="dc.subject" content="Computer Imaging, Vision, Pattern Recognition and Graphics"/>
    <meta name="dc.subject" content="Artificial Intelligence"/>
    <meta name="dc.subject" content="Image Processing and Computer Vision"/>
    <meta name="dc.subject" content="Pattern Recognition"/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Computer Vision; citation_title=Sequential monte carlo for maximum weight subgraphs with application to solving image jigsaw puzzles; citation_author=N Adluru, X Yang, LJ Latecki; citation_volume=112; citation_issue=3; citation_publication_date=2015; citation_pages=319-341; citation_doi=10.1007/s11263-014-0766-9; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=American Journal of Applied Sciences; citation_title=Solving square jigsaw puzzles using dynamic programming and the Hungarian procedure; citation_author=N Alajlan; citation_volume=6; citation_issue=11; citation_publication_date=2009; citation_pages=1941; citation_doi=10.3844/ajassp.2009.1941.1947; citation_id=CR2"/>
    <meta name="citation_reference" content="Ali, F. A. B.&#160;H., &amp; Karim, F.&#160;B. (2014). Development of captcha system based on puzzle. In 2014 international conference on computer, communications, and control technology (I4CT) (pp.&#160;426&#8211;428). IEEE."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE PAMI; citation_title=PSQP: Puzzle solving by quadratic programming; citation_author=F Andalo, G Taubin, S Goldenstein; citation_volume=39; citation_issue=2; citation_publication_date=2016; citation_pages=385-396; citation_doi=10.1109/TPAMI.2016.2547394; citation_id=CR4"/>
    <meta name="citation_reference" content="Andal&#243;, F. A., Carneiro, G., Taubin, G., Goldenstein, S., &amp; Velho, L. (2016). Automatic reconstruction of ancient Portuguese tile panels. Graphics Appl: IEEE Comput."/>
    <meta name="citation_reference" content="Benaroya, H., &amp; Han, S. Probability models in engineering and science."/>
    <meta name="citation_reference" content="Brand&#227;o, S., &amp; Marques, M. (2016). Hot tiles: A heat diffusion based descriptor for automatic tile panel assembly. In European conference on computer vision (pp.&#160;768&#8211;782). Springer."/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Heritage in the Digital Era; citation_title=Tools for virtual reassembly of fresco fragments; citation_author=BJ Brown, L Laken, P Dutr&#233;, L Gool, S Rusinkiewicz, T Weyrich; citation_volume=1; citation_publication_date=2012; citation_pages=313-329; citation_doi=10.1260/2047-4970.1.2.313; citation_id=CR8"/>
    <meta name="citation_reference" content="Bunke, H., &amp; Kaufmann, G. (1993). Jigsaw puzzle solving using approximate string matching and best-first search. In International conference on computer analysis of images and patterns (pp.&#160;299&#8211;308). Springer."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Robotics and Automation; citation_title=Solving jigsaw puzzles by a robot; citation_author=B Burdea, HJ Wolfson; citation_volume=5; citation_issue=6; citation_publication_date=1989; citation_pages=752-764; citation_doi=10.1109/70.88097; citation_id=CR10"/>
    <meta name="citation_reference" content="Casta&#241;eda, A., Brown, B.&#160;J., Rusinkiewicz, S., Funkhouser, T., &amp; Weyrich, T. (2011). Global consistency in the automatic assembly of fragmented artefacts. In VAST."/>
    <meta name="citation_reference" content="Catto, E. Box2d. 
                  https://github.com/erincatto/Box2D
                  
                ."/>
    <meta name="citation_reference" content="Cho, T.&#160;S., Avidan, S., &amp; Freeman, W.&#160;T. (2010). A probabilistic image jigsaw puzzle solver. In 2010 IEEE computer society conference on computer vision and pattern recognition (pp.&#160;183&#8211;190). IEEE."/>
    <meta name="citation_reference" content="Chung, M.&#160;G., Fleck, M.&#160;M., &amp; Forsyth, D.&#160;A. (1998). Jigsaw puzzle solver using shape and color. In ICSP&#8217;98. 1998 Fourth international conference on signal processing (Cat. No. 98TH8344) (Vol. 2, pp.&#160;877&#8211;880). IEEE."/>
    <meta name="citation_reference" content="De&#160;Bock, J., De&#160;Smet, R., Philips, W., &amp; D&#8217;Haeyer, J. (2004). Constructing the topological solution of jigsaw puzzles. In 2004 International conference on image processing, 2004. ICIP&#8217;04. (Vol.&#160;3, pp.&#160;2127&#8211;2130). IEEE."/>
    <meta name="citation_reference" content="citation_journal_title=Graphs and Combinatorics; citation_title=Jigsaw puzzles, edge matching, and polyomino packing: Connections and complexity; citation_author=ED Demaine, ML Demaine; citation_volume=23; citation_issue=1; citation_publication_date=2007; citation_pages=195-208; citation_doi=10.1007/s00373-007-0713-4; citation_id=CR16"/>
    <meta name="citation_reference" content="Derech, N., Tal, A., &amp; Shimshoni, I. (2021). Solving archaeological puzzles. Pattern Recognition, 108065."/>
    <meta name="citation_reference" content="citation_journal_title=Ecology; citation_title=Measures of the amount of ecologic association between species; citation_author=LR Dice; citation_volume=26; citation_issue=3; citation_publication_date=1945; citation_pages=297-302; citation_doi=10.2307/1932409; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Assembly Automation; citation_title=An image processing approach for jigsaw puzzle assembly; citation_author=N Fei, F Zhuang, L Renqiang, C Qixin, Z Yanzheng; citation_volume=27; citation_issue=1; citation_publication_date=2007; citation_pages=25-30; citation_doi=10.1108/01445150710724676; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Electronic Computers; citation_title=Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition; citation_author=H Freeman, L Garder; citation_volume=2; citation_publication_date=1964; citation_pages=118-127; citation_doi=10.1109/PGEC.1964.263781; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=ACM Journal on Computing and Cultural Heritage; citation_title=Learning how to match fresco fragments; citation_author=T Funkhouser, H Shin, C Toler-Franklin, A Casta&#241;eda, BJ Brown, D Dobkin, S Rusinkiewicz, T Weyrich; citation_volume=4; citation_publication_date=2011; citation_pages=7:1-7:13; citation_id=CR21"/>
    <meta name="citation_reference" content="Gallagher, A.&#160;C. (2012). Jigsaw puzzles with pieces of unknown orientation. In 2012 IEEE conference on computer vision and pattern recognition (pp.&#160;382&#8211;389). IEEE."/>
    <meta name="citation_reference" content="Gao, H., Yao, D., Liu, H., Liu, X., &amp; Wang, L. (2010). A novel image based captcha using jigsaw puzzle. In 2010 13th IEEE international conference on computational science and engineering (pp.&#160;351&#8211;356). IEEE."/>
    <meta name="citation_reference" content="citation_journal_title=Proceedings of the National Academy of Sciences; citation_title=A test of the &#8220;jigsaw puzzle&#8221; model for protein folding by multiple methionine substitutions within the core of t4 lysozyme; citation_author=N Gassner, W Baase, B Matthews; citation_volume=93; citation_issue=22; citation_publication_date=1996; citation_pages=12155-12158; citation_doi=10.1073/pnas.93.22.12155; citation_id=CR24"/>
    <meta name="citation_reference" content="Gioe, D. (2017). &#8216;The more things change&#8217;: HUMINT in the cyber age. In The Palgrave handbook of security, risk and intelligence (pp.&#160;213&#8211;227). Springer."/>
    <meta name="citation_reference" content="Goldberg, D., Malon, C., &amp; Bern, M. (2002). A global approach to automatic solution of jigsaw puzzles. In Proceedings of the eighteenth annual symposium on Computational geometry (pp.&#160;82&#8211;87). ACM."/>
    <meta name="citation_reference" content="citation_journal_title=Annual Review of Anthropology; citation_title=Reaching the point of no return: The computational revolution in archaeology; citation_author=L Grosman; citation_volume=45; citation_publication_date=2016; citation_pages=129-145; citation_doi=10.1146/annurev-anthro-102215-095946; citation_id=CR27"/>
    <meta name="citation_reference" content="Gur, S., &amp; Ben-Shahar, O. (2017). From square pieces to brick walls: The next challenge in solving jigsaw puzzles. In Proceedings of the IEEE international conference on computer vision (pp.&#160;4029&#8211;4037)."/>
    <meta name="citation_reference" content="citation_journal_title=ACM Transaction Graph.; citation_title=Reassembling fractured objects by geometric matching; citation_author=Q Huang, S Fl&#246;ry, N Gelfand, M Hofer, H Pottmann; citation_volume=25; citation_publication_date=2006; citation_pages=569-578; citation_doi=10.1145/1141911.1141925; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Pattern Recognition Letters; citation_title=An optimal algorithm for extracting the regions of a plane graph; citation_author=X Jiang, H Bunke; citation_volume=14; citation_issue=7; citation_publication_date=1993; citation_pages=553-558; citation_doi=10.1016/0167-8655(93)90104-L; citation_id=CR30"/>
    <meta name="citation_reference" content="Kleber, F., &amp; Sablatnig, R (2009). Scientific puzzle solving: Current techniques and applications. In CAA."/>
    <meta name="citation_reference" content="Kleber, F., &amp; Sablatnig, R. (2009). A survey of techniques for document and archaeology artefact reconstruction. In ICDAR (pp.&#160;1061&#8211;1065)."/>
    <meta name="citation_reference" content="citation_journal_title=Bullettino Della Commissione Archeologica Comunale di Roma; citation_title=Computer-aided reconstruction and new matches in the forma urbis romae; citation_author=D Koller, M Levoy; citation_volume=2; citation_publication_date=2006; citation_pages=103-125; citation_id=CR33"/>
    <meta name="citation_reference" content="Kong, W., &amp; Kimia, B.&#160;B. (2001). On solving 2d and 3d puzzles using curve matching. In Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001 (Vol.&#160;2, pp.&#160;II&#8211;II). IEEE."/>
    <meta name="citation_reference" content="Kosiba, D.&#160;A., Devaux, P.&#160;M., Balasubramanian, S., Gandhi, T.&#160;L., &amp; Kasturi, K. (1994). An automatic jigsaw puzzle solver. In Proceedings of 12th international conference on pattern recognition, (Vol.&#160;1, pp.&#160;616&#8211;618). IEEE."/>
    <meta name="citation_reference" content="Le, C., &amp; Li, X. (2019). Jigsawnet: Shredded image reassembly using convolutional neural network and loop-based composition. IEEE Transactions on Image Processing ."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Access; citation_title=Pairwise matching for 3d fragment reassembly based on boundary curves and concave-convex patches; citation_author=Q Li, G Geng, M Zhou; citation_volume=8; citation_publication_date=2020; citation_pages=6153-6161; citation_doi=10.1109/ACCESS.2019.2961391; citation_id=CR37"/>
    <meta name="citation_reference" content="Lindstr&#246;m, M. (2019). The geological development of the arctic. In The Arctic (pp.&#160;3&#8211;25). Routledge."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Multimedia; citation_title=Automated assembly of shredded pieces from multiple photos; citation_author=H Liu, S Cao, S Yan; citation_volume=13; citation_issue=5; citation_publication_date=2011; citation_pages=1154-1162; citation_doi=10.1109/TMM.2011.2160845; citation_id=CR39"/>
    <meta name="citation_reference" content="Makridis, M., &amp; Papamarkos, N. (2006). A new technique for solving a jigsaw puzzle. In 2006 international conference on image processing (pp.&#160;2001&#8211;2004). IEEE."/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Mitochondrial dna as a genomic jigsaw puzzle; citation_author=W Marande, G Burger; citation_volume=318; citation_issue=5849; citation_publication_date=2007; citation_pages=415-415; citation_doi=10.1126/science.1148033; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=The Visual Computer; citation_title=Jigsaw puzzle solving techniques and applications: A survey; citation_author=S Markaki, C Panagiotakis; citation_volume=39; citation_issue=10; citation_publication_date=2023; citation_pages=4405-4421; citation_doi=10.1007/s00371-022-02598-9; citation_id=CR42"/>
    <meta name="citation_reference" content="Mavridis, P., Andreadis, A., &amp; Papaioannou, G. (2015). Fractured object reassembly via robust surface registration. In Eurographics."/>
    <meta name="citation_reference" content="Mellado, N., Reuter, P., &amp; Schlick, C. (2010). Semi-automatic geometry-driven reassembly of fractured archeological objects. In VAST."/>
    <meta name="citation_reference" content="Mondal, D., Wang, Y., &amp; Durocher, S. (2013). Robust solvers for square jigsaw puzzles. In 2013 international conference on computer and robot vision(pp.&#160;249&#8211;256). IEEE."/>
    <meta name="citation_reference" content="citation_journal_title=The College Mathematics Journal; citation_title=Using euler&#8217;s formula to solve plane separation problems; citation_author=TL Moore; citation_volume=22; citation_issue=2; citation_publication_date=1991; citation_pages=125-130; citation_doi=10.1080/07468342.1991.11973368; citation_id=CR46"/>
    <meta name="citation_reference" content="Murakami, T., Toyama, F., Shoji, K., &amp; Miyamichi, J. (2008). Assembly of puzzles by connecting between blocks. In 2008 19th international conference on pattern recognition (pp.&#160;1&#8211;4). IEEE."/>
    <meta name="citation_reference" content="citation_journal_title=Pattern Recognition Letters; citation_title=Solving jigsaw puzzles using image features; citation_author=TR Nielsen, P Drewsen, K Hansen; citation_volume=29; citation_issue=14; citation_publication_date=2008; citation_pages=1924-1933; citation_doi=10.1016/j.patrec.2008.05.027; citation_id=CR48"/>
    <meta name="citation_reference" content="Oxholm, G., &amp; Nishino, K. (2011). Reassembling thin artifacts of unknown geometry. In VAST."/>
    <meta name="citation_reference" content="Paikin, G., &amp; Tal, A. (2015). Solving multiple square jigsaw puzzles with missing pieces. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.&#160;4832&#8211;4839)."/>
    <meta name="citation_reference" content="citation_journal_title=2013 Digital Heritage International Congress (DigitalHeritage); citation_title=A computer-assisted constraint-based system for assembling fragmented objects; citation_author=G Palmas, N Pietroni, P Cignoni, R Scopigno; citation_volume=1; citation_publication_date=2013; citation_pages=529-536; citation_doi=10.1109/DigitalHeritage.2013.6743793; citation_id=CR51"/>
    <meta name="citation_reference" content="citation_journal_title=Image and Vision Computing; citation_title=On the automatic assemblage of arbitrary broken solid artefacts; citation_author=G Papaioannou, E-A Karabassi; citation_volume=21; citation_publication_date=2003; citation_pages=401-412; citation_doi=10.1016/S0262-8856(03)00008-8; citation_id=CR52"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Computer Graphics and Applications; citation_title=Virtual archaeologist: Assembling the past; citation_author=G Papaioannou, E-A Karabassi, T Theoharis; citation_volume=21; citation_publication_date=2001; citation_pages=53-59; citation_doi=10.1109/38.909015; citation_id=CR53"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Signal Processing; citation_title=Contour-shape based reconstruction of fragmented, 1600 bc wall paintings; citation_author=C Papaodysseus, T Panagopoulos, M Exarhos, C Triantafillou, D Fragoulis, C Doumas; citation_volume=50; citation_publication_date=2002; citation_pages=1277-1288; citation_doi=10.1109/TSP.2002.1003053; citation_id=CR54"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Image Processing; citation_title=Deepzzle: Solving visual jigsaw puzzles with deep learning and shortest path optimization; citation_author=M-M Paumard, D Picard, H Tabia; citation_volume=29; citation_publication_date=2020; citation_pages=3569-3581; citation_doi=10.1109/TIP.2019.2963378; citation_id=CR55"/>
    <meta name="citation_reference" content="Pintus, R., Pal, K., Yang, Y., Weyrich, T., Gobbetti, E., &amp; Rushmeier, H.&#160;E. (2014) Geometric analysis in cultural heritage. In GCH, pp.&#160;117&#8211;133."/>
    <meta name="citation_reference" content="Pomeranz, D., Shemesh, M., &amp; Ben-Shahar, O. (2011). A fully automated greedy square jigsaw puzzle solver. In CVPR 2011, (pp.&#160;9&#8211;16). IEEE."/>
    <meta name="citation_reference" content="citation_journal_title=Computer Graphics and Image Processing; citation_title=Jigsaw puzzle matching using a boundary-centered polar encoding; citation_author=GM Radack, NI Badler; citation_volume=19; citation_issue=1; citation_publication_date=1982; citation_pages=1-17; citation_doi=10.1016/0146-664X(82)90111-3; citation_id=CR58"/>
    <meta name="citation_reference" content="Rika, D., Sholomon, D., David, E.&#160;O., &amp; Netanyahu, N.&#160;S. (2019). A novel hybrid scheme using genetic algorithms and deep learning for the reconstruction of portuguese tile panels. In Proceedings of the genetic and evolutionary computation conference, (pp.&#160;1319&#8211;1327). ACM."/>
    <meta name="citation_reference" content="Rombach, R., Blattmann, A., Lorenz, D., Esser, P., &amp; Ommer, B. (June 2022). High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR) (pp.&#160;10684&#8211;10695)."/>
    <meta name="citation_reference" content="citation_journal_title=Top; citation_title=Optimization for automated assembly of puzzles; citation_author=M&#350; Sa&#287;&#305;ro&#287;lu, A Er&#231;il; citation_volume=18; citation_issue=2; citation_publication_date=2010; citation_pages=321-338; citation_doi=10.1007/s11750-010-0156-6; citation_id=CR61"/>
    <meta name="citation_reference" content="citation_journal_title=Journal on Computing and Cultural Heritage (JOCCH); citation_title=Analyzing and simulating fracture patterns of theran wall paintings; citation_author=H Shin, C Doumas, T Funkhouser, S Rusinkiewicz, K Steiglitz, A Vlachopoulos, T Weyrich; citation_volume=5; citation_issue=3; citation_publication_date=2012; citation_pages=10; citation_id=CR62"/>
    <meta name="citation_reference" content="Sholomon, D., David, O., &amp; Netanyahu, N.&#160;S. (2013). A genetic algorithm-based solver for very large jigsaw puzzles. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.&#160;1767&#8211;1774)."/>
    <meta name="citation_reference" content="Sholomon, D., David, O.&#160;E., &amp; Netanyahu, N.&#160;S. (2014). A generalized genetic algorithm-based solver for very large jigsaw puzzles of complex types. In Twenty-eighth AAAI conference on artificial intelligence."/>
    <meta name="citation_reference" content="citation_journal_title=Journal on Computing and Cultural Heritage (JOCCH); citation_title=Wall painting reconstruction using a genetic algorithm; citation_author=E Sizikova, TA Funkhouser; citation_volume=11; citation_publication_date=2016; citation_pages=1-17; citation_id=CR65"/>
    <meta name="citation_reference" content="Son, K., Hays, J., &amp; Cooper, D.&#160;B. (2014). Solving square jigsaw puzzles with loop constraints. In European conference on computer vision, (pp.&#160;32&#8211;46). Springer."/>
    <meta name="citation_reference" content="Son, K., Hays, J., &amp; Cooper, D.&#160;B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence."/>
    <meta name="citation_reference" content="Son, K., Hays, J., Cooper, &amp; D.&#160;B., et&#160;al. (2016). Solving small-piece jigsaw puzzles by growing consensus. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.&#160;1193&#8211;1201)."/>
    <meta name="citation_reference" content="Song, X., Yang, X., Ren, J., Bai, R., &amp; Jiang, X. (2023). Solving jigsaw puzzle of large eroded gaps using puzzlet discriminant network. In ICASSP 2023 - 2023 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp.&#160;1&#8211;5)."/>
    <meta name="citation_reference" content="citation_journal_title=Computing; citation_title=Least-squares rigid motion using svd; citation_author=O Sorkine-Hornung, M Rabinovich; citation_volume=1; citation_publication_date=2017; citation_pages=1; citation_id=CR70"/>
    <meta name="citation_reference" content="Telea, A. (01 2004). An image inpainting technique based on the fast marching method. Journal of Graphics Tools 9."/>
    <meta name="citation_reference" content="Toler-Franklin, C., Brown, B.&#160;J., Weyrich, T., Funkhouser, T., &amp; Rusinkiewicz, S. (2010). Multi-feature matching of fresco fragments. In SIGGRAPH 2010."/>
    <meta name="citation_reference" content="Toyama, F., Fujiki, Y., Shoji, K., &amp; Miyamichi, J. (2002). Assembly of puzzles using a genetic algorithm. In Object recognition supported by user interaction for service robots (Vol.&#160;4, IEEE, pp.&#160;389&#8211;392)."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Image Processing; citation_title=Automatic color based reassembly of fragmented images and paintings; citation_author=E Tsamoura, I Pitas; citation_volume=19; citation_issue=3; citation_publication_date=2009; citation_pages=680-690; citation_doi=10.1109/TIP.2009.2035840; citation_id=CR74"/>
    <meta name="citation_reference" content="citation_journal_title=Geology 42; citation_title=The puzzle assembled: Ediacaran guide fossil Cloudina reveals an old proto-Gondwana seaway; citation_author=L Warren, F Quaglio, C Riccomini, M Sim&#245;es, D Poir&#233;, N Strikis, L Anelli, P Strikis; citation_volume=5; citation_publication_date=2014; citation_pages=391-394; citation_id=CR75"/>
    <meta name="citation_reference" content="Webster, R. W., LaFollette, P. S., &amp; Stafford, R. L. (1991). Isthmus critical points for solving jigsaw puzzles in computer vision. IEEE Transactions on Systems, Man, and Cybernetics, 21(5), 1271&#8211;1278."/>
    <meta name="citation_reference" content="Wetzel, J. E. (1978). On the division of the plane by lines. The American Mathematical Monthly, 85(8), 647&#8211;656."/>
    <meta name="citation_reference" content="Willis, A., &amp; Cooper, D. (2008). Computational reconstruction of ancient artifacts. IEEE Signal Processing Magazine. 25."/>
    <meta name="citation_reference" content="citation_journal_title=Annals of Operations Research; citation_title=Solving jigsaw puzzles by computer; citation_author=H Wolfson, E Schonberg, A Kalvin, Y Lamdan; citation_volume=12; citation_issue=1; citation_publication_date=1988; citation_pages=51-64; citation_doi=10.1007/BF02186360; citation_id=CR79"/>
    <meta name="citation_reference" content="Yaglom, A.&#160;M., &amp; Yaglom, I.&#160;M. (1987). Challenging Mathematical Problems with Elementary Solutions, vol.&#160;1. Dover Publications."/>
    <meta name="citation_reference" content="Yang, X., Adluru, N., &amp; Latecki, L.&#160;J. (2011). Particle filter with state permutations for solving image jigsaw puzzles. In CVPR 2011, (pp.&#160;2873&#8211;2880). IEEE."/>
    <meta name="citation_reference" content="citation_journal_title=Pattern Recognition Letters; citation_title=A shape and image merging technique to solve jigsaw puzzles; citation_author=F-H Yao, G-F Shao; citation_volume=24; citation_issue=12; citation_publication_date=2003; citation_pages=1819-1835; citation_doi=10.1016/S0167-8655(03)00006-0; citation_id=CR82"/>
    <meta name="citation_reference" content="Yu, R., Russell, C., &amp; Agapito, L. (2015). Solving jigsaw puzzles with linear programming. arXiv preprint 
                  arXiv:1511.04472
                  
                ."/>
    <meta name="citation_reference" content="citation_journal_title=Computer Science Review; citation_title=Comprehensive survey of the solving puzzle problems; citation_author=S Ylmaz, VV Nabiyev; citation_volume=50; citation_publication_date=2023; citation_doi=10.1016/j.cosrev.2023.100586; citation_id=CR84"/>
    <meta name="citation_reference" content="citation_journal_title=Graphical Models; citation_title=A graph-based optimization algorithm for fragmented image reassembly; citation_author=K Zhang, X Li; citation_volume=76; citation_issue=5; citation_publication_date=2014; citation_pages=484-495; citation_doi=10.1016/j.gmod.2014.03.001; citation_id=CR85"/>
    <meta name="citation_reference" content="citation_journal_title=Applied Intelligence; citation_title=A jigsaw puzzle inspired algorithm for solving large-scale no-wait flow shop scheduling problems; citation_author=F Zhao, X He, Y Zhang, W Lei, W Ma, C Zhang, H Song; citation_volume=50; citation_publication_date=2020; citation_pages=87-100; citation_doi=10.1007/s10489-019-01497-2; citation_id=CR86"/>
    <meta name="citation_reference" content="Zhao, Y.-X., Su, M.-C., Chou, Z.-L., &amp; Lee, J. (2007). A puzzle solver and its application in speech descrambling. In WSEAS international conference on computer engineering and applications (pp.&#160;171&#8211;176)."/>
    <meta name="citation_author" content="Harel, Peleg"/>
    <meta name="citation_author_institution" content="Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel"/>
    <meta name="citation_author" content="Shahar, Ofir Itzhak"/>
    <meta name="citation_author_institution" content="Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel"/>
    <meta name="citation_author" content="Ben-Shahar, Ohad"/>
    <meta name="citation_author_email" content="ben-shahar@cs.bgu.ac.il"/>
    <meta name="citation_author_institution" content="Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel"/>
    <meta name="format-detection" content="telephone=no"/>
    <meta name="citation_cover_date" content="2024/09/01"/>
    

            
    
    <meta property="og:url" content="https://link.springer.com/article/10.1007/s11263-024-02033-7"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="SpringerLink"/>
    <meta property="og:title" content="Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts - International Journal of Computer Vision"/>
    <meta property="og:description" content="Jigsaw puzzle solving, the problem of constructing a coherent whole from a set of non-overlapping unordered visual fragments, is fundamental to numerous applications, and yet most of the literature of the last two decades has focused thus far on less realistic puzzles whose pieces are identical squares. Here we formalize a new type of jigsaw puzzle where the pieces are general convex polygons generated by cutting through a global polygonal shape/image with an arbitrary number of straight cuts, a generation model inspired by the celebrated Lazy caterer&#8217;s sequence. We analyze the theoretical properties of such puzzles, including the inherent challenges in solving them once pieces are contaminated with geometrical noise. To cope with such difficulties and obtain tractable solutions, we abstract the problem as a multi-body spring-mass dynamical system endowed with hierarchical loop constraints and a layered reconstruction process. We define evaluation metrics and present experimental results on both apictorial and pictorial puzzles to show that they are solvable completely automatically."/>
    <meta property="og:image" content="https://static-content.springer.com/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig1_HTML.png"/>
    

            
        

        <meta name="format-detection" content="telephone=no">

        
    
        
    
    
    

    


        <link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/img/favicons/darwin/apple-touch-icon-92e819bf8a.png>
<link rel="icon" type="image/png" sizes="192x192" href=/oscar-static/img/favicons/darwin/android-chrome-192x192-6f081ca7e5.png>
<link rel="icon" type="image/png" sizes="32x32" href=/oscar-static/img/favicons/darwin/favicon-32x32-1435da3e82.png>
<link rel="icon" type="image/png" sizes="16x16" href=/oscar-static/img/favicons/darwin/favicon-16x16-ed57f42bd2.png>
<link rel="shortcut icon" data-test="shortcut-icon" href=/oscar-static/img/favicons/darwin/favicon-c6d59aafac.ico>

<meta name="theme-color" content="#e6e6e6">


        <!-- Please see discussion: https://github.com/springernature/frontend-open-space/issues/316-->
<!--TODO: Implement alternative to CTM in here if the discussion concludes we do not continue with CTM as a practice-->


<link rel="stylesheet" media="print" href=/oscar-static/app-springerlink/css/print-b8af42253b.css>



    
        
            
    <style> html{text-size-adjust:100%;line-height:1.15}body{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;line-height:1.8;margin:0}details,main{display:block}h1{font-size:2em;margin:.67em 0}a{background-color:transparent;color:#025e8d}sub{bottom:-.25em;font-size:75%;line-height:0;position:relative;vertical-align:baseline}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input{font-family:inherit;font-size:100%;line-height:1.15;margin:0;overflow:visible}button{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}summary{display:list-item}[hidden]{display:none}button{cursor:pointer}svg{height:1rem;width:1rem} </style>
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  body{background:#fff;color:#222;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;line-height:1.8;min-height:100%}a{color:#025e8d;text-decoration:underline;text-decoration-skip-ink:auto}button{cursor:pointer}img{border:0;height:auto;max-width:100%;vertical-align:middle}html{box-sizing:border-box;font-size:100%;height:100%;overflow-y:scroll}h1{font-size:2.25rem}h2{font-size:1.75rem}h1,h2,h4{font-weight:700;line-height:1.2}h4{font-size:1.25rem}body{font-size:1.125rem}*{box-sizing:inherit}p{margin-bottom:2rem;margin-top:0}p:last-of-type{margin-bottom:0}.c-ad{text-align:center}@media only screen and (min-width:480px){.c-ad{padding:8px}}.c-ad--728x90{display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:876px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-ad__label,.c-status-message{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-status-message{align-items:center;box-sizing:border-box;display:flex;position:relative;width:100%}.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #ccc;line-height:1.4;padding:16px}.c-status-message__heading{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.eds-c-header{background-color:#fff;border-bottom:2px solid #01324b;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;line-height:1.5;padding:8px 0 0}.eds-c-header__container{align-items:center;display:flex;flex-wrap:nowrap;gap:8px 16px;justify-content:space-between;margin:0 auto 8px;max-width:1280px;padding:0 8px;position:relative}.eds-c-header__nav{border-top:2px solid #c5e0f4;padding-top:4px;position:relative}.eds-c-header__nav-container{align-items:center;display:flex;flex-wrap:wrap;margin:0 auto 4px;max-width:1280px;padding:0 8px;position:relative}.eds-c-header__nav-container>:not(:last-child){margin-right:32px}.eds-c-header__link-container{align-items:center;display:flex;flex:1 0 auto;gap:8px 16px;justify-content:space-between}.eds-c-header__list{list-style:none;margin:0;padding:0}.eds-c-header__list-item{font-weight:700;margin:0 auto;max-width:1280px;padding:8px}.eds-c-header__list-item:not(:last-child){border-bottom:2px solid #c5e0f4}.eds-c-header__item{color:inherit}@media only screen and (min-width:768px){.eds-c-header__item--menu{display:none;visibility:hidden}.eds-c-header__item--menu:first-child+*{margin-block-start:0}}.eds-c-header__item--inline-links{display:none;visibility:hidden}@media only screen and (min-width:768px){.eds-c-header__item--inline-links{display:flex;gap:16px 16px;visibility:visible}}.eds-c-header__item--divider:before{border-left:2px solid #c5e0f4;content:"";height:calc(100% - 16px);margin-left:-15px;position:absolute;top:8px}.eds-c-header__brand{padding:16px 8px}.eds-c-header__brand a{display:block;line-height:1;text-decoration:none}.eds-c-header__brand img{height:1.5rem;width:auto}.eds-c-header__link{color:inherit;display:inline-block;font-weight:700;padding:16px 8px;position:relative;text-decoration-color:transparent;white-space:nowrap;word-break:normal}.eds-c-header__icon{fill:currentcolor;display:inline-block;font-size:1.5rem;height:1em;transform:translate(0);vertical-align:bottom;width:1em}.eds-c-header__icon+*{margin-left:8px}.eds-c-header__expander{background-color:#f0f7fc}.eds-c-header__search{display:block;padding:24px 0}@media only screen and (min-width:768px){.eds-c-header__search{max-width:70%}}.eds-c-header__search-container{position:relative}.eds-c-header__search-label{color:inherit;display:inline-block;font-weight:700;margin-bottom:8px}.eds-c-header__search-input{background-color:#fff;border:1px solid #000;padding:8px 48px 8px 8px;width:100%}.eds-c-header__search-button{background-color:transparent;border:0;color:inherit;height:100%;padding:0 8px;position:absolute;right:0}.has-tethered.eds-c-header__expander{border-bottom:2px solid #01324b;left:0;margin-top:-2px;top:100%;width:100%;z-index:10}@media only screen and (min-width:768px){.has-tethered.eds-c-header__expander--menu{display:none;visibility:hidden}}.has-tethered .eds-c-header__heading{display:none;visibility:hidden}.has-tethered .eds-c-header__heading:first-child+*{margin-block-start:0}.has-tethered .eds-c-header__search{margin:auto}.eds-c-header__heading{margin:0 auto;max-width:1280px;padding:16px 16px 0}.eds-c-pagination{align-items:center;display:flex;flex-wrap:wrap;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;gap:16px 0;justify-content:center;line-height:1.4;list-style:none;margin:0;padding:32px 0}@media only screen and (min-width:480px){.eds-c-pagination{padding:32px 16px}}.eds-c-pagination__item{margin-right:8px}.eds-c-pagination__item--prev{margin-right:16px}.eds-c-pagination__item--next .eds-c-pagination__link,.eds-c-pagination__item--prev .eds-c-pagination__link{padding:16px 8px}.eds-c-pagination__item--next{margin-left:8px}.eds-c-pagination__item:last-child{margin-right:0}.eds-c-pagination__link{align-items:center;color:#222;cursor:pointer;display:inline-block;font-size:1rem;margin:0;padding:16px 24px;position:relative;text-align:center;transition:all .2s ease 0s}.eds-c-pagination__link:visited{color:#222}.eds-c-pagination__link--disabled{border-color:#555;color:#555;cursor:default}.eds-c-pagination__link--active{background-color:#01324b;background-image:none;border-radius:8px;color:#fff}.eds-c-pagination__link--active:focus,.eds-c-pagination__link--active:hover,.eds-c-pagination__link--active:visited{color:#fff}.eds-c-pagination__link-container{align-items:center;display:flex}.eds-c-pagination__icon{fill:#222;height:1.5rem;width:1.5rem}.eds-c-pagination__icon--disabled{fill:#555}.eds-c-pagination__visually-hidden{clip:rect(0,0,0,0);border:0;clip-path:inset(50%);height:1px;overflow:hidden;padding:0;position:absolute!important;white-space:nowrap;width:1px}.c-breadcrumbs{color:#333;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs>li{display:inline}svg.c-breadcrumbs__chevron{fill:#333;height:10px;margin:0 .25rem;width:10px}.c-breadcrumbs--contrast,.c-breadcrumbs--contrast .c-breadcrumbs__link{color:#fff}.c-breadcrumbs--contrast svg.c-breadcrumbs__chevron{fill:#fff}@media only screen and (max-width:479px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-skip-link{background:#01324b;bottom:auto;color:#fff;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);width:100%;z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:active,.c-skip-link:hover,.c-skip-link:link,.c-skip-link:visited{color:#fff}.c-skip-link:focus{transform:translateY(0)}.l-with-sidebar{display:flex;flex-wrap:wrap}.l-with-sidebar>*{margin:0}.l-with-sidebar__sidebar{flex-basis:var(--with-sidebar--basis,400px);flex-grow:1}.l-with-sidebar>:not(.l-with-sidebar__sidebar){flex-basis:0px;flex-grow:999;min-width:var(--with-sidebar--min,53%)}.l-with-sidebar>:first-child{padding-right:4rem}@supports (gap:1em){.l-with-sidebar>:first-child{padding-right:0}.l-with-sidebar{gap:var(--with-sidebar--gap,4rem)}}.c-header__link{color:inherit;display:inline-block;font-weight:700;padding:16px 8px;position:relative;text-decoration-color:transparent;white-space:nowrap;word-break:normal}.app-masthead__colour-4{--background-color:#ff9500;--gradient-light:rgba(0,0,0,.5);--gradient-dark:rgba(0,0,0,.8)}.app-masthead{background:var(--background-color,#0070a8);position:relative}.app-masthead:after{background:radial-gradient(circle at top right,var(--gradient-light,rgba(0,0,0,.4)),var(--gradient-dark,rgba(0,0,0,.7)));bottom:0;content:"";left:0;position:absolute;right:0;top:0}@media only screen and (max-width:479px){.app-masthead:after{background:linear-gradient(225deg,var(--gradient-light,rgba(0,0,0,.4)),var(--gradient-dark,rgba(0,0,0,.7)))}}.app-masthead__container{color:var(--masthead-color,#fff);margin:0 auto;max-width:1280px;padding:0 16px;position:relative;z-index:1}.u-button{align-items:center;background-color:#01324b;background-image:none;border:4px solid transparent;border-radius:32px;cursor:pointer;display:inline-flex;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;font-weight:700;justify-content:center;line-height:1.3;margin:0;padding:16px 32px;position:relative;transition:all .2s ease 0s;width:auto}.u-button svg,.u-button--contrast svg,.u-button--primary svg,.u-button--secondary svg,.u-button--tertiary svg{fill:currentcolor}.u-button,.u-button:visited{color:#fff}.u-button,.u-button:hover{box-shadow:0 0 0 1px #01324b;text-decoration:none}.u-button:hover{border:4px solid #fff}.u-button:focus{border:4px solid #fc0;box-shadow:none;outline:0;text-decoration:none}.u-button:focus,.u-button:hover{background-color:#fff;background-image:none;color:#01324b}.app-masthead--pastel .c-pdf-download .u-button--primary:focus svg path,.app-masthead--pastel .c-pdf-download .u-button--primary:hover svg path,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary:focus svg path,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary:hover svg path,.u-button--primary:focus svg path,.u-button--primary:hover svg path,.u-button:focus svg path,.u-button:hover svg path{fill:#01324b}.u-button--primary{background-color:#01324b;background-image:none;border:4px solid transparent;box-shadow:0 0 0 1px #01324b;color:#fff;font-weight:700}.u-button--primary:visited{color:#fff}.u-button--primary:hover{border:4px solid #fff;box-shadow:0 0 0 1px #01324b;text-decoration:none}.u-button--primary:focus{border:4px solid #fc0;box-shadow:none;outline:0;text-decoration:none}.u-button--primary:focus,.u-button--primary:hover{background-color:#fff;background-image:none;color:#01324b}.u-button--secondary{background-color:#fff;border:4px solid #fff;color:#01324b;font-weight:700}.u-button--secondary:visited{color:#01324b}.u-button--secondary:hover{border:4px solid #01324b;box-shadow:none}.u-button--secondary:focus,.u-button--secondary:hover{background-color:#01324b;color:#fff}.app-masthead--pastel .c-pdf-download .u-button--secondary:focus svg path,.app-masthead--pastel .c-pdf-download .u-button--secondary:hover svg path,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--secondary:focus svg path,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--secondary:hover svg path,.u-button--secondary:focus svg path,.u-button--secondary:hover svg path,.u-button--tertiary:focus svg path,.u-button--tertiary:hover svg path{fill:#fff}.u-button--tertiary{background-color:#ebf1f5;border:4px solid transparent;box-shadow:none;color:#666;font-weight:700}.u-button--tertiary:visited{color:#666}.u-button--tertiary:hover{border:4px solid #01324b;box-shadow:none}.u-button--tertiary:focus,.u-button--tertiary:hover{background-color:#01324b;color:#fff}.u-button--contrast{background-color:transparent;background-image:none;color:#fff;font-weight:400}.u-button--contrast:visited{color:#fff}.u-button--contrast,.u-button--contrast:focus,.u-button--contrast:hover{border:4px solid #fff}.u-button--contrast:focus,.u-button--contrast:hover{background-color:#fff;background-image:none;color:#000}.u-button--contrast:focus svg path,.u-button--contrast:hover svg path{fill:#000}.u-button--disabled,.u-button:disabled{background-color:transparent;background-image:none;border:4px solid #ccc;color:#000;cursor:default;font-weight:400;opacity:.7}.u-button--disabled svg,.u-button:disabled svg{fill:currentcolor}.u-button--disabled:visited,.u-button:disabled:visited{color:#000}.u-button--disabled:focus,.u-button--disabled:hover,.u-button:disabled:focus,.u-button:disabled:hover{border:4px solid #ccc;text-decoration:none}.u-button--disabled:focus,.u-button--disabled:hover,.u-button:disabled:focus,.u-button:disabled:hover{background-color:transparent;background-image:none;color:#000}.u-button--disabled:focus svg path,.u-button--disabled:hover svg path,.u-button:disabled:focus svg path,.u-button:disabled:hover svg path{fill:#000}.u-button--small,.u-button--xsmall{font-size:.875rem;padding:2px 8px}.u-button--small{padding:8px 16px}.u-button--large{font-size:1.125rem;padding:10px 35px}.u-button--full-width{display:flex;width:100%}.u-button--icon-left svg{margin-right:8px}.u-button--icon-right svg{margin-left:8px}.u-clear-both{clear:both}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-visually-hidden{clip:rect(0,0,0,0);border:0;clip-path:inset(50%);height:1px;overflow:hidden;padding:0;position:absolute!important;white-space:nowrap;width:1px}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-list-reset{list-style:none;margin:0;padding:0}.u-ma-16{margin:16px}.u-mt-0{margin-top:0}.u-mt-24{margin-top:24px}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-32{margin-bottom:32px}.u-button-reset{background-color:transparent;border:0;padding:0}.u-sans-serif{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.u-serif{font-family:Merriweather,serif}h1,h2,h4{-webkit-font-smoothing:antialiased}p{overflow-wrap:break-word;word-break:break-word}.u-h4{font-size:1.25rem;font-weight:700;line-height:1.2}.u-mbs-0{margin-block-start:0!important}.c-article-header{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}@media only screen and (min-width:876px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:767px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#025e8d;border-color:transparent;color:#fff}.c-article-body .c-article-access-provider{padding:8px 16px}.c-article-body .c-article-access-provider,.c-notes{border:1px solid #d5d5d5;border-image:initial;border-left:none;border-right:none;margin:24px 0}.c-article-body .c-article-access-provider__text{color:#555}.c-article-body .c-article-access-provider__text,.c-notes__text{font-size:1rem;margin-bottom:0;padding-bottom:2px;padding-top:2px;text-align:center}.c-article-body .c-article-author-affiliation__address{color:inherit;font-weight:700;margin:0}.c-article-body .c-article-author-affiliation__authors-list{list-style:none;margin:0;padding:0}.c-article-body .c-article-author-affiliation__authors-item{display:inline;margin-left:0}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #fff;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;margin-bottom:24px}.c-article-share-box__description{font-size:1rem;margin-bottom:8px}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__additional-info{color:#626262;font-size:.813rem}.c-article-share-box__button{background:#fff;box-sizing:content-box;text-align:center}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#025e8d;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{font-size:1rem}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;font-size:1.25rem;font-weight:700;line-height:1.2;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-article-section__figure-caption{display:block;margin-bottom:8px;word-break:break-word}.c-article-section__figure .video,p.app-article-masthead__access--above-download{margin:0 0 16px}.c-article-section__figure-description{font-size:1rem}.c-article-section__figure-description>*{margin-bottom:0}.c-cod{display:block;font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#025e8d;border:1px solid #025e8d;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#025e8d}.save-data .c-article-author-institutional-author__sub-division,.save-data .c-article-equation__number,.save-data .c-article-figure-description,.save-data .c-article-fullwidth-content,.save-data .c-article-main-column,.save-data .c-article-satellite-article-link,.save-data .c-article-satellite-subtitle,.save-data .c-article-table-container,.save-data .c-blockquote__body,.save-data .c-code-block__heading,.save-data .c-reading-companion__figure-title,.save-data .c-reading-companion__reference-citation,.save-data .c-site-messages--nature-briefing-email-variant .serif,.save-data .c-site-messages--nature-briefing-email-variant.serif,.save-data .serif,.save-data .u-serif,.save-data h1,.save-data h2,.save-data h3{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px}.c-pdf-download__link:hover{text-decoration:none}@media only screen and (min-width:768px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.c-article-body .c-article-recommendations-list,.c-book-body .c-article-recommendations-list{display:flex;flex-direction:row;gap:16px 16px;margin:0;max-width:100%;padding:16px 0 0}.c-article-body .c-article-recommendations-list__item,.c-book-body .c-article-recommendations-list__item{flex:1 1 0%}@media only screen and (max-width:767px){.c-article-body .c-article-recommendations-list,.c-book-body .c-article-recommendations-list{flex-direction:column}}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:767px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-body .c-article-history{margin-top:24px}.app-article-metrics-bar p{margin:0}.app-article-masthead{display:flex;flex-direction:column;gap:16px 16px;padding:16px 0 24px}.app-article-masthead__info{display:flex;flex-direction:column;flex-grow:1}.app-article-masthead__brand{border-top:1px solid hsla(0,0%,100%,.8);display:flex;flex-direction:column;flex-shrink:0;gap:8px 8px;min-height:96px;padding:16px 0 0}.app-article-masthead__brand img{border:1px solid #fff;border-radius:8px;box-shadow:0 4px 15px 0 hsla(0,0%,50%,.25);height:auto;left:0;position:absolute;width:72px}.app-article-masthead__journal-link{display:block;font-size:1.125rem;font-weight:700;margin:0 0 8px;max-width:400px;padding:0 0 0 88px;position:relative}.app-article-masthead__journal-title{-webkit-box-orient:vertical;-webkit-line-clamp:3;display:-webkit-box;overflow:hidden}.app-article-masthead__submission-link{align-items:center;display:flex;font-size:1rem;gap:4px 4px;margin:0 0 0 88px}.app-article-masthead__access{align-items:center;display:flex;flex-wrap:wrap;font-size:.875rem;font-weight:300;gap:4px 4px;margin:0}.app-article-masthead__buttons{display:flex;flex-flow:column wrap;gap:16px 16px}.app-article-masthead__access svg,.app-masthead--pastel .c-pdf-download .u-button--primary svg,.app-masthead--pastel .c-pdf-download .u-button--secondary svg,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary svg,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--secondary svg{fill:currentcolor}.app-article-masthead a{color:#fff}.app-masthead--pastel .c-pdf-download .u-button--primary,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary{background-color:#025e8d;background-image:none;border:2px solid transparent;box-shadow:none;color:#fff;font-weight:700}.app-masthead--pastel .c-pdf-download .u-button--primary:visited,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary:visited{color:#fff}.app-masthead--pastel .c-pdf-download .u-button--primary:hover,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary:hover{text-decoration:none}.app-masthead--pastel .c-pdf-download .u-button--primary:focus,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary:focus{border:4px solid #fc0;box-shadow:none;outline:0;text-decoration:none}.app-masthead--pastel .c-pdf-download .u-button--primary:focus,.app-masthead--pastel .c-pdf-download .u-button--primary:hover,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary:focus,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary:hover{background-color:#fff;background-image:none;color:#01324b}.app-masthead--pastel .c-pdf-download .u-button--primary:hover,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--primary:hover{background:0 0;border:2px solid #025e8d;box-shadow:none;color:#025e8d}.app-masthead--pastel .c-pdf-download .u-button--secondary,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--secondary{background:0 0;border:2px solid #025e8d;color:#025e8d;font-weight:700}.app-masthead--pastel .c-pdf-download .u-button--secondary:visited,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--secondary:visited{color:#01324b}.app-masthead--pastel .c-pdf-download .u-button--secondary:hover,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--secondary:hover{background-color:#01324b;background-color:#025e8d;border:2px solid transparent;box-shadow:none;color:#fff}.app-masthead--pastel .c-pdf-download .u-button--secondary:focus,.c-context-bar--sticky .c-context-bar__container .c-pdf-download .u-button--secondary:focus{background-color:#fff;background-image:none;border:4px solid #fc0;color:#01324b}@media only screen and (min-width:768px){.app-article-masthead{flex-direction:row;gap:64px 64px;padding:24px 0}.app-article-masthead__brand{border:0;padding:0}.app-article-masthead__brand img{height:auto;position:static;width:auto}.app-article-masthead__buttons{align-items:center;flex-direction:row;margin-top:auto}.app-article-masthead__journal-link{display:flex;flex-direction:column;gap:24px 24px;margin:0 0 8px;padding:0}.app-article-masthead__submission-link{margin:0}}@media only screen and (min-width:1024px){.app-article-masthead__brand{flex-basis:400px}}.app-article-masthead .c-article-identifiers{font-size:.875rem;font-weight:300;line-height:1;margin:0 0 8px;overflow:hidden;padding:0}.app-article-masthead .c-article-identifiers--cite-list{margin:0 0 16px}.app-article-masthead .c-article-identifiers *{color:#fff}.app-article-masthead .c-cod{display:none}.app-article-masthead .c-article-identifiers__item{border-left:1px solid #fff;border-right:0;margin:0 17px 8px -9px;padding:0 0 0 8px}.app-article-masthead .c-article-identifiers__item--cite{border-left:0}.app-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;padding:16px 0 0;row-gap:24px}.app-article-metrics-bar__item{padding:0 16px 0 0}.app-article-metrics-bar__count{font-weight:700}.app-article-metrics-bar__label{font-weight:400;padding-left:4px}.app-article-metrics-bar__icon{height:auto;margin-right:4px;margin-top:-4px;width:auto}.app-article-metrics-bar__arrow-icon{margin:4px 0 0 4px}.app-article-metrics-bar a{color:#000}.app-article-metrics-bar .app-article-metrics-bar__item--metrics{padding-right:0}.app-overview-section .c-article-author-list,.app-overview-section__authors{line-height:2}.app-article-metrics-bar{margin-top:8px}.c-book-toc-pagination+.c-book-section__back-to-top{margin-top:0}.c-article-body .c-article-access-provider__text--chapter{color:#222;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;padding:20px 0}.c-article-body .c-article-access-provider__text--chapter svg.c-status-message__icon{fill:#003f8d;vertical-align:middle}.c-article-body-section__content--separator{padding-top:40px}.c-pdf-download__link{max-height:44px}.app-article-access .u-button--primary,.app-article-access .u-button--primary:visited{color:#fff}.c-article-sidebar{display:none}@media only screen and (min-width:1024px){.c-article-sidebar{display:block}}.c-cod__form{border-radius:12px}.c-cod__label{font-size:.875rem}.c-cod .c-status-message{align-items:center;justify-content:center;margin-bottom:16px;padding-bottom:16px}@media only screen and (min-width:1024px){.c-cod .c-status-message{align-items:inherit}}.c-cod .c-status-message__icon{margin-top:4px}.c-cod .c-cod__prompt{font-size:1rem;margin-bottom:16px}.c-article-body .app-article-access,.c-book-body .app-article-access{display:block}@media only screen and (min-width:1024px){.c-article-body .app-article-access,.c-book-body .app-article-access{display:none}}.c-article-body .app-card-service{margin-bottom:32px}@media only screen and (min-width:1024px){.c-article-body .app-card-service{display:none}}.app-article-access .buybox__buy .u-button--secondary,.app-article-access .u-button--primary,.c-cod__row .u-button--primary{background-color:#025e8d;border:2px solid #025e8d;box-shadow:none;font-size:1rem;font-weight:700;gap:8px 8px;justify-content:center;line-height:1.5;padding:8px 24px}.app-article-access .buybox__buy .u-button--secondary,.app-article-access .u-button--primary:hover,.c-cod__row .u-button--primary:hover{background-color:#fff;color:#025e8d}.app-article-access .buybox__buy .u-button--secondary:hover{background-color:#025e8d;color:#fff}.buybox__buy .c-notes__text{color:#666;font-size:.875rem;padding:0 16px 8px}.c-cod__input{flex-basis:auto;width:100%}.c-article-title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:2.25rem;font-weight:700;line-height:1.2;margin:12px 0}.c-reading-companion__figure-item figure{margin:0}@media only screen and (min-width:768px){.c-article-title{margin:16px 0}}.app-article-access{border:1px solid #c5e0f4;border-radius:12px}.app-article-access__heading{border-bottom:1px solid #c5e0f4;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1.125rem;font-weight:700;margin:0;padding:16px;text-align:center}.app-article-access .buybox__info svg{vertical-align:middle}.c-article-body .app-article-access p{margin-bottom:0}.app-article-access .buybox__info{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;margin:0}.app-article-access{margin:0 0 32px}@media only screen and (min-width:1024px){.app-article-access{margin:0 0 24px}}.c-status-message{font-size:1rem}.c-article-body{font-size:1.125rem}.c-article-body dl,.c-article-body ol,.c-article-body p,.c-article-body ul{margin-bottom:32px;margin-top:0}.c-article-access-provider__text:last-of-type,.c-article-body .c-notes__text:last-of-type{margin-bottom:0}.c-article-body ol p,.c-article-body ul p{margin-bottom:16px}.c-article-section__figure-caption{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-reading-companion__figure-item{border-top-color:#c5e0f4}.c-reading-companion__sticky{max-width:400px}.c-article-section .c-article-section__figure-description>*{font-size:1rem;margin-bottom:16px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;padding:16px 0}.c-reading-companion__reference-item:first-child{padding-top:0}.c-article-share-box__button,.js .c-article-authors-search__item .c-article-button{background:0 0;border:2px solid #025e8d;border-radius:32px;box-shadow:none;color:#025e8d;font-size:1rem;font-weight:700;line-height:1.5;margin:0;padding:8px 24px;transition:all .2s ease 0s}.c-article-authors-search__item .c-article-button{width:100%}.c-pdf-download .u-button{background-color:#fff;border:2px solid #fff;color:#01324b;justify-content:center}.c-context-bar__container .c-pdf-download .u-button svg,.c-pdf-download .u-button svg{fill:currentcolor}.c-pdf-download .u-button:visited{color:#01324b}.c-pdf-download .u-button:hover{border:4px solid #01324b;box-shadow:none}.c-pdf-download .u-button:focus,.c-pdf-download .u-button:hover{background-color:#01324b}.c-pdf-download .u-button:focus svg path,.c-pdf-download .u-button:hover svg path{fill:#fff}.c-context-bar__container .c-pdf-download .u-button{background-image:none;border:2px solid;color:#fff}.c-context-bar__container .c-pdf-download .u-button:visited{color:#fff}.c-context-bar__container .c-pdf-download .u-button:hover{text-decoration:none}.c-context-bar__container .c-pdf-download .u-button:focus{box-shadow:none;outline:0;text-decoration:none}.c-context-bar__container .c-pdf-download .u-button:focus,.c-context-bar__container .c-pdf-download .u-button:hover{background-color:#fff;background-image:none;color:#01324b}.c-context-bar__container .c-pdf-download .u-button:focus svg path,.c-context-bar__container .c-pdf-download .u-button:hover svg path{fill:#01324b}.c-context-bar__container .c-pdf-download .u-button,.c-pdf-download .u-button{box-shadow:none;font-size:1rem;font-weight:700;line-height:1.5;padding:8px 24px}.c-context-bar__container .c-pdf-download .u-button{background-color:#025e8d}.c-pdf-download .u-button:hover{border:2px solid #fff}.c-pdf-download .u-button:focus,.c-pdf-download .u-button:hover{background:0 0;box-shadow:none;color:#fff}.c-context-bar__container .c-pdf-download .u-button:hover{border:2px solid #025e8d;box-shadow:none;color:#025e8d}.c-context-bar__container .c-pdf-download .u-button:focus,.c-pdf-download .u-button:focus{border:2px solid #025e8d}.c-article-share-box__button:focus:focus,.c-article__pill-button:focus:focus,.c-context-bar__container .c-pdf-download .u-button:focus:focus,.c-pdf-download .u-button:focus:focus{outline:3px solid #08c;will-change:transform}.c-pdf-download__link .u-icon{padding-top:0}.c-bibliographic-information__column button{margin-bottom:16px}.c-article-body .c-article-author-affiliation__list p,.c-article-body .c-article-author-information__list p,figure{margin:0}.c-article-share-box__button{margin-right:16px}.c-status-message--boxed{border-radius:12px}.c-article-associated-content__collection-title{font-size:1rem}.app-card-service__description,.c-article-body .app-card-service__description{color:#222;margin-bottom:0;margin-top:8px}.app-article-access__subscriptions a,.app-article-access__subscriptions a:visited,.app-book-series-listing__item a,.app-book-series-listing__item a:hover,.app-book-series-listing__item a:visited,.c-article-author-list a,.c-article-author-list a:visited,.c-article-buy-box a,.c-article-buy-box a:visited,.c-article-peer-review a,.c-article-peer-review a:visited,.c-article-satellite-subtitle a,.c-article-satellite-subtitle a:visited,.c-breadcrumbs__link,.c-breadcrumbs__link:hover,.c-breadcrumbs__link:visited{color:#000}.c-article-author-list svg{height:24px;margin:0 0 0 6px;width:24px}.c-article-header{margin-bottom:32px}@media only screen and (min-width:876px){.js .c-ad--conditional{display:block}}.u-lazy-ad-wrapper{background-color:#fff;display:none;min-height:149px}@media only screen and (min-width:876px){.u-lazy-ad-wrapper{display:block}}p.c-ad__label{margin-bottom:4px}.c-ad--728x90{background-color:#fff;border-bottom:2px solid #cedbe0} } </style>
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .eds-c-header__brand img{height:24px;width:203px}.app-article-masthead__journal-link img{height:93px;width:72px}@media only screen and (min-width:769px){.app-article-masthead__journal-link img{height:161px;width:122px}} } </style>



        
        <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href=/oscar-static/app-springerlink/css/core-darwin-9fe647df8f.css media="print" onload="this.media='all';this.onload=null">
        <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href="/oscar-static/app-springerlink/css/enhanced-darwin-article-868332661c.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    

        
        
    <script type="text/javascript">
        config = {
            env: 'live',
            site: '11263.springer.com',
            siteWithPath: '11263.springer.com' + window.location.pathname,
            twitterHashtag: '11263',
            cmsPrefix: 'https://studio-cms.springernature.com/studio/',
            
            
            
            
            publisherBrand: 'Springer',
            mustardcut: false
        };
    </script>

        
                




    <script>
        window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1007/s11263-024-02033-7","Page":"article","springerJournal":true,"Publishing Model":"Hybrid Access","Country":"IL","japan":false,"doi":"10.1007-s11263-024-02033-7","Journal Id":11263,"Journal Title":"International Journal of Computer Vision","imprint":"Springer","Keywords":"Computational jigsaw puzzle solving, Lazy caterer, Crossing cuts, Pictorial and apictorial puzzles, Loopy constraints, Hierarchical loops","kwrd":["Computational_jigsaw_puzzle_solving","Lazy_caterer","Crossing_cuts","Pictorial_and_apictorial_puzzles","Loopy_constraints","Hierarchical_loops"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"Y","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"open","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"vgzm.415900-10.1007-s11263-024-02033-7","Full HTML":"Y","Subject Codes":["SCI","SCI22005","SCI21000","SCI22021","SCI2203X"],"pmc":["I","I22005","I21000","I22021","I2203X"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1573-1405","pissn":"0920-5691"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Imaging, Vision, Pattern Recognition and Graphics","2":"Artificial Intelligence","3":"Image Processing and Computer Vision","4":"Pattern Recognition"},"secondarySubjectCodes":{"1":"I22005","2":"I21000","3":"I22021","4":"I2203X"}},"sucode":"SC6","articleType":"Article"},"attributes":{"deliveryPlatform":"oscar"}},"page":{"attributes":{"environment":"live"},"category":{"pageType":"article"}},"Event Category":"Article"}];
    </script>











    <script data-test="springer-link-article-datalayer">
        window.dataLayer = window.dataLayer || [];
        window.dataLayer.push({
            ga4MeasurementId: 'G-B3E4QL2TPR',
            ga360TrackingId: 'UA-26408784-1',
            twitterId: 'o47a7',
            baiduId: 'aef3043f025ccf2305af8a194652d70b',
            ga4ServerUrl: 'https://collect.springer.com',
            imprint: 'springerlink',
                page: {
                    attributes:{
                        featureFlags: [{ name: 'darwin-orion', active: true }],
                        darwinAvailable: true
                    }
                }
            
        });
    </script>



        
        <script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>


        <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
                window.suppressShareButton = false;
                window.onArticlePage = true;
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-572d4fec60.js', 'async': false}
            ];

            var bodyScripts = [
                
                    {'src': '/oscar-static/js/global-article-es5-bundle-237659debf.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-2c19ea9e42.js', 'async': false, 'module': true}
                
                
                    
                
                
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>


<script data-src="https://cdn.optimizely.com/js/27195530232.js" data-cc-script="C03"></script>



        
            
            
                
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                    j = d.createElement(s),
                    dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>

            
            
            
        

        <script>
(function (w, d, t) {
    function cc() {
        var h = w.location.hostname;
        var e = d.createElement(t),
        s = d.getElementsByTagName(t)[0];

        
        if (h.indexOf('springer.com') > -1 && h.indexOf('biomedcentral.com') === -1 && h.indexOf('springeropen.com') === -1) {
            if (h.indexOf('link-qa.springer.com') > -1 || h.indexOf('test-www.springer.com') > -1) {
                e.src = 'https://cmp.springer.com/production_live/en/consent-bundle-17-55.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = 'https://cmp.springer.com/production_live/en/consent-bundle-17-55.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            }
        } else if (h.indexOf('biomedcentral.com') > -1) {
            if (h.indexOf('biomedcentral.com.qa') > -1) {
                e.src = 'https://cmp.biomedcentral.com/production_live/en/consent-bundle-15-40.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = 'https://cmp.biomedcentral.com/production_live/en/consent-bundle-15-40.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            }
        } else if (h.indexOf('springeropen.com') > -1) {
            if (h.indexOf('springeropen.com.qa') > -1) {
                e.src = 'https://cmp.springernature.com/production_live/en/consent-bundle-16-37.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = 'https://cmp.springernature.com/production_live/en/consent-bundle-16-37.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            }
        } else if (h.indexOf('springernature.com') > -1) {
            if (h.indexOf('beta-qa.springernature.com') > -1) {
                e.src = 'https://cmp.springernature.com/production_live/en/consent-bundle-49-43.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-NK22KLS')");
            } else {
                e.src = 'https://cmp.springernature.com/production_live/en/consent-bundle-49-43.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-NK22KLS')");
            }
        } else {
            e.src = '/oscar-static/js/cookie-consent-es5-bundle-cb57c2c98a.js';
            e.setAttribute('data-consent', h);
        }
        s.insertAdjacentElement('afterend', e);
    }

    cc();
})(window, document, 'script');
</script>


        
        
        
    
        
    


        
    
    <link rel="canonical" href="https://link.springer.com/article/10.1007/s11263-024-02033-7"/>
    

        
        
        
        

        
    <script type="application/ld+json">{"mainEntity":{"headline":"Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts","description":"Jigsaw puzzle solving, the problem of constructing a coherent whole from a set of non-overlapping unordered visual fragments, is fundamental to numerous applications, and yet most of the literature of the last two decades has focused thus far on less realistic puzzles whose pieces are identical squares. Here we formalize a new type of jigsaw puzzle where the pieces are general convex polygons generated by cutting through a global polygonal shape/image with an arbitrary number of straight cuts, a generation model inspired by the celebrated Lazy caterer’s sequence. We analyze the theoretical properties of such puzzles, including the inherent challenges in solving them once pieces are contaminated with geometrical noise. To cope with such difficulties and obtain tractable solutions, we abstract the problem as a multi-body spring-mass dynamical system endowed with hierarchical loop constraints and a layered reconstruction process. We define evaluation metrics and present experimental results on both apictorial and pictorial puzzles to show that they are solvable completely automatically.\n","datePublished":"2024-03-22T00:00:00Z","dateModified":"2024-03-22T00:00:00Z","pageStart":"3428","pageEnd":"3462","license":"http://creativecommons.org/licenses/by/4.0/","sameAs":"https://doi.org/10.1007/s11263-024-02033-7","keywords":["Computational jigsaw puzzle solving","Lazy caterer","Crossing cuts","Pictorial and apictorial puzzles","Loopy constraints","Hierarchical loops","Computer Imaging","Vision","Pattern Recognition and Graphics","Artificial Intelligence","Image Processing and Computer Vision","Pattern Recognition"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig1_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig2_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig3_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig4_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig5_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Figa_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig6_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig7_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig8_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig9_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig10_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig11_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig12_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig13_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig14_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig15_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig16_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig17_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig18_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig19_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig20_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig21_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig22_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig23_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig24_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig25_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig26_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig27_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig28_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig29_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig30_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig31_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig32_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig33_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig34_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig35_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig36_HTML.png"],"isPartOf":{"name":"International Journal of Computer Vision","issn":["1573-1405","0920-5691"],"volumeNumber":"132","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Springer US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Peleg Harel","affiliation":[{"name":"Ben-Gurion University of the Negev","address":{"name":"Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Ofir Itzhak Shahar","affiliation":[{"name":"Ben-Gurion University of the Negev","address":{"name":"Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Ohad Ben-Shahar","url":"http://orcid.org/0000-0001-5346-152X","affiliation":[{"name":"Ben-Gurion University of the Negev","address":{"name":"Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel","@type":"PostalAddress"},"@type":"Organization"}],"email":"ben-shahar@cs.bgu.ac.il","@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>

        


        
    </head>

    <body class=""
    
          >
        
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript>
                <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                        height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    

        
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript data-test="gtm-body">
                <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    


        <div class="u-visually-hidden" aria-hidden="true" data-test="darwin-icons">
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><radialGradient id="a" cx="0" cy="0" r="1" gradientTransform="rotate(45 -59.62 655.522) scale(44.8128 213.2632)" gradientUnits="userSpaceOnUse"><stop stop-color="#F58220"/><stop offset=".33" stop-color="#C75301"/><stop offset=".66" stop-color="#785BA7"/><stop offset="1" stop-color="#08C"/></radialGradient></defs><symbol id="icon-eds-i-accesses-medium" viewBox="0 0 24 24"><path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742H15a1 1 0 0 1 0-2h4.455a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM8 13c2.052 0 4.66 1.61 6.36 3.4l.124.141c.333.41.516.925.516 1.459 0 .6-.232 1.178-.64 1.599C12.666 21.388 10.054 23 8 23c-2.052 0-4.66-1.61-6.353-3.393A2.31 2.31 0 0 1 1 18c0-.6.232-1.178.64-1.6C3.34 14.61 5.948 13 8 13Zm0 2c-1.369 0-3.552 1.348-4.917 2.785A.31.31 0 0 0 3 18c0 .083.031.161.09.222C4.447 19.652 6.631 21 8 21c1.37 0 3.556-1.35 4.917-2.785A.31.31 0 0 0 13 18a.32.32 0 0 0-.048-.17l-.042-.052C11.553 16.348 9.369 15 8 15Zm0 1a2 2 0 1 1 0 4 2 2 0 0 1 0-4Z"/></symbol><symbol id="icon-eds-i-altmetric-medium" viewBox="0 0 24 24"><path d="M12 1c5.978 0 10.843 4.77 10.996 10.712l.004.306-.002.022-.002.248C22.843 18.23 17.978 23 12 23 5.925 23 1 18.075 1 12S5.925 1 12 1Zm-1.726 9.246L8.848 12.53a1 1 0 0 1-.718.461L8.003 13l-4.947.014a9.001 9.001 0 0 0 17.887-.001L16.553 13l-2.205 3.53a1 1 0 0 1-1.735-.068l-.05-.11-2.289-6.106ZM12 3a9.001 9.001 0 0 0-8.947 8.013l4.391-.012L9.652 7.47a1 1 0 0 1 1.784.179l2.288 6.104 1.428-2.283a1 1 0 0 1 .722-.462l.129-.008 4.943.012A9.001 9.001 0 0 0 12 3Z"/></symbol><symbol id="icon-eds-i-arrow-bend-down-medium" viewBox="0 0 24 24"><path d="m11.852 20.989.058.007L12 21l.075-.003.126-.017.111-.03.111-.044.098-.052.104-.074.082-.073 6-6a1 1 0 0 0-1.414-1.414L13 17.585v-12.2C13 4.075 11.964 3 10.667 3H4a1 1 0 1 0 0 2h6.667c.175 0 .333.164.333.385v12.2l-4.293-4.292a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414l6 6c.035.036.073.068.112.097l.11.071.114.054.105.035.118.025Z"/></symbol><symbol id="icon-eds-i-arrow-bend-down-small" viewBox="0 0 16 16"><path d="M1 2a1 1 0 0 0 1 1h5v8.585L3.707 8.293a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414l5 5 .063.059.093.069.081.048.105.048.104.035.105.022.096.01h.136l.122-.018.113-.03.103-.04.1-.053.102-.07.052-.043 5.04-5.037a1 1 0 1 0-1.415-1.414L9 11.583V3a2 2 0 0 0-2-2H2a1 1 0 0 0-1 1Z"/></symbol><symbol id="icon-eds-i-arrow-bend-up-medium" viewBox="0 0 24 24"><path d="m11.852 3.011.058-.007L12 3l.075.003.126.017.111.03.111.044.098.052.104.074.082.073 6 6a1 1 0 1 1-1.414 1.414L13 6.415v12.2C13 19.925 11.964 21 10.667 21H4a1 1 0 0 1 0-2h6.667c.175 0 .333-.164.333-.385v-12.2l-4.293 4.292a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l6-6c.035-.036.073-.068.112-.097l.11-.071.114-.054.105-.035.118-.025Z"/></symbol><symbol id="icon-eds-i-arrow-bend-up-small" viewBox="0 0 16 16"><path d="M1 13.998a1 1 0 0 1 1-1h5V4.413L3.707 7.705a1 1 0 0 1-1.32.084l-.094-.084a1 1 0 0 1 0-1.414l5-5 .063-.059.093-.068.081-.05.105-.047.104-.035.105-.022L7.94 1l.136.001.122.017.113.03.103.04.1.053.102.07.052.043 5.04 5.037a1 1 0 1 1-1.415 1.414L9 4.415v8.583a2 2 0 0 1-2 2H2a1 1 0 0 1-1-1Z"/></symbol><symbol id="icon-eds-i-arrow-diagonal-medium" viewBox="0 0 24 24"><path d="M14 3h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L21 4v6a1 1 0 0 1-2 0V6.414l-4.293 4.293a1 1 0 0 1-1.414-1.414L17.584 5H14a1 1 0 0 1-.993-.883L13 4a1 1 0 0 1 1-1ZM4 13a1 1 0 0 1 1 1v3.584l4.293-4.291a1 1 0 1 1 1.414 1.414L6.414 19H10a1 1 0 0 1 .993.883L11 20a1 1 0 0 1-1 1l-6.075-.003-.126-.017-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08a1.01 1.01 0 0 1-.097-.112l-.071-.11-.054-.114-.035-.105-.025-.118-.007-.058L3 20v-6a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-arrow-diagonal-small" viewBox="0 0 16 16"><path d="m2 15-.082-.004-.119-.016-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08a1.008 1.008 0 0 1-.097-.112l-.071-.11-.031-.062-.034-.081-.024-.076-.025-.118-.007-.058L1 14.02V9a1 1 0 1 1 2 0v2.584l2.793-2.791a1 1 0 1 1 1.414 1.414L4.414 13H7a1 1 0 0 1 .993.883L8 14a1 1 0 0 1-1 1H2ZM14 1l.081.003.12.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.031.062.034.081.024.076.03.148L15 2v5a1 1 0 0 1-2 0V4.414l-2.96 2.96A1 1 0 1 1 8.626 5.96L11.584 3H9a1 1 0 0 1-.993-.883L8 2a1 1 0 0 1 1-1h5Z"/></symbol><symbol id="icon-eds-i-arrow-down-medium" viewBox="0 0 24 24"><path d="m20.707 12.728-7.99 7.98a.996.996 0 0 1-.561.281l-.157.011a.998.998 0 0 1-.788-.384l-7.918-7.908a1 1 0 0 1 1.414-1.416L11 17.576V4a1 1 0 0 1 2 0v13.598l6.293-6.285a1 1 0 0 1 1.32-.082l.095.083a1 1 0 0 1-.001 1.414Z"/></symbol><symbol id="icon-eds-i-arrow-down-small" viewBox="0 0 16 16"><path d="m1.293 8.707 6 6 .063.059.093.069.081.048.105.049.104.034.056.013.118.017L8 15l.076-.003.122-.017.113-.03.085-.032.063-.03.098-.058.06-.043.05-.043 6.04-6.037a1 1 0 0 0-1.414-1.414L9 11.583V2a1 1 0 1 0-2 0v9.585L2.707 7.293a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414Z"/></symbol><symbol id="icon-eds-i-arrow-left-medium" viewBox="0 0 24 24"><path d="m11.272 3.293-7.98 7.99a.996.996 0 0 0-.281.561L3 12.001c0 .32.15.605.384.788l7.908 7.918a1 1 0 0 0 1.416-1.414L6.424 13H20a1 1 0 0 0 0-2H6.402l6.285-6.293a1 1 0 0 0 .082-1.32l-.083-.095a1 1 0 0 0-1.414.001Z"/></symbol><symbol id="icon-eds-i-arrow-left-small" viewBox="0 0 16 16"><path d="m7.293 1.293-6 6-.059.063-.069.093-.048.081-.049.105-.034.104-.013.056-.017.118L1 8l.003.076.017.122.03.113.032.085.03.063.058.098.043.06.043.05 6.037 6.04a1 1 0 0 0 1.414-1.414L4.417 9H14a1 1 0 0 0 0-2H4.415l4.292-4.293a1 1 0 0 0 .083-1.32l-.083-.094a1 1 0 0 0-1.414 0Z"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-arrow-right-small" viewBox="0 0 16 16"><path d="m8.707 1.293 6 6 .059.063.069.093.048.081.049.105.034.104.013.056.017.118L15 8l-.003.076-.017.122-.03.113-.032.085-.03.063-.058.098-.043.06-.043.05-6.037 6.04a1 1 0 0 1-1.414-1.414L11.583 9H2a1 1 0 1 1 0-2h9.585L7.293 2.707a1 1 0 0 1-.083-1.32l.083-.094a1 1 0 0 1 1.414 0Z"/></symbol><symbol id="icon-eds-i-arrow-up-medium" viewBox="0 0 24 24"><path d="m3.293 11.272 7.99-7.98a.996.996 0 0 1 .561-.281L12.001 3c.32 0 .605.15.788.384l7.918 7.908a1 1 0 0 1-1.414 1.416L13 6.424V20a1 1 0 0 1-2 0V6.402l-6.293 6.285a1 1 0 0 1-1.32.082l-.095-.083a1 1 0 0 1 .001-1.414Z"/></symbol><symbol id="icon-eds-i-arrow-up-small" viewBox="0 0 16 16"><path d="m1.293 7.293 6-6 .063-.059.093-.069.081-.048.105-.049.104-.034.056-.013.118-.017L8 1l.076.003.122.017.113.03.085.032.063.03.098.058.06.043.05.043 6.04 6.037a1 1 0 0 1-1.414 1.414L9 4.417V14a1 1 0 0 1-2 0V4.415L2.707 8.707a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414Z"/></symbol><symbol id="icon-eds-i-article-medium" viewBox="0 0 24 24"><path d="M8 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H8ZM8 11a1 1 0 1 0 0 2h8a1 1 0 1 0 0-2H8ZM7 16a1 1 0 0 1 1-1h8a1 1 0 1 1 0 2H8a1 1 0 0 1-1-1Z"/><path d="M5.545 1A2.542 2.542 0 0 0 3 3.538v16.924A2.542 2.542 0 0 0 5.545 23h12.91A2.542 2.542 0 0 0 21 20.462V3.5A2.5 2.5 0 0 0 18.5 1H5.545ZM5 3.538C5 3.245 5.24 3 5.545 3H18.5a.5.5 0 0 1 .5.5v16.962c0 .293-.24.538-.546.538H5.545A.542.542 0 0 1 5 20.462V3.538Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-book-medium" viewBox="0 0 24 24"><path d="M18.5 1A2.5 2.5 0 0 1 21 3.5v12c0 1.16-.79 2.135-1.86 2.418l-.14.031V21h1a1 1 0 0 1 .993.883L21 22a1 1 0 0 1-1 1H6.5A3.5 3.5 0 0 1 3 19.5v-15A3.5 3.5 0 0 1 6.5 1h12ZM17 18H6.5a1.5 1.5 0 0 0-1.493 1.356L5 19.5A1.5 1.5 0 0 0 6.5 21H17v-3Zm1.5-15h-12A1.5 1.5 0 0 0 5 4.5v11.837l.054-.025a3.481 3.481 0 0 1 1.254-.307L6.5 16h12a.5.5 0 0 0 .492-.41L19 15.5v-12a.5.5 0 0 0-.5-.5ZM15 6a1 1 0 0 1 0 2H9a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M1 3.786C1 2.759 1.857 2 2.82 2H6.18c.964 0 1.82.759 1.82 1.786V4h3.168c.668 0 1.298.364 1.616.938.158-.109.333-.195.523-.252l3.216-.965c.923-.277 1.962.204 2.257 1.187l4.146 13.82c.296.984-.307 1.957-1.23 2.234l-3.217.965c-.923.277-1.962-.203-2.257-1.187L13 10.005v10.21c0 1.04-.878 1.785-1.834 1.785H7.833c-.291 0-.575-.07-.83-.195A1.849 1.849 0 0 1 6.18 22H2.821C1.857 22 1 21.241 1 20.214V3.786ZM3 4v11h3V4H3Zm0 16v-3h3v3H3Zm15.075-.04-.814-2.712 2.874-.862.813 2.712-2.873.862Zm1.485-5.49-2.874.862-2.634-8.782 2.873-.862 2.635 8.782ZM8 20V6h3v14H8Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-calendar-acceptance-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-.534 7.747a1 1 0 0 1 .094 1.412l-4.846 5.538a1 1 0 0 1-1.352.141l-2.77-2.076a1 1 0 0 1 1.2-1.6l2.027 1.519 4.236-4.84a1 1 0 0 1 1.411-.094ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-date-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1ZM8 15a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm-4-4a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-decision-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-2.935 8.246 2.686 2.645c.34.335.34.883 0 1.218l-2.686 2.645a.858.858 0 0 1-1.213-.009.854.854 0 0 1 .009-1.21l1.05-1.035H7.984a.992.992 0 0 1-.984-1c0-.552.44-1 .984-1h5.928l-1.051-1.036a.854.854 0 0 1-.085-1.121l.076-.088a.858.858 0 0 1 1.213-.009ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-impact-factor-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-3.2 6.924a.48.48 0 0 1 .125.544l-1.52 3.283h2.304c.27 0 .491.215.491.483a.477.477 0 0 1-.13.327l-4.18 4.484a.498.498 0 0 1-.69.031.48.48 0 0 1-.125-.544l1.52-3.284H9.291a.487.487 0 0 1-.491-.482c0-.121.047-.238.13-.327l4.18-4.484a.498.498 0 0 1 .69-.031ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-call-papers-medium" viewBox="0 0 24 24"><g><path d="m20.707 2.883-1.414 1.414a1 1 0 0 0 1.414 1.414l1.414-1.414a1 1 0 0 0-1.414-1.414Z"/><path d="M6 16.054c0 2.026 1.052 2.943 3 2.943a1 1 0 1 1 0 2c-2.996 0-5-1.746-5-4.943v-1.227a4.068 4.068 0 0 1-1.83-1.189 4.553 4.553 0 0 1-.87-1.455 4.868 4.868 0 0 1-.3-1.686c0-1.17.417-2.298 1.17-3.14.38-.426.834-.767 1.338-1 .51-.237 1.06-.36 1.617-.36L6.632 6H7l7.932-2.895A2.363 2.363 0 0 1 18 5.36v9.28a2.36 2.36 0 0 1-3.069 2.25l.084.03L7 14.997H6v1.057Zm9.637-11.057a.415.415 0 0 0-.083.008L8 7.638v5.536l7.424 1.786.104.02c.035.01.072.02.109.02.2 0 .363-.16.363-.36V5.36c0-.2-.163-.363-.363-.363Zm-9.638 3h-.874a1.82 1.82 0 0 0-.625.111l-.15.063a2.128 2.128 0 0 0-.689.517c-.42.47-.661 1.123-.661 1.81 0 .34.06.678.176.992.114.308.28.585.485.816.4.447.925.691 1.464.691h.874v-5Z" clip-rule="evenodd"/><path d="M20 8.997h2a1 1 0 1 1 0 2h-2a1 1 0 1 1 0-2ZM20.707 14.293l1.414 1.414a1 1 0 0 1-1.414 1.414l-1.414-1.414a1 1 0 0 1 1.414-1.414Z"/></g></symbol><symbol id="icon-eds-i-card-medium" viewBox="0 0 24 24"><path d="M19.615 2c.315 0 .716.067 1.14.279.76.38 1.245 1.107 1.245 2.106v15.23c0 .315-.067.716-.279 1.14-.38.76-1.107 1.245-2.106 1.245H4.385a2.56 2.56 0 0 1-1.14-.279C2.485 21.341 2 20.614 2 19.615V4.385c0-.315.067-.716.279-1.14C2.659 2.485 3.386 2 4.385 2h15.23Zm0 2H4.385c-.213 0-.265.034-.317.14A.71.71 0 0 0 4 4.385v15.23c0 .213.034.265.14.317a.71.71 0 0 0 .245.068h15.23c.213 0 .265-.034.317-.14a.71.71 0 0 0 .068-.245V4.385c0-.213-.034-.265-.14-.317A.71.71 0 0 0 19.615 4ZM17 16a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h10Zm0-3a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h10Zm-.5-7A1.5 1.5 0 0 1 18 7.5v3a1.5 1.5 0 0 1-1.5 1.5h-9A1.5 1.5 0 0 1 6 10.5v-3A1.5 1.5 0 0 1 7.5 6h9ZM16 8H8v2h8V8Z"/></symbol><symbol id="icon-eds-i-cart-medium" viewBox="0 0 24 24"><path d="M5.76 1a1 1 0 0 1 .994.902L7.155 6h13.34c.18 0 .358.02.532.057l.174.045a2.5 2.5 0 0 1 1.693 3.103l-2.069 7.03c-.36 1.099-1.398 1.823-2.49 1.763H8.65c-1.272.015-2.352-.927-2.546-2.244L4.852 3H2a1 1 0 0 1-.993-.883L1 2a1 1 0 0 1 1-1h3.76Zm2.328 14.51a.555.555 0 0 0 .55.488l9.751.001a.533.533 0 0 0 .527-.357l2.059-7a.5.5 0 0 0-.48-.642H7.351l.737 7.51ZM18 19a2 2 0 1 1 0 4 2 2 0 0 1 0-4ZM8 19a2 2 0 1 1 0 4 2 2 0 0 1 0-4Z"/></symbol><symbol id="icon-eds-i-check-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm5.125 4.72a1 1 0 0 1 .156 1.405l-6 7.5a1 1 0 0 1-1.421.143l-3-2.5a1 1 0 0 1 1.28-1.536l2.217 1.846 5.362-6.703a1 1 0 0 1 1.406-.156Z"/></symbol><symbol id="icon-eds-i-check-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm5.125 6.72a1 1 0 0 0-1.406.155l-5.362 6.703-2.217-1.846a1 1 0 1 0-1.28 1.536l3 2.5a1 1 0 0 0 1.42-.143l6-7.5a1 1 0 0 0-.155-1.406Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 24 24"><path d="M3.305 8.28a1 1 0 0 0-.024 1.415l7.495 7.762c.314.345.757.543 1.224.543.467 0 .91-.198 1.204-.522l7.515-7.783a1 1 0 1 0-1.438-1.39L12 15.845l-7.28-7.54A1 1 0 0 0 3.4 8.2l-.096.082Z"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-left-medium" viewBox="0 0 24 24"><path d="M15.72 3.305a1 1 0 0 0-1.415-.024l-7.762 7.495A1.655 1.655 0 0 0 6 12c0 .467.198.91.522 1.204l7.783 7.515a1 1 0 1 0 1.39-1.438L8.155 12l7.54-7.28A1 1 0 0 0 15.8 3.4l-.082-.096Z"/></symbol><symbol id="icon-eds-i-chevron-left-small" viewBox="0 0 16 16"><path d="M10.722 2.308a1 1 0 0 0-1.414-.03L4.49 6.897a1.491 1.491 0 0 0-.019 2.188l4.838 4.637a1 1 0 1 0 1.384-1.444L6.229 8l4.463-4.278a1 1 0 0 0 .111-1.318l-.081-.096Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 24 24"><path d="M8.28 3.305a1 1 0 0 1 1.415-.024l7.762 7.495c.345.314.543.757.543 1.224 0 .467-.198.91-.522 1.204l-7.783 7.515a1 1 0 1 1-1.39-1.438L15.845 12l-7.54-7.28A1 1 0 0 1 8.2 3.4l.082-.096Z"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 16 16"><path d="M5.278 2.308a1 1 0 0 1 1.414-.03l4.819 4.619a1.491 1.491 0 0 1 .019 2.188l-4.838 4.637a1 1 0 1 1-1.384-1.444L9.771 8 5.308 3.722a1 1 0 0 1-.111-1.318l.081-.096Z"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 24 24"><path d="M20.695 15.72a1 1 0 0 0 .024-1.415l-7.495-7.762A1.655 1.655 0 0 0 12 6c-.467 0-.91.198-1.204.522l-7.515 7.783a1 1 0 1 0 1.438 1.39L12 8.155l7.28 7.54a1 1 0 0 0 1.319.106l.096-.082Z"/></symbol><symbol id="icon-eds-i-chevron-up-small" viewBox="0 0 16 16"><path d="M13.692 10.722a1 1 0 0 0 .03-1.414L9.103 4.49a1.491 1.491 0 0 0-2.188-.019L2.278 9.308a1 1 0 0 0 1.444 1.384L8 6.229l4.278 4.463a1 1 0 0 0 1.318.111l.096-.081Z"/></symbol><symbol id="icon-eds-i-citations-medium" viewBox="0 0 24 24"><path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM5.483 14.35c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Zm5 0c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Z"/></symbol><symbol id="icon-eds-i-clipboard-check-medium" viewBox="0 0 24 24"><path d="M14.4 1c1.238 0 2.274.865 2.536 2.024L18.5 3C19.886 3 21 4.14 21 5.535v14.93C21 21.86 19.886 23 18.5 23h-13C4.114 23 3 21.86 3 20.465V5.535C3 4.14 4.114 3 5.5 3h1.57c.27-1.147 1.3-2 2.53-2h4.8Zm4.115 4-1.59.024A2.601 2.601 0 0 1 14.4 7H9.6c-1.23 0-2.26-.853-2.53-2H5.5c-.27 0-.5.234-.5.535v14.93c0 .3.23.535.5.535h13c.27 0 .5-.234.5-.535V5.535c0-.3-.23-.535-.485-.535Zm-1.909 4.205a1 1 0 0 1 .19 1.401l-5.334 7a1 1 0 0 1-1.344.23l-2.667-1.75a1 1 0 1 1 1.098-1.672l1.887 1.238 4.769-6.258a1 1 0 0 1 1.401-.19ZM14.4 3H9.6a.6.6 0 0 0-.6.6v.8a.6.6 0 0 0 .6.6h4.8a.6.6 0 0 0 .6-.6v-.8a.6.6 0 0 0-.6-.6Z"/></symbol><symbol id="icon-eds-i-clipboard-report-medium" viewBox="0 0 24 24"><path d="M14.4 1c1.238 0 2.274.865 2.536 2.024L18.5 3C19.886 3 21 4.14 21 5.535v14.93C21 21.86 19.886 23 18.5 23h-13C4.114 23 3 21.86 3 20.465V5.535C3 4.14 4.114 3 5.5 3h1.57c.27-1.147 1.3-2 2.53-2h4.8Zm4.115 4-1.59.024A2.601 2.601 0 0 1 14.4 7H9.6c-1.23 0-2.26-.853-2.53-2H5.5c-.27 0-.5.234-.5.535v14.93c0 .3.23.535.5.535h13c.27 0 .5-.234.5-.535V5.535c0-.3-.23-.535-.485-.535Zm-2.658 10.929a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h7.857Zm0-3.929a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h7.857ZM14.4 3H9.6a.6.6 0 0 0-.6.6v.8a.6.6 0 0 0 .6.6h4.8a.6.6 0 0 0 .6-.6v-.8a.6.6 0 0 0-.6-.6Z"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18ZM8.707 7.293 12 10.585l3.293-3.292a1 1 0 0 1 1.414 1.414L13.415 12l3.292 3.293a1 1 0 0 1-1.414 1.414L12 13.415l-3.293 3.292a1 1 0 1 1-1.414-1.414L10.585 12 7.293 8.707a1 1 0 0 1 1.414-1.414Z"/></symbol><symbol id="icon-eds-i-cloud-upload-medium" viewBox="0 0 24 24"><path d="m12.852 10.011.028-.004L13 10l.075.003.126.017.086.022.136.052.098.052.104.074.082.073 3 3a1 1 0 0 1 0 1.414l-.094.083a1 1 0 0 1-1.32-.083L14 13.416V20a1 1 0 0 1-2 0v-6.586l-1.293 1.293a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l3-3 .112-.097.11-.071.114-.054.105-.035.118-.025Zm.587-7.962c3.065.362 5.497 2.662 5.992 5.562l.013.085.207.073c2.117.782 3.496 2.845 3.337 5.097l-.022.226c-.297 2.561-2.503 4.491-5.124 4.502a1 1 0 1 1-.009-2c1.619-.007 2.967-1.186 3.147-2.733.179-1.542-.86-2.979-2.487-3.353-.512-.149-.894-.579-.981-1.165-.21-2.237-2-4.035-4.308-4.308-2.31-.273-4.497 1.06-5.25 3.19l-.049.113c-.234.468-.718.756-1.176.743-1.418.057-2.689.857-3.32 2.084a3.668 3.668 0 0 0 .262 3.798c.796 1.136 2.169 1.764 3.583 1.635a1 1 0 1 1 .182 1.992c-2.125.194-4.193-.753-5.403-2.48a5.668 5.668 0 0 1-.403-5.86c.85-1.652 2.449-2.79 4.323-3.092l.287-.039.013-.028c1.207-2.741 4.125-4.404 7.186-4.042Z"/></symbol><symbol id="icon-eds-i-collection-medium" viewBox="0 0 24 24"><path d="M21 7a1 1 0 0 1 1 1v12.5a2.5 2.5 0 0 1-2.5 2.5H8a1 1 0 0 1 0-2h11.5a.5.5 0 0 0 .5-.5V8a1 1 0 0 1 1-1Zm-5.5-5A2.5 2.5 0 0 1 18 4.5v12a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 2 16.5v-12A2.5 2.5 0 0 1 4.5 2h11Zm0 2h-11a.5.5 0 0 0-.5.5v12a.5.5 0 0 0 .5.5h11a.5.5 0 0 0 .5-.5v-12a.5.5 0 0 0-.5-.5ZM13 13a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h6Zm0-3.5a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h6ZM13 6a1 1 0 0 1 0 2H7a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-conference-series-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M4.5 2A2.5 2.5 0 0 0 2 4.5v11A2.5 2.5 0 0 0 4.5 18h2.37l-2.534 2.253a1 1 0 0 0 1.328 1.494L9.88 18H11v3a1 1 0 1 0 2 0v-3h1.12l4.216 3.747a1 1 0 0 0 1.328-1.494L17.13 18h2.37a2.5 2.5 0 0 0 2.5-2.5v-11A2.5 2.5 0 0 0 19.5 2h-15ZM20 6V4.5a.5.5 0 0 0-.5-.5h-15a.5.5 0 0 0-.5.5V6h16ZM4 8v7.5a.5.5 0 0 0 .5.5h15a.5.5 0 0 0 .5-.5V8H4Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-delivery-medium" viewBox="0 0 24 24"><path d="M8.51 20.598a3.037 3.037 0 0 1-3.02 0A2.968 2.968 0 0 1 4.161 19L3.5 19A2.5 2.5 0 0 1 1 16.5v-11A2.5 2.5 0 0 1 3.5 3h10a2.5 2.5 0 0 1 2.45 2.004L16 5h2.527c.976 0 1.855.585 2.27 1.49l2.112 4.62a1 1 0 0 1 .091.416v4.856C23 17.814 21.889 19 20.484 19h-.523a1.01 1.01 0 0 1-.121-.007 2.96 2.96 0 0 1-1.33 1.605 3.037 3.037 0 0 1-3.02 0A2.968 2.968 0 0 1 14.161 19H9.838a2.968 2.968 0 0 1-1.327 1.597Zm-2.024-3.462a.955.955 0 0 0-.481.73L5.999 18l.001.022a.944.944 0 0 0 .388.777l.098.065c.316.181.712.181 1.028 0A.97.97 0 0 0 8 17.978a.95.95 0 0 0-.486-.842 1.037 1.037 0 0 0-1.028 0Zm10 0a.955.955 0 0 0-.481.73l-.005.156a.944.944 0 0 0 .388.777l.098.065c.316.181.712.181 1.028 0a.97.97 0 0 0 .486-.886.95.95 0 0 0-.486-.842 1.037 1.037 0 0 0-1.028 0ZM21 12h-5v3.17a3.038 3.038 0 0 1 2.51.232 2.993 2.993 0 0 1 1.277 1.45l.058.155.058-.005.581-.002c.27 0 .516-.263.516-.618V12Zm-7.5-7h-10a.5.5 0 0 0-.5.5v11a.5.5 0 0 0 .5.5h.662a2.964 2.964 0 0 1 1.155-1.491l.172-.107a3.037 3.037 0 0 1 3.022 0A2.987 2.987 0 0 1 9.843 17H13.5a.5.5 0 0 0 .5-.5v-11a.5.5 0 0 0-.5-.5Zm5.027 2H16v3h4.203l-1.224-2.677a.532.532 0 0 0-.375-.316L18.527 7Z"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 24 24"><path d="M22 18.5a3.5 3.5 0 0 1-3.5 3.5h-13A3.5 3.5 0 0 1 2 18.5V18a1 1 0 0 1 2 0v.5A1.5 1.5 0 0 0 5.5 20h13a1.5 1.5 0 0 0 1.5-1.5V18a1 1 0 0 1 2 0v.5Zm-3.293-7.793-6 6-.063.059-.093.069-.081.048-.105.049-.104.034-.056.013-.118.017L12 17l-.076-.003-.122-.017-.113-.03-.085-.032-.063-.03-.098-.058-.06-.043-.05-.043-6.04-6.037a1 1 0 0 1 1.414-1.414l4.294 4.29L11 3a1 1 0 0 1 2 0l.001 10.585 4.292-4.292a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414Z"/></symbol><symbol id="icon-eds-i-edit-medium" viewBox="0 0 24 24"><path d="M17.149 2a2.38 2.38 0 0 1 1.699.711l2.446 2.46a2.384 2.384 0 0 1 .005 3.38L10.01 19.906a1 1 0 0 1-.434.257l-6.3 1.8a1 1 0 0 1-1.237-1.237l1.8-6.3a1 1 0 0 1 .257-.434L15.443 2.718A2.385 2.385 0 0 1 17.15 2Zm-3.874 5.689-7.586 7.536-1.234 4.319 4.318-1.234 7.54-7.582-3.038-3.039ZM17.149 4a.395.395 0 0 0-.286.126L14.695 6.28l3.029 3.029 2.162-2.173a.384.384 0 0 0 .106-.197L20 6.864c0-.103-.04-.2-.119-.278l-2.457-2.47A.385.385 0 0 0 17.149 4Z"/></symbol><symbol id="icon-eds-i-education-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M12.41 2.088a1 1 0 0 0-.82 0l-10 4.5a1 1 0 0 0 0 1.824L3 9.047v7.124A3.001 3.001 0 0 0 4 22a3 3 0 0 0 1-5.83V9.948l1 .45V14.5a1 1 0 0 0 .087.408L7 14.5c-.913.408-.912.41-.912.41l.001.003.003.006.007.015a1.988 1.988 0 0 0 .083.16c.054.097.131.225.236.373.21.297.53.68.993 1.057C8.351 17.292 9.824 18 12 18c2.176 0 3.65-.707 4.589-1.476.463-.378.783-.76.993-1.057a4.162 4.162 0 0 0 .319-.533l.007-.015.003-.006v-.003h.002s0-.002-.913-.41l.913.408A1 1 0 0 0 18 14.5v-4.103l4.41-1.985a1 1 0 0 0 0-1.824l-10-4.5ZM16 11.297l-3.59 1.615a1 1 0 0 1-.82 0L8 11.297v2.94a3.388 3.388 0 0 0 .677.739C9.267 15.457 10.294 16 12 16s2.734-.543 3.323-1.024a3.388 3.388 0 0 0 .677-.739v-2.94ZM4.437 7.5 12 4.097 19.563 7.5 12 10.903 4.437 7.5ZM3 19a1 1 0 1 1 2 0 1 1 0 0 1-2 0Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-error-diamond-medium" viewBox="0 0 24 24"><path d="M12.002 1c.702 0 1.375.279 1.871.775l8.35 8.353a2.646 2.646 0 0 1 .001 3.744l-8.353 8.353a2.646 2.646 0 0 1-3.742 0l-8.353-8.353a2.646 2.646 0 0 1 0-3.744l8.353-8.353.156-.142c.424-.362.952-.58 1.507-.625l.21-.008Zm0 2a.646.646 0 0 0-.38.123l-.093.08-8.34 8.34a.646.646 0 0 0-.18.355L3 12c0 .171.068.336.19.457l8.353 8.354a.646.646 0 0 0 .914 0l8.354-8.354a.646.646 0 0 0-.001-.914l-8.351-8.354A.646.646 0 0 0 12.002 3ZM12 14.5a1.5 1.5 0 0 1 .144 2.993L12 17.5a1.5 1.5 0 0 1 0-3ZM12 6a1 1 0 0 1 1 1v5a1 1 0 0 1-2 0V7a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-error-filled-medium" viewBox="0 0 24 24"><path d="M12.002 1c.702 0 1.375.279 1.871.775l8.35 8.353a2.646 2.646 0 0 1 .001 3.744l-8.353 8.353a2.646 2.646 0 0 1-3.742 0l-8.353-8.353a2.646 2.646 0 0 1 0-3.744l8.353-8.353.156-.142c.424-.362.952-.58 1.507-.625l.21-.008ZM12 14.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 14.5ZM12 6a1 1 0 0 0-1 1v5a1 1 0 0 0 2 0V7a1 1 0 0 0-1-1Z"/></symbol><symbol id="icon-eds-i-external-link-medium" viewBox="0 0 24 24"><path d="M9 2a1 1 0 1 1 0 2H4.6c-.371 0-.6.209-.6.5v15c0 .291.229.5.6.5h14.8c.371 0 .6-.209.6-.5V15a1 1 0 0 1 2 0v4.5c0 1.438-1.162 2.5-2.6 2.5H4.6C3.162 22 2 20.938 2 19.5v-15C2 3.062 3.162 2 4.6 2H9Zm6 0h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L22 3v6a1 1 0 0 1-2 0V5.414l-6.693 6.693a1 1 0 0 1-1.414-1.414L18.584 4H15a1 1 0 0 1-.993-.883L14 3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-external-link-small" viewBox="0 0 16 16"><path d="M5 1a1 1 0 1 1 0 2l-2-.001V13L13 13v-2a1 1 0 0 1 2 0v2c0 1.15-.93 2-2.067 2H3.067C1.93 15 1 14.15 1 13V3c0-1.15.93-2 2.067-2H5Zm4 0h5l.075.003.126.017.111.03.111.044.098.052.096.067.09.08.044.047.073.093.051.083.054.113.035.105.03.148L15 2v5a1 1 0 0 1-2 0V4.414L9.107 8.307a1 1 0 0 1-1.414-1.414L11.584 3H9a1 1 0 0 1-.993-.883L8 2a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-file-download-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3ZM12 7a1 1 0 0 1 1 1v6.585l2.293-2.292a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414l-4 4a1.008 1.008 0 0 1-.112.097l-.11.071-.114.054-.105.035-.149.03L12 18l-.075-.003-.126-.017-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08-4-4a1 1 0 0 1 1.414-1.414L11 14.585V8a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-file-report-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742H5.545c-.674 0-1.32-.267-1.798-.742A2.535 2.535 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .142.057.278.158.379.102.102.242.159.387.159h12.91a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.915L14.085 3ZM16 17a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm0-3a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm-4.793-6.207L13 9.585l1.793-1.792a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414l-2.5 2.5a1 1 0 0 1-1.414 0L10.5 9.915l-1.793 1.792a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l2.5-2.5a1 1 0 0 1 1.414 0Z"/></symbol><symbol id="icon-eds-i-file-text-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3ZM16 15a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm0-4a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm-5-4a1 1 0 0 1 0 2H8a1 1 0 1 1 0-2h3Z"/></symbol><symbol id="icon-eds-i-file-upload-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3Zm-2.233 4.011.058-.007L12 7l.075.003.126.017.111.03.111.044.098.052.104.074.082.073 4 4a1 1 0 0 1 0 1.414l-.094.083a1 1 0 0 1-1.32-.083L13 10.415V17a1 1 0 0 1-2 0v-6.585l-2.293 2.292a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l4-4 .112-.097.11-.071.114-.054.105-.035.118-.025Z"/></symbol><symbol id="icon-eds-i-filter-medium" viewBox="0 0 24 24"><path d="M21 2a1 1 0 0 1 .82 1.573L15 13.314V18a1 1 0 0 1-.31.724l-.09.076-4 3A1 1 0 0 1 9 21v-7.684L2.18 3.573a1 1 0 0 1 .707-1.567L3 2h18Zm-1.921 2H4.92l5.9 8.427a1 1 0 0 1 .172.45L11 13v6l2-1.5V13a1 1 0 0 1 .117-.469l.064-.104L19.079 4Z"/></symbol><symbol id="icon-eds-i-funding-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M23 8A7 7 0 1 0 9 8a7 7 0 0 0 14 0ZM9.006 12.225A4.07 4.07 0 0 0 6.12 11.02H2a.979.979 0 1 0 0 1.958h4.12c.558 0 1.094.222 1.489.617l2.207 2.288c.27.27.27.687.012.944a.656.656 0 0 1-.928 0L7.744 15.67a.98.98 0 0 0-1.386 1.384l1.157 1.158c.535.536 1.244.791 1.946.765l.041.002h6.922c.874 0 1.597.748 1.597 1.688 0 .203-.146.354-.309.354H7.755c-.487 0-.96-.178-1.339-.504L2.64 17.259a.979.979 0 0 0-1.28 1.482L5.137 22c.733.631 1.66.979 2.618.979h9.957c1.26 0 2.267-1.043 2.267-2.312 0-2.006-1.584-3.646-3.555-3.646h-4.529a2.617 2.617 0 0 0-.681-2.509l-2.208-2.287ZM16 3a5 5 0 1 0 0 10 5 5 0 0 0 0-10Zm.979 3.5a.979.979 0 1 0-1.958 0v3a.979.979 0 1 0 1.958 0v-3Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-hashtag-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18ZM9.52 18.189a1 1 0 1 1-1.964-.378l.437-2.274H6a1 1 0 1 1 0-2h2.378l.592-3.076H6a1 1 0 0 1 0-2h3.354l.51-2.65a1 1 0 1 1 1.964.378l-.437 2.272h3.04l.51-2.65a1 1 0 1 1 1.964.378l-.438 2.272H18a1 1 0 0 1 0 2h-1.917l-.592 3.076H18a1 1 0 0 1 0 2h-2.893l-.51 2.652a1 1 0 1 1-1.964-.378l.437-2.274h-3.04l-.51 2.652Zm.895-4.652h3.04l.591-3.076h-3.04l-.591 3.076Z"/></symbol><symbol id="icon-eds-i-home-medium" viewBox="0 0 24 24"><path d="M5 22a1 1 0 0 1-1-1v-8.586l-1.293 1.293a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l10-10a1 1 0 0 1 1.414 0l10 10a1 1 0 0 1-1.414 1.414L20 12.415V21a1 1 0 0 1-1 1H5Zm7-17.585-6 5.999V20h5v-4a1 1 0 0 1 2 0v4h5v-9.585l-6-6Z"/></symbol><symbol id="icon-eds-i-image-medium" viewBox="0 0 24 24"><path d="M19.615 2A2.385 2.385 0 0 1 22 4.385v15.23A2.385 2.385 0 0 1 19.615 22H4.385A2.385 2.385 0 0 1 2 19.615V4.385A2.385 2.385 0 0 1 4.385 2h15.23Zm0 2H4.385A.385.385 0 0 0 4 4.385v15.23c0 .213.172.385.385.385h1.244l10.228-8.76a1 1 0 0 1 1.254-.037L20 13.392V4.385A.385.385 0 0 0 19.615 4Zm-3.07 9.283L8.703 20h10.912a.385.385 0 0 0 .385-.385v-3.713l-3.455-2.619ZM9.5 6a3.5 3.5 0 1 1 0 7 3.5 3.5 0 0 1 0-7Zm0 2a1.5 1.5 0 1 0 0 3 1.5 1.5 0 0 0 0-3Z"/></symbol><symbol id="icon-eds-i-impact-factor-medium" viewBox="0 0 24 24"><path d="M16.49 2.672c.74.694.986 1.765.632 2.712l-.04.1-1.549 3.54h1.477a2.496 2.496 0 0 1 2.485 2.34l.005.163c0 .618-.23 1.21-.642 1.675l-7.147 7.961a2.48 2.48 0 0 1-3.554.165 2.512 2.512 0 0 1-.633-2.712l.042-.103L9.108 15H7.46c-1.393 0-2.379-1.11-2.455-2.369L5 12.473c0-.593.142-1.145.628-1.692l7.307-7.944a2.48 2.48 0 0 1 3.555-.165ZM14.43 4.164l-7.33 7.97c-.083.093-.101.214-.101.34 0 .277.19.526.46.526h4.163l.097-.009c.015 0 .03.003.046.009.181.078.264.32.186.5l-2.554 5.817a.512.512 0 0 0 .127.552.48.48 0 0 0 .69-.033l7.155-7.97a.513.513 0 0 0 .13-.34.497.497 0 0 0-.49-.502h-3.988a.355.355 0 0 1-.328-.497l2.555-5.844a.512.512 0 0 0-.127-.552.48.48 0 0 0-.69.033Z"/></symbol><symbol id="icon-eds-i-info-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm0 7a1 1 0 0 1 1 1v5h1.5a1 1 0 0 1 0 2h-5a1 1 0 0 1 0-2H11v-4h-.5a1 1 0 0 1-.993-.883L9.5 11a1 1 0 0 1 1-1H12Zm0-4.5a1.5 1.5 0 0 1 .144 2.993L12 8.5a1.5 1.5 0 0 1 0-3Z"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 9h-1.5a1 1 0 0 0-1 1l.007.117A1 1 0 0 0 10.5 12h.5v4H9.5a1 1 0 0 0 0 2h5a1 1 0 0 0 0-2H13v-5a1 1 0 0 0-1-1Zm0-4.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 5.5Z"/></symbol><symbol id="icon-eds-i-journal-medium" viewBox="0 0 24 24"><path d="M18.5 1A2.5 2.5 0 0 1 21 3.5v14a2.5 2.5 0 0 1-2.5 2.5h-13a.5.5 0 1 0 0 1H20a1 1 0 0 1 0 2H5.5A2.5 2.5 0 0 1 3 20.5v-17A2.5 2.5 0 0 1 5.5 1h13ZM7 3H5.5a.5.5 0 0 0-.5.5v14.549l.016-.002c.104-.02.211-.035.32-.042L5.5 18H7V3Zm11.5 0H9v15h9.5a.5.5 0 0 0 .5-.5v-14a.5.5 0 0 0-.5-.5ZM16 5a1 1 0 0 1 1 1v4a1 1 0 0 1-1 1h-5a1 1 0 0 1-1-1V6a1 1 0 0 1 1-1h5Zm-1 2h-3v2h3V7Z"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="M20.462 3C21.875 3 23 4.184 23 5.619v12.762C23 19.816 21.875 21 20.462 21H3.538C2.125 21 1 19.816 1 18.381V5.619C1 4.184 2.125 3 3.538 3h16.924ZM21 8.158l-7.378 6.258a2.549 2.549 0 0 1-3.253-.008L3 8.16v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619V8.158ZM20.462 5H3.538c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516Z"/></symbol><symbol id="icon-eds-i-mail-send-medium" viewBox="0 0 24 24"><path d="M20.444 5a2.562 2.562 0 0 1 2.548 2.37l.007.078.001.123v7.858A2.564 2.564 0 0 1 20.444 18H9.556A2.564 2.564 0 0 1 7 15.429l.001-7.977.007-.082A2.561 2.561 0 0 1 9.556 5h10.888ZM21 9.331l-5.46 3.51a1 1 0 0 1-1.08 0L9 9.332v6.097c0 .317.251.571.556.571h10.888a.564.564 0 0 0 .556-.571V9.33ZM20.444 7H9.556a.543.543 0 0 0-.32.105l5.763 3.706 5.766-3.706a.543.543 0 0 0-.32-.105ZM4.308 5a1 1 0 1 1 0 2H2a1 1 0 1 1 0-2h2.308Zm0 5.5a1 1 0 0 1 0 2H2a1 1 0 0 1 0-2h2.308Zm0 5.5a1 1 0 0 1 0 2H2a1 1 0 0 1 0-2h2.308Z"/></symbol><symbol id="icon-eds-i-mentions-medium" viewBox="0 0 24 24"><path d="m9.452 1.293 5.92 5.92 2.92-2.92a1 1 0 0 1 1.415 1.414l-2.92 2.92 5.92 5.92a1 1 0 0 1 0 1.415 10.371 10.371 0 0 1-10.378 2.584l.652 3.258A1 1 0 0 1 12 23H2a1 1 0 0 1-.874-1.486l4.789-8.62C4.194 9.074 4.9 4.43 8.038 1.292a1 1 0 0 1 1.414 0Zm-2.355 13.59L3.699 21h7.081l-.689-3.442a10.392 10.392 0 0 1-2.775-2.396l-.22-.28Zm1.69-11.427-.07.09a8.374 8.374 0 0 0 11.737 11.737l.089-.071L8.787 3.456Z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-metrics-medium" viewBox="0 0 24 24"><path d="M3 22a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v7h4V8a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v13a1 1 0 0 1-.883.993L21 22H3Zm17-2V9h-4v11h4Zm-6-8h-4v8h4v-8ZM8 4H4v16h4V4Z"/></symbol><symbol id="icon-eds-i-news-medium" viewBox="0 0 24 24"><path d="M17.384 3c.975 0 1.77.787 1.77 1.762v13.333c0 .462.354.846.815.899l.107.006.109-.006a.915.915 0 0 0 .809-.794l.006-.105V8.19a1 1 0 0 1 2 0v9.905A2.914 2.914 0 0 1 20.077 21H3.538a2.547 2.547 0 0 1-1.644-.601l-.147-.135A2.516 2.516 0 0 1 1 18.476V4.762C1 3.787 1.794 3 2.77 3h14.614Zm-.231 2H3v13.476c0 .11.035.216.1.304l.054.063c.101.1.24.157.384.157l13.761-.001-.026-.078a2.88 2.88 0 0 1-.115-.655l-.004-.17L17.153 5ZM14 15.021a.979.979 0 1 1 0 1.958H6a.979.979 0 1 1 0-1.958h8Zm0-8c.54 0 .979.438.979.979v4c0 .54-.438.979-.979.979H6A.979.979 0 0 1 5.021 12V8c0-.54.438-.979.979-.979h8Zm-.98 1.958H6.979v2.041h6.041V8.979Z"/></symbol><symbol id="icon-eds-i-newsletter-medium" viewBox="0 0 24 24"><path d="M21 10a1 1 0 0 1 1 1v9.5a2.5 2.5 0 0 1-2.5 2.5h-15A2.5 2.5 0 0 1 2 20.5V11a1 1 0 0 1 2 0v.439l8 4.888 8-4.889V11a1 1 0 0 1 1-1Zm-1 3.783-7.479 4.57a1 1 0 0 1-1.042 0l-7.48-4.57V20.5a.5.5 0 0 0 .501.5h15a.5.5 0 0 0 .5-.5v-6.717ZM15 9a1 1 0 0 1 0 2H9a1 1 0 0 1 0-2h6Zm2.5-8A2.5 2.5 0 0 1 20 3.5V9a1 1 0 0 1-2 0V3.5a.5.5 0 0 0-.5-.5h-11a.5.5 0 0 0-.5.5V9a1 1 0 1 1-2 0V3.5A2.5 2.5 0 0 1 6.5 1h11ZM15 5a1 1 0 0 1 0 2H9a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-notifcation-medium" viewBox="0 0 24 24"><path d="M14 20a1 1 0 0 1 0 2h-4a1 1 0 0 1 0-2h4ZM3 18l-.133-.007c-1.156-.124-1.156-1.862 0-1.986l.3-.012C4.32 15.923 5 15.107 5 14V9.5C5 5.368 8.014 2 12 2s7 3.368 7 7.5V14c0 1.107.68 1.923 1.832 1.995l.301.012c1.156.124 1.156 1.862 0 1.986L21 18H3Zm9-14C9.17 4 7 6.426 7 9.5V14c0 .671-.146 1.303-.416 1.858L6.51 16h10.979l-.073-.142a4.192 4.192 0 0 1-.412-1.658L17 14V9.5C17 6.426 14.83 4 12 4Z"/></symbol><symbol id="icon-eds-i-publish-medium" viewBox="0 0 24 24"><g><path d="M16.296 1.291A1 1 0 0 0 15.591 1H5.545A2.542 2.542 0 0 0 3 3.538V13a1 1 0 1 0 2 0V3.538l.007-.087A.543.543 0 0 1 5.545 3h9.633L20 7.8v12.662a.534.534 0 0 1-.158.379.548.548 0 0 1-.387.159H11a1 1 0 1 0 0 2h8.455c.674 0 1.32-.267 1.798-.742A2.534 2.534 0 0 0 22 20.462V7.385a1 1 0 0 0-.294-.709l-5.41-5.385Z"/><path d="M10.762 16.647a1 1 0 0 0-1.525-1.294l-4.472 5.271-2.153-1.665a1 1 0 1 0-1.224 1.582l2.91 2.25a1 1 0 0 0 1.374-.144l5.09-6ZM16 10a1 1 0 1 1 0 2H8a1 1 0 1 1 0-2h8ZM12 7a1 1 0 0 0-1-1H8a1 1 0 1 0 0 2h3a1 1 0 0 0 1-1Z"/></g></symbol><symbol id="icon-eds-i-refresh-medium" viewBox="0 0 24 24"><g><path d="M7.831 5.636H6.032A8.76 8.76 0 0 1 9 3.631 8.549 8.549 0 0 1 12.232 3c.603 0 1.192.063 1.76.182C17.979 4.017 21 7.632 21 12a1 1 0 1 0 2 0c0-5.296-3.674-9.746-8.591-10.776A10.61 10.61 0 0 0 5 3.851V2.805a1 1 0 0 0-.987-1H4a1 1 0 0 0-1 1v3.831a1 1 0 0 0 1 1h3.831a1 1 0 0 0 .013-2h-.013ZM17.968 18.364c-1.59 1.632-3.784 2.636-6.2 2.636C6.948 21 3 16.993 3 12a1 1 0 1 0-2 0c0 6.053 4.799 11 10.768 11 2.788 0 5.324-1.082 7.232-2.85v1.045a1 1 0 1 0 2 0v-3.831a1 1 0 0 0-1-1h-3.831a1 1 0 0 0 0 2h1.799Z"/></g></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-settings-medium" viewBox="0 0 24 24"><path d="M11.382 1h1.24a2.508 2.508 0 0 1 2.334 1.63l.523 1.378 1.59.933 1.444-.224c.954-.132 1.89.3 2.422 1.101l.095.155.598 1.066a2.56 2.56 0 0 1-.195 2.848l-.894 1.161v1.896l.92 1.163c.6.768.707 1.812.295 2.674l-.09.17-.606 1.08a2.504 2.504 0 0 1-2.531 1.25l-1.428-.223-1.589.932-.523 1.378a2.512 2.512 0 0 1-2.155 1.625L12.65 23h-1.27a2.508 2.508 0 0 1-2.334-1.63l-.524-1.379-1.59-.933-1.443.225c-.954.132-1.89-.3-2.422-1.101l-.095-.155-.598-1.066a2.56 2.56 0 0 1 .195-2.847l.891-1.161v-1.898l-.919-1.162a2.562 2.562 0 0 1-.295-2.674l.09-.17.606-1.08a2.504 2.504 0 0 1 2.531-1.25l1.43.223 1.618-.938.524-1.375.07-.167A2.507 2.507 0 0 1 11.382 1Zm.003 2a.509.509 0 0 0-.47.338l-.65 1.71a1 1 0 0 1-.434.51L7.6 6.85a1 1 0 0 1-.655.123l-1.762-.275a.497.497 0 0 0-.498.252l-.61 1.088a.562.562 0 0 0 .04.619l1.13 1.43a1 1 0 0 1 .216.62v2.585a1 1 0 0 1-.207.61L4.15 15.339a.568.568 0 0 0-.036.634l.601 1.072a.494.494 0 0 0 .484.26l1.78-.278a1 1 0 0 1 .66.126l2.2 1.292a1 1 0 0 1 .43.507l.648 1.71a.508.508 0 0 0 .467.338h1.263a.51.51 0 0 0 .47-.34l.65-1.708a1 1 0 0 1 .428-.507l2.201-1.292a1 1 0 0 1 .66-.126l1.763.275a.497.497 0 0 0 .498-.252l.61-1.088a.562.562 0 0 0-.04-.619l-1.13-1.43a1 1 0 0 1-.216-.62v-2.585a1 1 0 0 1 .207-.61l1.105-1.437a.568.568 0 0 0 .037-.634l-.601-1.072a.494.494 0 0 0-.484-.26l-1.78.278a1 1 0 0 1-.66-.126l-2.2-1.292a1 1 0 0 1-.43-.507l-.649-1.71A.508.508 0 0 0 12.62 3h-1.234ZM12 8a4 4 0 1 1 0 8 4 4 0 0 1 0-8Zm0 2a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"/></symbol><symbol id="icon-eds-i-shipping-medium" viewBox="0 0 24 24"><path d="M16.515 2c1.406 0 2.706.728 3.352 1.902l2.02 3.635.02.042.036.089.031.105.012.058.01.073.004.075v11.577c0 .64-.244 1.255-.683 1.713a2.356 2.356 0 0 1-1.701.731H4.386a2.356 2.356 0 0 1-1.702-.731 2.476 2.476 0 0 1-.683-1.713V7.948c.01-.217.083-.43.22-.6L4.2 3.905C4.833 2.755 6.089 2.032 7.486 2h9.029ZM20 9H4v10.556a.49.49 0 0 0 .075.26l.053.07a.356.356 0 0 0 .257.114h15.23c.094 0 .186-.04.258-.115a.477.477 0 0 0 .127-.33V9Zm-2 7.5a1 1 0 0 1 0 2h-4a1 1 0 0 1 0-2h4ZM16.514 4H13v3h6.3l-1.183-2.13c-.288-.522-.908-.87-1.603-.87ZM11 3.999H7.51c-.679.017-1.277.36-1.566.887L4.728 7H11V3.999Z"/></symbol><symbol id="icon-eds-i-step-guide-medium" viewBox="0 0 24 24"><path d="M11.394 9.447a1 1 0 1 0-1.788-.894l-.88 1.759-.019-.02a1 1 0 1 0-1.414 1.415l1 1a1 1 0 0 0 1.601-.26l1.5-3ZM12 11a1 1 0 0 1 1-1h3a1 1 0 1 1 0 2h-3a1 1 0 0 1-1-1ZM12 17a1 1 0 0 1 1-1h3a1 1 0 1 1 0 2h-3a1 1 0 0 1-1-1ZM10.947 14.105a1 1 0 0 1 .447 1.342l-1.5 3a1 1 0 0 1-1.601.26l-1-1a1 1 0 1 1 1.414-1.414l.02.019.879-1.76a1 1 0 0 1 1.341-.447Z"/><path d="M5.545 1A2.542 2.542 0 0 0 3 3.538v16.924A2.542 2.542 0 0 0 5.545 23h12.91A2.542 2.542 0 0 0 21 20.462V7.5a1 1 0 0 0-.293-.707l-5.5-5.5A1 1 0 0 0 14.5 1H5.545ZM5 3.538C5 3.245 5.24 3 5.545 3h8.54L19 7.914v12.547c0 .294-.24.539-.546.539H5.545A.542.542 0 0 1 5 20.462V3.538Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-submission-medium" viewBox="0 0 24 24"><g><path d="M5 3.538C5 3.245 5.24 3 5.545 3h9.633L20 7.8v12.662a.535.535 0 0 1-.158.379.549.549 0 0 1-.387.159H6a1 1 0 0 1-1-1v-2.5a1 1 0 1 0-2 0V20a3 3 0 0 0 3 3h13.455c.673 0 1.32-.266 1.798-.742A2.535 2.535 0 0 0 22 20.462V7.385a1 1 0 0 0-.294-.709l-5.41-5.385A1 1 0 0 0 15.591 1H5.545A2.542 2.542 0 0 0 3 3.538V7a1 1 0 0 0 2 0V3.538Z"/><path d="m13.707 13.707-4 4a1 1 0 0 1-1.414 0l-.083-.094a1 1 0 0 1 .083-1.32L10.585 14 2 14a1 1 0 1 1 0-2l8.583.001-2.29-2.294a1 1 0 0 1 1.414-1.414l4.037 4.04.043.05.043.06.059.098.03.063.031.085.03.113.017.122L14 13l-.004.087-.017.118-.013.056-.034.104-.049.105-.048.081-.07.093-.058.063Z"/></g></symbol><symbol id="icon-eds-i-table-1-medium" viewBox="0 0 24 24"><path d="M4.385 22a2.56 2.56 0 0 1-1.14-.279C2.485 21.341 2 20.614 2 19.615V4.385c0-.315.067-.716.279-1.14C2.659 2.485 3.386 2 4.385 2h15.23c.315 0 .716.067 1.14.279.76.38 1.245 1.107 1.245 2.106v15.23c0 .315-.067.716-.279 1.14-.38.76-1.107 1.245-2.106 1.245H4.385ZM4 19.615c0 .213.034.265.14.317a.71.71 0 0 0 .245.068H8v-4H4v3.615ZM20 16H10v4h9.615c.213 0 .265-.034.317-.14a.71.71 0 0 0 .068-.245V16Zm0-2v-4H10v4h10ZM4 14h4v-4H4v4ZM19.615 4H10v4h10V4.385c0-.213-.034-.265-.14-.317A.71.71 0 0 0 19.615 4ZM8 4H4.385l-.082.002c-.146.01-.19.047-.235.138A.71.71 0 0 0 4 4.385V8h4V4Z"/></symbol><symbol id="icon-eds-i-table-2-medium" viewBox="0 0 24 24"><path d="M4.384 22A2.384 2.384 0 0 1 2 19.616V4.384A2.384 2.384 0 0 1 4.384 2h15.232A2.384 2.384 0 0 1 22 4.384v15.232A2.384 2.384 0 0 1 19.616 22H4.384ZM10 15H4v4.616c0 .212.172.384.384.384H10v-5Zm5 0h-3v5h3v-5Zm5 0h-3v5h2.616a.384.384 0 0 0 .384-.384V15ZM10 9H4v4h6V9Zm5 0h-3v4h3V9Zm5 0h-3v4h3V9Zm-.384-5H4.384A.384.384 0 0 0 4 4.384V7h16V4.384A.384.384 0 0 0 19.616 4Z"/></symbol><symbol id="icon-eds-i-tag-medium" viewBox="0 0 24 24"><path d="m12.621 1.998.127.004L20.496 2a1.5 1.5 0 0 1 1.497 1.355L22 3.5l-.005 7.669c.038.456-.133.905-.447 1.206l-9.02 9.018a2.075 2.075 0 0 1-2.932 0l-6.99-6.99a2.075 2.075 0 0 1 .001-2.933L11.61 2.47c.246-.258.573-.418.881-.46l.131-.011Zm.286 2-8.885 8.886a.075.075 0 0 0 0 .106l6.987 6.988c.03.03.077.03.106 0l8.883-8.883L19.999 4l-7.092-.002ZM16 6.5a1.5 1.5 0 0 1 .144 2.993L16 9.5a1.5 1.5 0 0 1 0-3Z"/></symbol><symbol id="icon-eds-i-trash-medium" viewBox="0 0 24 24"><path d="M12 1c2.717 0 4.913 2.232 4.997 5H21a1 1 0 0 1 0 2h-1v12.5c0 1.389-1.152 2.5-2.556 2.5H6.556C5.152 23 4 21.889 4 20.5V8H3a1 1 0 1 1 0-2h4.003l.001-.051C7.114 3.205 9.3 1 12 1Zm6 7H6v12.5c0 .238.19.448.454.492l.102.008h10.888c.315 0 .556-.232.556-.5V8Zm-4 3a1 1 0 0 1 1 1v6.005a1 1 0 0 1-2 0V12a1 1 0 0 1 1-1Zm-4 0a1 1 0 0 1 1 1v6a1 1 0 0 1-2 0v-6a1 1 0 0 1 1-1Zm2-8c-1.595 0-2.914 1.32-2.996 3h5.991v-.02C14.903 4.31 13.589 3 12 3Z"/></symbol><symbol id="icon-eds-i-user-account-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 16c-1.806 0-3.52.994-4.664 2.698A8.947 8.947 0 0 0 12 21a8.958 8.958 0 0 0 4.664-1.301C15.52 17.994 13.806 17 12 17Zm0-14a9 9 0 0 0-6.25 15.476C7.253 16.304 9.54 15 12 15s4.747 1.304 6.25 3.475A9 9 0 0 0 12 3Zm0 3a4 4 0 1 1 0 8 4 4 0 0 1 0-8Zm0 2a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"/></symbol><symbol id="icon-eds-i-user-add-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm9 10a1 1 0 0 1 1 1v3h3a1 1 0 0 1 0 2h-3v3a1 1 0 0 1-2 0v-3h-3a1 1 0 0 1 0-2h3v-3a1 1 0 0 1 1-1Zm-5.545-.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378Z"/></symbol><symbol id="icon-eds-i-user-assign-medium" viewBox="0 0 24 24"><path d="M16.226 13.298a1 1 0 0 1 1.414-.01l.084.093a1 1 0 0 1-.073 1.32L15.39 17H22a1 1 0 0 1 0 2h-6.611l2.262 2.298a1 1 0 0 1-1.425 1.404l-3.939-4a1 1 0 0 1 0-1.404l3.94-4Zm-3.771-.449a1 1 0 1 1-.91 1.781 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 10.5 20a1 1 0 0 1 .993.883L11.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Z"/></symbol><symbol id="icon-eds-i-user-block-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm9 10a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm-5.545-.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM15 18a3 3 0 0 0 4.294 2.707l-4.001-4c-.188.391-.293.83-.293 1.293Zm3-3c-.463 0-.902.105-1.294.293l4.001 4A3 3 0 0 0 18 15Z"/></symbol><symbol id="icon-eds-i-user-check-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm13.647 12.237a1 1 0 0 1 .116 1.41l-5.091 6a1 1 0 0 1-1.375.144l-2.909-2.25a1 1 0 1 1 1.224-1.582l2.153 1.665 4.472-5.271a1 1 0 0 1 1.41-.116Zm-8.139-.977c.22.214.428.44.622.678a1 1 0 1 1-1.548 1.266 6.025 6.025 0 0 0-1.795-1.49.86.86 0 0 1-.163-.048l-.079-.036a5.721 5.721 0 0 0-2.62-.63l-.194.006c-2.76.134-5.022 2.177-5.592 4.864l-.035.175-.035.213c-.03.201-.05.405-.06.61L3.003 20 10 20a1 1 0 0 1 .993.883L11 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876l.005-.223.02-.356.02-.222.03-.248.022-.15c.02-.133.044-.265.071-.397.44-2.178 1.725-4.105 3.595-5.301a7.75 7.75 0 0 1 3.755-1.215l.12-.004a7.908 7.908 0 0 1 5.87 2.252Z"/></symbol><symbol id="icon-eds-i-user-delete-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6ZM4.763 13.227a7.713 7.713 0 0 1 7.692-.378 1 1 0 1 1-.91 1.781 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20H11.5a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897Zm11.421 1.543 2.554 2.553 2.555-2.553a1 1 0 0 1 1.414 1.414l-2.554 2.554 2.554 2.555a1 1 0 0 1-1.414 1.414l-2.555-2.554-2.554 2.554a1 1 0 0 1-1.414-1.414l2.553-2.555-2.553-2.554a1 1 0 0 1 1.414-1.414Z"/></symbol><symbol id="icon-eds-i-user-edit-medium" viewBox="0 0 24 24"><path d="m19.876 10.77 2.831 2.83a1 1 0 0 1 0 1.415l-7.246 7.246a1 1 0 0 1-.572.284l-3.277.446a1 1 0 0 1-1.125-1.13l.461-3.277a1 1 0 0 1 .283-.567l7.23-7.246a1 1 0 0 1 1.415-.001Zm-7.421 2.08a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 7.5 20a1 1 0 0 1 .993.883L8.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378Zm6.715.042-6.29 6.3-.23 1.639 1.633-.222 6.302-6.302-1.415-1.415ZM9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Z"/></symbol><symbol id="icon-eds-i-user-linked-medium" viewBox="0 0 24 24"><path d="M15.65 6c.31 0 .706.066 1.122.274C17.522 6.65 18 7.366 18 8.35v12.3c0 .31-.066.706-.274 1.122-.375.75-1.092 1.228-2.076 1.228H3.35a2.52 2.52 0 0 1-1.122-.274C1.478 22.35 1 21.634 1 20.65V8.35c0-.31.066-.706.274-1.122C1.65 6.478 2.366 6 3.35 6h12.3Zm0 2-12.376.002c-.134.007-.17.04-.21.12A.672.672 0 0 0 3 8.35v12.3c0 .198.028.24.122.287.09.044.2.063.228.063h.887c.788-2.269 2.814-3.5 5.263-3.5 2.45 0 4.475 1.231 5.263 3.5h.887c.198 0 .24-.028.287-.122.044-.09.063-.2.063-.228V8.35c0-.198-.028-.24-.122-.287A.672.672 0 0 0 15.65 8ZM9.5 19.5c-1.36 0-2.447.51-3.06 1.5h6.12c-.613-.99-1.7-1.5-3.06-1.5ZM20.65 1A2.35 2.35 0 0 1 23 3.348V15.65A2.35 2.35 0 0 1 20.65 18H20a1 1 0 0 1 0-2h.65a.35.35 0 0 0 .35-.35V3.348A.35.35 0 0 0 20.65 3H8.35a.35.35 0 0 0-.35.348V4a1 1 0 1 1-2 0v-.652A2.35 2.35 0 0 1 8.35 1h12.3ZM9.5 10a3.5 3.5 0 1 1 0 7 3.5 3.5 0 0 1 0-7Zm0 2a1.5 1.5 0 1 0 0 3 1.5 1.5 0 0 0 0-3Z"/></symbol><symbol id="icon-eds-i-user-multiple-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm6 0a5 5 0 0 1 0 10 1 1 0 0 1-.117-1.993L15 9a3 3 0 0 0 0-6 1 1 0 0 1 0-2ZM9 3a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm8.857 9.545a7.99 7.99 0 0 1 2.651 1.715A8.31 8.31 0 0 1 23 20.134V21a1 1 0 0 1-1 1h-3a1 1 0 0 1 0-2h1.995l-.005-.153a6.307 6.307 0 0 0-1.673-3.945l-.204-.209a5.99 5.99 0 0 0-1.988-1.287 1 1 0 1 1 .732-1.861Zm-3.349 1.715A8.31 8.31 0 0 1 17 20.134V21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.877c.044-4.343 3.387-7.908 7.638-8.115a7.908 7.908 0 0 1 5.87 2.252ZM9.016 14l-.285.006c-3.104.15-5.58 2.718-5.725 5.9L3.004 20h11.991l-.005-.153a6.307 6.307 0 0 0-1.673-3.945l-.204-.209A5.924 5.924 0 0 0 9.3 14.008L9.016 14Z"/></symbol><symbol id="icon-eds-i-user-notify-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm10 18v1a1 1 0 0 1-2 0v-1h-3a1 1 0 0 1 0-2v-2.818C14 13.885 15.777 12 18 12s4 1.885 4 4.182V19a1 1 0 0 1 0 2h-3Zm-6.545-8.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM18 14c-1.091 0-2 .964-2 2.182V19h4v-2.818c0-1.165-.832-2.098-1.859-2.177L18 14Z"/></symbol><symbol id="icon-eds-i-user-remove-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm3.455 9.85a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM22 17a1 1 0 0 1 0 2h-8a1 1 0 0 1 0-2h8Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm0 11.5a1.5 1.5 0 0 1 .144 2.993L12 17.5a1.5 1.5 0 0 1 0-3ZM12 6a1 1 0 0 1 1 1v5a1 1 0 0 1-2 0V7a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 13.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 14.5ZM12 6a1 1 0 0 0-1 1v5a1 1 0 0 0 2 0V7a1 1 0 0 0-1-1Z"/></symbol><symbol id="icon-ai" viewBox="-4.807 394.815 109.546 109.923"><g transform="translate(-1321.07 -292.074) scale(2.96829)"><a><path stroke="url(#a)" stroke-width="2" d="m469.451 241.994-4.593-7.217c-1.376-2.161-4.53-2.161-5.906 0l-4.593 7.217a1.507 1.507 0 0 1-.46.46l-7.217 4.593c-2.141 1.534-2.084 4.397 0 5.906l7.217 4.593c.185.118.342.275.46.46l4.593 7.217c1.376 2.161 4.438 2.119 5.906 0l4.593-7.217c.116-.19.275-.342.46-.46l7.217-4.593c2.166-1.451 2.161-4.53 0-5.906l-7.217-4.593a1.507 1.507 0 0 1-.46-.46Z" style="transform-origin:461.906px 249.992px"/><path d="m468.608 242.533-4.302-6.801c-1.258-2.183-3.581-2.168-4.729-.124l-4.463 7.013a2.187 2.187 0 0 1-.489.53l-6.748 4.303c-2.467 1.36-2.325 3.704-.132 5.031l6.831 4.385c.174.113.472.357.582.557l4.356 6.858c1.251 2.333 3.693 2.026 4.894-.205l4.375-6.854c.15-.205.513-.477.705-.596l6.703-4.26c2.288-1.321 2.176-3.548.038-4.714l-6.836-4.347a2.584 2.584 0 0 1-.647-.577" style="stroke-width:0;paint-order:stroke;transform-origin:461.906px 249.992px;fill:#f0f7fc"/></a><g style="transform-origin:461.359px 249.886px"><path fill-rule="evenodd" d="M456.406 254.106h2.145l.43-1.529h2.844l.455 1.53h2.167l-2.87-8.229h-2.322l-2.849 8.228Zm4.994-2.959-.759-2.552-.264-1.067-.275 1.067-.718 2.552h2.016Z" clip-rule="evenodd"/><path d="M465.337 245.932v8.173h2.068v-8.173h-2.068Z"/></g></g></symbol><symbol id="icon-chevron-left-medium" viewBox="0 0 24 24"><path d="M15.7194 3.3054C15.3358 2.90809 14.7027 2.89699 14.3054 3.28061L6.54342 10.7757C6.19804 11.09 6 11.5335 6 12C6 12.4665 6.19804 12.91 6.5218 13.204L14.3054 20.7194C14.7027 21.103 15.3358 21.0919 15.7194 20.6946C16.103 20.2973 16.0919 19.6642 15.6946 19.2806L8.155 12L15.6946 4.71939C16.0614 4.36528 16.099 3.79863 15.8009 3.40105L15.7194 3.3054Z"/></symbol><symbol id="icon-chevron-right-medium" viewBox="0 0 24 24"><path d="M8.28061 3.3054C8.66423 2.90809 9.29729 2.89699 9.6946 3.28061L17.4566 10.7757C17.802 11.09 18 11.5335 18 12C18 12.4665 17.802 12.91 17.4782 13.204L9.6946 20.7194C9.29729 21.103 8.66423 21.0919 8.28061 20.6946C7.89699 20.2973 7.90809 19.6642 8.3054 19.2806L15.845 12L8.3054 4.71939C7.93865 4.36528 7.90098 3.79863 8.19908 3.40105L8.28061 3.3054Z"/></symbol><symbol id="icon-eds-alerts" viewBox="0 0 32 32"><path d="M28 12.667c.736 0 1.333.597 1.333 1.333v13.333A3.333 3.333 0 0 1 26 30.667H6a3.333 3.333 0 0 1-3.333-3.334V14a1.333 1.333 0 1 1 2.666 0v1.252L16 21.769l10.667-6.518V14c0-.736.597-1.333 1.333-1.333Zm-1.333 5.71-9.972 6.094c-.427.26-.963.26-1.39 0l-9.972-6.094v8.956c0 .368.299.667.667.667h20a.667.667 0 0 0 .667-.667v-8.956ZM19.333 12a1.333 1.333 0 1 1 0 2.667h-6.666a1.333 1.333 0 1 1 0-2.667h6.666Zm4-10.667a3.333 3.333 0 0 1 3.334 3.334v6.666a1.333 1.333 0 1 1-2.667 0V4.667A.667.667 0 0 0 23.333 4H8.667A.667.667 0 0 0 8 4.667v6.666a1.333 1.333 0 1 1-2.667 0V4.667a3.333 3.333 0 0 1 3.334-3.334h14.666Zm-4 5.334a1.333 1.333 0 0 1 0 2.666h-6.666a1.333 1.333 0 1 1 0-2.666h6.666Z"/></symbol><symbol id="icon-eds-arrow-up" viewBox="0 0 24 24"><path fill-rule="evenodd" d="m13.002 7.408 4.88 4.88a.99.99 0 0 0 1.32.08l.09-.08c.39-.39.39-1.03 0-1.42l-6.58-6.58a1.01 1.01 0 0 0-1.42 0l-6.58 6.58a1 1 0 0 0-.09 1.32l.08.1a1 1 0 0 0 1.42-.01l4.88-4.87v11.59a.99.99 0 0 0 .88.99l.12.01c.55 0 1-.45 1-1V7.408z" class="layer"/></symbol><symbol id="icon-eds-checklist" viewBox="0 0 32 32"><path d="M19.2 1.333a3.468 3.468 0 0 1 3.381 2.699L24.667 4C26.515 4 28 5.52 28 7.38v19.906c0 1.86-1.485 3.38-3.333 3.38H7.333c-1.848 0-3.333-1.52-3.333-3.38V7.38C4 5.52 5.485 4 7.333 4h2.093A3.468 3.468 0 0 1 12.8 1.333h6.4ZM9.426 6.667H7.333c-.36 0-.666.312-.666.713v19.906c0 .401.305.714.666.714h17.334c.36 0 .666-.313.666-.714V7.38c0-.4-.305-.713-.646-.714l-2.121.033A3.468 3.468 0 0 1 19.2 9.333h-6.4a3.468 3.468 0 0 1-3.374-2.666Zm12.715 5.606c.586.446.7 1.283.253 1.868l-7.111 9.334a1.333 1.333 0 0 1-1.792.306l-3.556-2.333a1.333 1.333 0 1 1 1.463-2.23l2.517 1.651 6.358-8.344a1.333 1.333 0 0 1 1.868-.252ZM19.2 4h-6.4a.8.8 0 0 0-.8.8v1.067a.8.8 0 0 0 .8.8h6.4a.8.8 0 0 0 .8-.8V4.8a.8.8 0 0 0-.8-.8Z"/></symbol><symbol id="icon-eds-citation" viewBox="0 0 36 36"><path d="M23.25 1.5a1.5 1.5 0 0 1 1.06.44l8.25 8.25a1.5 1.5 0 0 1 .44 1.06v19.5c0 2.105-1.645 3.75-3.75 3.75H18a1.5 1.5 0 0 1 0-3h11.25c.448 0 .75-.302.75-.75V11.873L22.628 4.5H8.31a.811.811 0 0 0-.8.68l-.011.13V16.5a1.5 1.5 0 0 1-3 0V5.31A3.81 3.81 0 0 1 8.31 1.5h14.94ZM8.223 20.358a.984.984 0 0 1-.192 1.378l-.048.034c-.54.36-.942.676-1.206.951-.59.614-.885 1.395-.885 2.343.115-.028.288-.042.518-.042.662 0 1.26.237 1.791.711.533.474.799 1.074.799 1.799 0 .753-.259 1.352-.777 1.799-.518.446-1.151.669-1.9.669-1.006 0-1.812-.293-2.417-.878C3.302 28.536 3 27.657 3 26.486c0-1.115.165-2.085.496-2.907.331-.823.734-1.513 1.209-2.071.475-.558.971-.997 1.49-1.318a6.01 6.01 0 0 1 .347-.2 1.321 1.321 0 0 1 1.681.368Zm7.5 0a.984.984 0 0 1-.192 1.378l-.048.034c-.54.36-.942.676-1.206.951-.59.614-.885 1.395-.885 2.343.115-.028.288-.042.518-.042.662 0 1.26.237 1.791.711.533.474.799 1.074.799 1.799 0 .753-.259 1.352-.777 1.799-.518.446-1.151.669-1.9.669-1.006 0-1.812-.293-2.417-.878-.604-.586-.906-1.465-.906-2.636 0-1.115.165-2.085.496-2.907.331-.823.734-1.513 1.209-2.071.475-.558.971-.997 1.49-1.318a6.01 6.01 0 0 1 .347-.2 1.321 1.321 0 0 1 1.681.368Z"/></symbol><symbol id="icon-eds-i-access-indicator" viewBox="0 0 16 16"><circle cx="4.5" cy="11.5" r="3.5" style="fill:currentColor"/><path fill-rule="evenodd" d="M4 3v3a1 1 0 0 1-2 0V2.923C2 1.875 2.84 1 3.909 1h5.909a1 1 0 0 1 .713.298l3.181 3.231a1 1 0 0 1 .288.702v7.846c0 .505-.197.993-.554 1.354a1.902 1.902 0 0 1-1.355.569H10a1 1 0 1 1 0-2h2V5.64L9.4 3H4Z" clip-rule="evenodd" style="fill:#222"/></symbol><symbol id="icon-eds-i-copy-link" viewBox="0 0 24 24"><path fill-rule="evenodd" clip-rule="evenodd" d="M19.4594 8.57015C19.0689 8.17963 19.0689 7.54646 19.4594 7.15594L20.2927 6.32261C20.2927 6.32261 20.2927 6.32261 20.2927 6.32261C21.0528 5.56252 21.0528 4.33019 20.2928 3.57014C19.5327 2.81007 18.3004 2.81007 17.5404 3.57014L16.7071 4.40347C16.3165 4.794 15.6834 4.794 15.2928 4.40348C14.9023 4.01296 14.9023 3.3798 15.2928 2.98927L16.1262 2.15594C17.6673 0.614803 20.1659 0.614803 21.707 2.15593C23.2481 3.69705 23.248 6.19569 21.707 7.7368L20.8737 8.57014C20.4831 8.96067 19.85 8.96067 19.4594 8.57015Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M18.0944 5.90592C18.4849 6.29643 18.4849 6.9296 18.0944 7.32013L16.4278 8.9868C16.0373 9.37733 15.4041 9.37734 15.0136 8.98682C14.6231 8.59631 14.6231 7.96314 15.0136 7.57261L16.6802 5.90594C17.0707 5.51541 17.7039 5.5154 18.0944 5.90592Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5113 6.32243C13.9018 6.71295 13.9018 7.34611 13.5113 7.73664L12.678 8.56997C12.678 8.56997 12.678 8.56997 12.678 8.56997C11.9179 9.33006 11.9179 10.5624 12.6779 11.3224C13.438 12.0825 14.6703 12.0825 15.4303 11.3224L16.2636 10.4891C16.6542 10.0986 17.2873 10.0986 17.6779 10.4891C18.0684 10.8796 18.0684 11.5128 17.6779 11.9033L16.8445 12.7366C15.3034 14.2778 12.8048 14.2778 11.2637 12.7366C9.72262 11.1955 9.72266 8.69689 11.2637 7.15578L12.097 6.32244C12.4876 5.93191 13.1207 5.93191 13.5113 6.32243Z"/><path d="M8 20V22H19.4619C20.136 22 20.7822 21.7311 21.2582 21.2529C21.7333 20.7757 22 20.1289 22 19.4549V15C22 14.4477 21.5523 14 21 14C20.4477 14 20 14.4477 20 15V19.4549C20 19.6004 19.9426 19.7397 19.8408 19.842C19.7399 19.9433 19.6037 20 19.4619 20H8Z"/><path d="M4 13H2V19.4619C2 20.136 2.26889 20.7822 2.74705 21.2582C3.22434 21.7333 3.87105 22 4.5451 22H9C9.55228 22 10 21.5523 10 21C10 20.4477 9.55228 20 9 20H4.5451C4.39957 20 4.26028 19.9426 4.15804 19.8408C4.05668 19.7399 4 19.6037 4 19.4619V13Z"/><path d="M4 13H2V4.53808C2 3.86398 2.26889 3.21777 2.74705 2.74178C3.22434 2.26666 3.87105 2 4.5451 2H9C9.55228 2 10 2.44772 10 3C10 3.55228 9.55228 4 9 4H4.5451C4.39957 4 4.26028 4.05743 4.15804 4.15921C4.05668 4.26011 4 4.39633 4 4.53808V13Z"/></symbol><symbol id="icon-eds-i-github-medium" viewBox="0 0 24 24"><path d="M 11.964844 0 C 5.347656 0 0 5.269531 0 11.792969 C 0 17.003906 3.425781 21.417969 8.179688 22.976562 C 8.773438 23.09375 8.992188 22.722656 8.992188 22.410156 C 8.992188 22.136719 8.972656 21.203125 8.972656 20.226562 C 5.644531 20.929688 4.953125 18.820312 4.953125 18.820312 C 4.417969 17.453125 3.625 17.101562 3.625 17.101562 C 2.535156 16.378906 3.703125 16.378906 3.703125 16.378906 C 4.914062 16.457031 5.546875 17.589844 5.546875 17.589844 C 6.617188 19.386719 8.339844 18.878906 9.03125 18.566406 C 9.132812 17.804688 9.449219 17.277344 9.785156 16.984375 C 7.132812 16.710938 4.339844 15.695312 4.339844 11.167969 C 4.339844 9.878906 4.8125 8.824219 5.566406 8.003906 C 5.445312 7.710938 5.03125 6.5 5.683594 4.878906 C 5.683594 4.878906 6.695312 4.566406 8.972656 6.089844 C 9.949219 5.832031 10.953125 5.703125 11.964844 5.699219 C 12.972656 5.699219 14.003906 5.835938 14.957031 6.089844 C 17.234375 4.566406 18.242188 4.878906 18.242188 4.878906 C 18.898438 6.5 18.480469 7.710938 18.363281 8.003906 C 19.136719 8.824219 19.589844 9.878906 19.589844 11.167969 C 19.589844 15.695312 16.796875 16.691406 14.125 16.984375 C 14.558594 17.355469 14.933594 18.058594 14.933594 19.171875 C 14.933594 20.753906 14.914062 22.019531 14.914062 22.410156 C 14.914062 22.722656 15.132812 23.09375 15.726562 22.976562 C 20.480469 21.414062 23.910156 17.003906 23.910156 11.792969 C 23.929688 5.269531 18.558594 0 11.964844 0 Z M 11.964844 0 "/></symbol><symbol id="icon-eds-i-institution-medium" viewBox="0 0 24 24"><g><path fill-rule="evenodd" clip-rule="evenodd" d="M11.9967 1C11.6364 1 11.279 1.0898 10.961 1.2646C10.9318 1.28061 10.9035 1.29806 10.8761 1.31689L2.79765 6.87C2.46776 7.08001 2.20618 7.38466 2.07836 7.76668C1.94823 8.15561 1.98027 8.55648 2.12665 8.90067C2.42086 9.59246 3.12798 10 3.90107 10H4.99994V16H4.49994C3.11923 16 1.99994 17.1193 1.99994 18.5V19.5C1.99994 20.8807 3.11923 22 4.49994 22H19.4999C20.8807 22 21.9999 20.8807 21.9999 19.5V18.5C21.9999 17.1193 20.8807 16 19.4999 16H18.9999V10H20.0922C20.8653 10 21.5725 9.59252 21.8667 8.90065C22.0131 8.55642 22.0451 8.15553 21.9149 7.7666C21.7871 7.38459 21.5255 7.07997 21.1956 6.86998L13.1172 1.31689C13.0898 1.29806 13.0615 1.28061 13.0324 1.2646C12.7143 1.0898 12.357 1 11.9967 1ZM4.6844 8L11.9472 3.00755C11.9616 3.00295 11.9783 3 11.9967 3C12.015 3 12.0318 3.00295 12.0461 3.00755L19.3089 8H4.6844ZM16.9999 16V10H14.9999V16H16.9999ZM12.9999 16V10H10.9999V16H12.9999ZM8.99994 16V10H6.99994V16H8.99994ZM3.99994 18.5C3.99994 18.2239 4.2238 18 4.49994 18H19.4999C19.7761 18 19.9999 18.2239 19.9999 18.5V19.5C19.9999 19.7761 19.7761 20 19.4999 20H4.49994C4.2238 20 3.99994 19.7761 3.99994 19.5V18.5Z"/></g></symbol><symbol id="icon-eds-i-limited-access" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 3v3a1 1 0 0 1-2 0V2.923C2 1.875 2.84 1 3.909 1h5.909a1 1 0 0 1 .713.298l3.181 3.231a1 1 0 0 1 .288.702V6a1 1 0 1 1-2 0v-.36L9.4 3H4ZM3 8a1 1 0 0 1 1 1v1a1 1 0 1 1-2 0V9a1 1 0 0 1 1-1Zm10 0a1 1 0 0 1 1 1v1a1 1 0 1 1-2 0V9a1 1 0 0 1 1-1Zm-3.5 6a1 1 0 0 1-1 1h-1a1 1 0 1 1 0-2h1a1 1 0 0 1 1 1Zm2.441-1a1 1 0 0 1 2 0c0 .73-.246 1.306-.706 1.664a1.61 1.61 0 0 1-.876.334l-.032.002H11.5a1 1 0 1 1 0-2h.441ZM4 13a1 1 0 0 0-2 0c0 .73.247 1.306.706 1.664a1.609 1.609 0 0 0 .876.334l.032.002H4.5a1 1 0 1 0 0-2H4Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-rss" viewBox="0 0 22 22"><path d="M1.96094 1C1.96094 0.447715 2.40865 0 2.96094 0C5.46109 0 7.93678 0.492038 10.2467 1.44806C12.5565 2.40407 14.6554 3.80534 16.4234 5.57189C18.1913 7.33843 19.5939 9.4357 20.5508 11.744C21.5077 14.0522 22.0001 16.5263 22.0001 19.0247C22.0001 19.577 21.5524 20.0247 21.0001 20.0247C20.4478 20.0247 20.0001 19.577 20.0001 19.0247C20.0001 16.7891 19.5595 14.5753 18.7033 12.5098C17.8471 10.4444 16.5919 8.56762 15.0097 6.98666C13.4275 5.40575 11.5492 4.15167 9.48182 3.29604C7.41447 2.4404 5.19868 2 2.96094 2C2.40865 2 1.96094 1.55228 1.96094 1Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M0 18.649C0 16.7974 1.50196 15.298 3.35294 15.298C5.20392 15.298 6.70588 16.7974 6.70588 18.649C6.70588 20.5003 5.20397 22 3.35294 22C1.50191 22 0 20.5003 0 18.649ZM3.35294 17.298C2.60493 17.298 2 17.9036 2 18.649C2 19.3943 2.60498 20 3.35294 20C4.1009 20 4.70588 19.3943 4.70588 18.649C4.70588 17.9036 4.10095 17.298 3.35294 17.298Z"/><path d="M3.3374 7.46115C2.78512 7.46115 2.3374 7.90887 2.3374 8.46115C2.3374 9.01344 2.78512 9.46115 3.3374 9.46115C4.54515 9.46115 5.74107 9.69885 6.85684 10.1606C7.97262 10.6224 8.98639 11.2993 9.84028 12.1525C10.6942 13.0057 11.3715 14.0185 11.8336 15.1332C12.2956 16.2478 12.5335 17.4424 12.5335 18.649C12.5335 19.2013 12.9812 19.649 13.5335 19.649C14.0858 19.649 14.5335 19.2013 14.5335 18.649C14.5335 17.1796 14.2438 15.7247 13.6811 14.3673C13.1184 13.0099 12.2936 11.7765 11.2539 10.7377C10.2142 9.69885 8.97999 8.87484 7.62168 8.31266C6.26337 7.75049 4.80757 7.46115 3.3374 7.46115Z"/></symbol><symbol id="icon-eds-i-search-category-medium" viewBox="0 0 32 32"><path fill-rule="evenodd" d="M2 5.306A3.306 3.306 0 0 1 5.306 2h5.833a3.306 3.306 0 0 1 3.306 3.306v5.833a3.306 3.306 0 0 1-3.306 3.305H5.306A3.306 3.306 0 0 1 2 11.14V5.306Zm3.306-.584a.583.583 0 0 0-.584.584v5.833c0 .322.261.583.584.583h5.833a.583.583 0 0 0 .583-.583V5.306a.583.583 0 0 0-.583-.584H5.306Zm15.555 8.945a7.194 7.194 0 1 0 4.034 13.153l2.781 2.781a1.361 1.361 0 1 0 1.925-1.925l-2.781-2.781a7.194 7.194 0 0 0-5.958-11.228Zm3.173 10.346a4.472 4.472 0 1 0-.021.021l.01-.01.011-.011Zm-5.117-19.29a.583.583 0 0 0-.584.583v5.833a1.361 1.361 0 0 1-2.722 0V5.306A3.306 3.306 0 0 1 18.917 2h5.833a3.306 3.306 0 0 1 3.306 3.306v5.833c0 .6-.161 1.166-.443 1.654a1.361 1.361 0 1 1-2.357-1.363.575.575 0 0 0 .078-.291V5.306a.583.583 0 0 0-.584-.584h-5.833ZM2 18.916a3.306 3.306 0 0 1 3.306-3.306h5.833a1.361 1.361 0 1 1 0 2.722H5.306a.583.583 0 0 0-.584.584v5.833c0 .322.261.583.584.583h5.833a.574.574 0 0 0 .29-.077 1.361 1.361 0 1 1 1.364 2.356 3.296 3.296 0 0 1-1.654.444H5.306A3.306 3.306 0 0 1 2 24.75v-5.833Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-subjects-medium" viewBox="0 0 24 24"><g id="icon-subjects-copy" stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.3846154,2 C14.7015971,2 15.7692308,3.06762994 15.7692308,4.38461538 L15.7692308,7.15384615 C15.7692308,8.47082629 14.7015955,9.53846154 13.3846154,9.53846154 L13.1038388,9.53925278 C13.2061091,9.85347965 13.3815528,10.1423885 13.6195822,10.3804178 C13.9722182,10.7330539 14.436524,10.9483278 14.9293854,10.9918129 L15.1153846,11 C16.2068332,11 17.2535347,11.433562 18.0254647,12.2054189 C18.6411944,12.8212361 19.0416785,13.6120766 19.1784166,14.4609738 L19.6153846,14.4615385 C20.932386,14.4615385 22,15.5291672 22,16.8461538 L22,19.6153846 C22,20.9323924 20.9323924,22 19.6153846,22 L16.8461538,22 C15.5291672,22 14.4615385,20.932386 14.4615385,19.6153846 L14.4615385,16.8461538 C14.4615385,15.5291737 15.5291737,14.4615385 16.8461538,14.4615385 L17.126925,14.460779 C17.0246537,14.1465537 16.8492179,13.857633 16.6112344,13.6196157 C16.2144418,13.2228606 15.6764136,13 15.1153846,13 C14.0239122,13 12.9771569,12.5664197 12.2053686,11.7946314 C12.1335167,11.7227795 12.0645962,11.6485444 11.9986839,11.5721119 C11.9354038,11.6485444 11.8664833,11.7227795 11.7946314,11.7946314 C11.0228431,12.5664197 9.97608778,13 8.88461538,13 C8.323576,13 7.78552852,13.2228666 7.38881294,13.6195822 C7.15078359,13.8576115 6.97533988,14.1465203 6.8730696,14.4607472 L7.15384615,14.4615385 C8.47082629,14.4615385 9.53846154,15.5291737 9.53846154,16.8461538 L9.53846154,19.6153846 C9.53846154,20.932386 8.47083276,22 7.15384615,22 L4.38461538,22 C3.06762347,22 2,20.9323876 2,19.6153846 L2,16.8461538 C2,15.5291721 3.06762994,14.4615385 4.38461538,14.4615385 L4.8215823,14.4609378 C4.95831893,13.6120029 5.3588057,12.8211623 5.97459937,12.2053686 C6.69125996,11.488708 7.64500941,11.0636656 8.6514968,11.0066017 L8.88461538,11 C9.44565477,11 9.98370225,10.7771334 10.3804178,10.3804178 C10.6184472,10.1423885 10.7938909,9.85347965 10.8961612,9.53925278 L10.6153846,9.53846154 C9.29840448,9.53846154 8.23076923,8.47082629 8.23076923,7.15384615 L8.23076923,4.38461538 C8.23076923,3.06762994 9.29840286,2 10.6153846,2 L13.3846154,2 Z M7.15384615,16.4615385 L4.38461538,16.4615385 C4.17220099,16.4615385 4,16.63374 4,16.8461538 L4,19.6153846 C4,19.8278134 4.17218833,20 4.38461538,20 L7.15384615,20 C7.36626945,20 7.53846154,19.8278103 7.53846154,19.6153846 L7.53846154,16.8461538 C7.53846154,16.6337432 7.36625679,16.4615385 7.15384615,16.4615385 Z M19.6153846,16.4615385 L16.8461538,16.4615385 C16.6337432,16.4615385 16.4615385,16.6337432 16.4615385,16.8461538 L16.4615385,19.6153846 C16.4615385,19.8278103 16.6337306,20 16.8461538,20 L19.6153846,20 C19.8278229,20 20,19.8278229 20,19.6153846 L20,16.8461538 C20,16.6337306 19.8278103,16.4615385 19.6153846,16.4615385 Z M13.3846154,4 L10.6153846,4 C10.4029708,4 10.2307692,4.17220099 10.2307692,4.38461538 L10.2307692,7.15384615 C10.2307692,7.36625679 10.402974,7.53846154 10.6153846,7.53846154 L13.3846154,7.53846154 C13.597026,7.53846154 13.7692308,7.36625679 13.7692308,7.15384615 L13.7692308,4.38461538 C13.7692308,4.17220099 13.5970292,4 13.3846154,4 Z" id="Shape" fill-rule="nonzero"/></g></symbol><symbol id="icon-eds-small-arrow-left" viewBox="0 0 16 17"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14 8.092H2m0 0L8 2M2 8.092l6 6.035"/></symbol><symbol id="icon-eds-small-arrow-right" viewBox="0 0 16 16"><g fill-rule="evenodd" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M2 8.092h12M8 2l6 6.092M8 14.127l6-6.035"/></g></symbol><symbol id="icon-orcid-logo" viewBox="0 0 40 40"><path fill-rule="evenodd" d="M12.281 10.453c.875 0 1.578-.719 1.578-1.578 0-.86-.703-1.578-1.578-1.578-.875 0-1.578.703-1.578 1.578 0 .86.703 1.578 1.578 1.578Zm-1.203 18.641h2.406V12.359h-2.406v16.735Z"/><path fill-rule="evenodd" d="M17.016 12.36h6.5c6.187 0 8.906 4.421 8.906 8.374 0 4.297-3.36 8.375-8.875 8.375h-6.531V12.36Zm6.234 14.578h-3.828V14.53h3.703c4.688 0 6.828 2.844 6.828 6.203 0 2.063-1.25 6.203-6.703 6.203Z" clip-rule="evenodd"/></symbol></svg>
</div>


        

        
        
    <a class="c-skip-link" href="#main">Skip to main content</a>

    

    <header class="eds-c-header" data-eds-c-header>
    <div class="eds-c-header__container" data-eds-c-header-expander-anchor>
        <div class="eds-c-header__brand">
            
                
                    <a href="https://link.springer.com"
                    	 data-test=springerlink-logo
                        
                            data-track="click_imprint_logo"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click logo link"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        <img src="/oscar-static/images/darwin/header/img/logo-springer-nature-link-3149409f62.svg" alt="Springer Nature Link">
                    </a>
                
            
        </div>

        
            
                
    
        <a class="c-header__link eds-c-header__link" id="identity-account-widget" data-track="click_login" data-track-context="header" href='https://idp.springer.com/auth/personal/springernature?redirect_uri=https://link.springer.com/article/10.1007/s11263-024-02033-7'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
    


            
        
    </div>

    
        <nav class="eds-c-header__nav" aria-label="header navigation">
            <div class="eds-c-header__nav-container">
                <div class="eds-c-header__item eds-c-header__item--menu">
                   <a href="#eds-c-header-nav" class="eds-c-header__link" data-eds-c-header-expander>
                        <svg class="eds-c-header__icon" width="24" height="24" aria-hidden="true" focusable="false">
                            <use xlink:href="#icon-eds-i-menu-medium"></use>
                        </svg><span>Menu</span>
                    </a>
                </div>

                <div class="eds-c-header__item eds-c-header__item--inline-links">
                    
                        <a class="eds-c-header__link" href="https://link.springer.com/journals/"
                            
                                data-track="nav_find_a_journal"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click find a journal"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Find a journal
                        </a>
                    
                        <a class="eds-c-header__link" href="https://www.springernature.com/gp/authors"
                            
                                data-track="nav_how_to_publish"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click publish with us link"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Publish with us
                        </a>
                    
                        <a class="eds-c-header__link" href="https://link.springernature.com/home/"
                            
                                data-track="nav_track_your_research"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click track your research"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Track your research
                        </a>
                    
                </div>

                <div class="eds-c-header__link-container">
                    
                        <div class="eds-c-header__item eds-c-header__item--divider">
                            <a href="#eds-c-header-popup-search" class="eds-c-header__link" data-eds-c-header-expander data-eds-c-header-test-search-btn>
                                <svg class="eds-c-header__icon" width="24" height="24" aria-hidden="true" focusable="false">
                                    <use xlink:href="#icon-eds-i-search-medium"></use>
                                </svg><span>Search</span>
                            </a>
                        </div>
                    
                    
                        <div id="ecommerce-header-cart-icon-link" class="eds-c-header__item ecommerce-cart" style="display:inline-block">
 <a class="eds-c-header__link" href="https://order.springer.com/public/cart" style="appearance:none;border:none;background:none;color:inherit;position:relative">
  <svg id="eds-i-cart" class="eds-c-header__icon" xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 24 24" aria-hidden="true" focusable="false">
   <path fill="currentColor" fill-rule="nonzero" d="M2 1a1 1 0 0 0 0 2l1.659.001 2.257 12.808a2.599 2.599 0 0 0 2.435 2.185l.167.004 9.976-.001a2.613 2.613 0 0 0 2.61-1.748l.03-.106 1.755-7.82.032-.107a2.546 2.546 0 0 0-.311-1.986l-.108-.157a2.604 2.604 0 0 0-2.197-1.076L6.042 5l-.56-3.17a1 1 0 0 0-.864-.82l-.12-.007L2.001 1ZM20.35 6.996a.63.63 0 0 1 .54.26.55.55 0 0 1 .082.505l-.028.1L19.2 15.63l-.022.05c-.094.177-.282.299-.526.317l-10.145.002a.61.61 0 0 1-.618-.515L6.394 6.999l13.955-.003ZM18 19a2 2 0 1 0 0 4 2 2 0 0 0 0-4ZM8 19a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"></path>
  </svg><span>Cart</span><span class="cart-info" style="display:none;position:absolute;top:10px;right:45px;background-color:#C65301;color:#fff;width:18px;height:18px;font-size:11px;border-radius:50%;line-height:17.5px;text-align:center"></span></a>
 <script>(function () { var exports = {}; if (window.fetch) {
            
            "use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.headerWidgetClientInit = void 0;
var headerWidgetClientInit = function (getCartInfo) {
    document.body.addEventListener("updatedCart", function () {
        updateCartIcon();
    }, false);
    return updateCartIcon();
    function updateCartIcon() {
        return getCartInfo()
            .then(function (res) { return res.json(); })
            .then(refreshCartState)
            .catch(function (_) { });
    }
    function refreshCartState(json) {
        var indicator = document.querySelector("#ecommerce-header-cart-icon-link .cart-info");
        /* istanbul ignore else */
        if (indicator && json.itemCount) {
            indicator.style.display = 'block';
            indicator.textContent = json.itemCount > 9 ? '9+' : json.itemCount.toString();
            var moreThanOneItem = json.itemCount > 1;
            indicator.setAttribute('title', "there ".concat(moreThanOneItem ? "are" : "is", " ").concat(json.itemCount, " item").concat(moreThanOneItem ? "s" : "", " in your cart"));
        }
        return json;
    }
};
exports.headerWidgetClientInit = headerWidgetClientInit;

            
            headerWidgetClientInit(
              function () {
                return window.fetch("https://cart.springer.com/cart-info", {
                  credentials: "include",
                  headers: { Accept: "application/json" }
                })
              }
            )
        }})()</script>
</div>
                    
                </div>
            </div>
        </nav>
    
</header>



    <article lang="en" id="main" class="app-masthead__colour-18">
        <section class="app-masthead " aria-label="article masthead">
    <div class="app-masthead__container">
        
            <div class="app-article-masthead u-sans-serif js-context-bar-sticky-point-masthead" data-track-component="article" data-test="masthead-component">
                <div class="app-article-masthead__info">
                    
    
        <nav aria-label="breadcrumbs" data-test="breadcrumbs">
            <ol class="c-breadcrumbs c-breadcrumbs--contrast" itemscope itemtype="https://schema.org/BreadcrumbList">
                
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/" class="c-breadcrumbs__link" itemprop="item" data-track="click_breadcrumb" data-track-context="article page"  data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb1"><span itemprop="name">Home</span></a><meta itemprop="position" content="1">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" width="10" height="10" viewBox="0 0 10 10">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/journal/11263" class="c-breadcrumbs__link" itemprop="item" data-track="click_breadcrumb" data-track-context="article page"  data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb2"><span itemprop="name">International Journal of Computer Vision</span></a><meta itemprop="position" content="2">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" width="10" height="10" viewBox="0 0 10 10">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <span itemprop="name">Article</span><meta itemprop="position" content="3">
                    </li>
                
            </ol>
        </nav>
    

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts</h1>

                    <ul class="c-article-identifiers">
                        
    
        <li class="c-article-identifiers__item">
            <a href="https://www.springernature.com/gp/open-research/about/the-fundamentals-of-open-access-and-open-research" data-track="click" data-track-action="open access" data-track-label="link" class="u-color-open-access" data-test="open-access">Open access</a>
        </li>
    
    

                        <li class="c-article-identifiers__item">
                            Published: <time datetime="2024-03-22">22 March 2024</time>
                        </li>
                    </ul>
                    <ul class="c-article-identifiers c-article-identifiers--cite-list">
                        <li class="c-article-identifiers__item">
                            <span data-test="journal-volume">Volume 132</span>, pages 3428–3462, (<span data-test="article-publication-year">2024</span>)
                        </li>
                        <li class="c-article-identifiers__item c-article-identifiers__item--cite">
                            <a href="#citeas" data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link">Cite this article</a>
                        </li>
                    </ul>

                    <div class="app-article-masthead__buttons" data-test="download-article-link-wrapper" data-track-context="masthead">
                        
        <div class="c-pdf-container">
            <div class="c-pdf-download u-clear-both u-mb-16">
                <a href="/content/pdf/10.1007/s11263-024-02033-7.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="content_download" data-track-type="article pdf download" data-track-action="download pdf" data-track-label="button" data-track-external download>
                    
                        <span class="c-pdf-download__text">Download PDF</span>
                        <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-eds-i-download-medium"/></svg>
                    
                </a>
            </div>
        </div>
    

                        <p class="app-article-masthead__access">
                            <svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-check-filled-medium"></use></svg>
                            You have full access to this <a href="https://www.springernature.com/gp/open-research/about/the-fundamentals-of-open-access-and-open-research" data-track="click" data-track-action="open access" data-track-label="link">open access</a> article</p>
                        
                    </div>
                </div>
                <div class="app-article-masthead__brand">
                    
                        
                            <a href="/journal/11263"
                        
                           class="app-article-masthead__journal-link"
                           data-track="click_journal_home"
                           data-track-action="journal homepage"
                           data-track-context="article page"
                           data-track-label="link">
                            <picture>
                                <source type="image/webp" media="(min-width: 768px)" width="120" height="159"
                                        srcset="https://media.springernature.com/w120/springer-static/cover-hires/journal/11263?as=webp,
                                                    https://media.springernature.com/w316/springer-static/cover-hires/journal/11263?as=webp 2x">
                                <img width="72" height="95"
                                     src="https://media.springernature.com/w72/springer-static/cover-hires/journal/11263?as=webp"
                                     srcset="https://media.springernature.com/w144/springer-static/cover-hires/journal/11263?as=webp 2x" alt="">
                            </picture>
                            <span class="app-article-masthead__journal-title">International Journal of Computer Vision</span>
                        </a>
                        
                            <a href="https://link.springer.com/journal/11263/aims-and-scope" class="app-article-masthead__submission-link"
                               data-track="click_aims_and_scope"
                               data-track-action="aims and scope"
                               data-track-context="article page"
                               data-track-label="link">
                                Aims and scope
                                <svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-arrow-right-medium"></use></svg>
                            </a>
                        
                        
                            <a href="https://www.editorialmanager.com/visi" class="app-article-masthead__submission-link"
                               data-track="click_submit_manuscript"
                               data-track-context="article masthead on springerlink article page"
                               data-track-action="submit manuscript"
                               data-track-label="link">
                                Submit manuscript
                                <svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-arrow-right-medium"></use></svg>
                            </a>
                        
                    
                </div>
            </div>
        
    </div>
</section>

        <div class="c-article-main u-container u-mt-24 u-mb-32 l-with-sidebar" id="main-content"
             data-component="article-container">
            <main class="u-serif js-main-column" data-track-component="article body">
                
                
                    <div class="c-context-bar u-hide"
                         data-test="context-bar"
                         data-context-bar
                         aria-hidden="true">
                        <div class="c-context-bar__container u-container">
                            <div class="c-context-bar__title">
                                Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts
                            </div>
                            
                                <div data-test="inCoD" data-track-context="sticky banner">
                                    
        <div class="c-pdf-container">
            <div class="c-pdf-download u-clear-both u-mb-16">
                <a href="/content/pdf/10.1007/s11263-024-02033-7.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="content_download" data-track-type="article pdf download" data-track-action="download pdf" data-track-label="button" data-track-external download>
                    
                        <span class="c-pdf-download__text">Download PDF</span>
                        <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-eds-i-download-medium"/></svg>
                    
                </a>
            </div>
        </div>
    

                                </div>
                            
                        </div>
                    </div>
                

                

                <div class="c-article-header">
                    <header>
                        <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Peleg-Harel-Aff1" data-author-popup="auth-Peleg-Harel-Aff1" data-author-search="Harel, Peleg">Peleg Harel</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ofir_Itzhak-Shahar-Aff1" data-author-popup="auth-Ofir_Itzhak-Shahar-Aff1" data-author-search="Shahar, Ofir Itzhak">Ofir Itzhak Shahar</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ohad-Ben_Shahar-Aff1" data-author-popup="auth-Ohad-Ben_Shahar-Aff1" data-author-search="Ben-Shahar, Ohad" data-corresp-id="c1">Ohad Ben-Shahar<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0001-5346-152X"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-5346-152X</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup> </li></ul>
                        
    

                        <div data-test="article-metrics">
                            <ul class="app-article-metrics-bar u-list-reset">
                                
    
        <li class="app-article-metrics-bar__item">
            <p class="app-article-metrics-bar__count"><svg class="u-icon app-article-metrics-bar__icon" width="24" height="24" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-eds-i-accesses-medium"></use>
            </svg>1980 <span class="app-article-metrics-bar__label">Accesses</span></p>
        </li>
    
    
    
        
            <li class="app-article-metrics-bar__item">
                <p class="app-article-metrics-bar__count"><svg class="u-icon app-article-metrics-bar__icon" width="24" height="24" aria-hidden="true" focusable="false">
                    <use xlink:href="#icon-eds-i-altmetric-medium"></use>
                </svg>1 <span class="app-article-metrics-bar__label">Altmetric</span></p>
            </li>
        
    
    
    
        <li class="app-article-metrics-bar__item app-article-metrics-bar__item--metrics">
            <p class="app-article-metrics-bar__details"><a href="/article/10.1007/s11263-024-02033-7/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Explore all metrics <svg class="u-icon app-article-metrics-bar__arrow-icon" width="24" height="24" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-eds-i-arrow-right-medium"></use>
            </svg></a></p>
        </li>
    




                            </ul>
                        </div>
                        
    <div class="u-mt-32">
    

    
    </div>

                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Jigsaw puzzle solving, the problem of constructing a coherent whole from a set of non-overlapping unordered visual fragments, is fundamental to numerous applications, and yet most of the literature of the last two decades has focused thus far on less realistic puzzles whose pieces are identical squares. Here we formalize a new type of jigsaw puzzle where the pieces are general convex polygons generated by cutting through a global polygonal shape/image with an arbitrary number of straight cuts, a generation model inspired by the celebrated Lazy caterer’s sequence. We analyze the theoretical properties of such puzzles, including the inherent challenges in solving them once pieces are contaminated with geometrical noise. To cope with such difficulties and obtain tractable solutions, we abstract the problem as a multi-body spring-mass dynamical system endowed with hierarchical loop constraints and a layered reconstruction process. We define evaluation metrics and present experimental results on both apictorial and pictorial puzzles to show that they are solvable completely automatically.
</p></div></div></section>
                    
    


                    

                    <div data-test="cobranding-download">
                        
                    </div>

                    
                        
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1007%2Fs00371-022-02598-9/MediaObjects/371_2022_2598_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/s00371-022-02598-9?fromPaywallRec=false"
                                           data-track="select_recommendations_1"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1007/s00371-022-02598-9">Jigsaw puzzle solving techniques and applications: a survey
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">09 July 2022</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-981-96-0960-4?as&#x3D;webp" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/978-981-96-0960-4_29?fromPaywallRec=false"
                                           data-track="select_recommendations_2"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1007/978-981-96-0960-4_29">Nash Meets Wertheimer: Using Good Continuation in Jigsaw Puzzles
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Chapter</span>
                                        
                                         <span class="c-article-meta-recommendations__date">© 2025</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1007%2Fs00371-020-01968-5/MediaObjects/371_2020_1968_Fig1_HTML.jpg" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/s00371-020-01968-5?fromPaywallRec=false"
                                           data-track="select_recommendations_3"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1007/s00371-020-01968-5">Computational design of polyomino puzzles
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">07 September 2020</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'NA',
                        timestamp: 1743947254,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                    

                    
                        
    <section aria-labelledby="content-related-subjects" data-test="subject-content">
        <h3 id="content-related-subjects" class="c-article__sub-heading">Explore related subjects</h3>
        <span class="u-sans-serif u-text-s u-display-block u-mb-24">Discover the latest articles, news and stories from top researchers in related subjects.</span>
        <ul class="c-article-subject-list" role="list">
        
            <li class="c-article-subject-list__subject">
                <a href="/subject/artificial-intelligence"  data-track="select_related_subject_1" data-track-context="related subjects from content page" data-track-label="Artificial Intelligence">Artificial Intelligence</a>
            </li>
        
        </ul>
    </section>

                    

                    
                        
    <div class="app-card-service" data-test="article-checklist-banner">
        <div>
            <a class="app-card-service__link" data-track="click_presubmission_checklist" data-track-context="article page top of reading companion" data-track-category="pre-submission-checklist" data-track-action="clicked article page checklist banner test 2 old version" data-track-label="link" href="https://beta.springernature.com/pre-submission?journalId=11263"
            data-test="article-checklist-banner-link">
            <span class="app-card-service__link-text">Use our pre-submission checklist</span>
            <svg class="app-card-service__link-icon" aria-hidden="true" focusable="false"><use xlink:href="#icon-eds-i-arrow-right-small"></use></svg>
            </a>
            <p class="app-card-service__description">Avoid common mistakes on your manuscript.</p>
        </div>
        <div class="app-card-service__icon-container">
            <svg class="app-card-service__icon" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-eds-i-clipboard-check-medium"></use>
            </svg>
        </div>
    </div>

                    

                    
                        
                                <div class="main-content">
                                    <section data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1"><span class="c-article-section__title-number">1 </span>Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>It happens often in real life that an orderless set of given fragments should be matched correctly (typically with no overlaps) to reconstruct a desired (known or unknown) coherent shape. Indeed, this broader (yet informal) problem description of the common jigsaw puzzle game fits countless real-world applications, including in (but not limited to) archaeology (Willis &amp; Cooper, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Willis, A., &amp; Cooper, D. (2008). Computational reconstruction of ancient artifacts. IEEE Signal Processing Magazine. 25." href="/article/10.1007/s11263-024-02033-7#ref-CR78" id="ref-link-section-d337817856e351">2008</a>; Kleber, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Kleber, F., &amp; Sablatnig, R (2009). Scientific puzzle solving: Current techniques and applications. In CAA." href="/article/10.1007/s11263-024-02033-7#ref-CR31" id="ref-link-section-d337817856e354">2009</a>; Sizikova &amp; Funkhouser, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Sizikova, E., &amp; Funkhouser, T. A. (2016). Wall painting reconstruction using a genetic algorithm. Journal on Computing and Cultural Heritage (JOCCH), 11, 1–17." href="/article/10.1007/s11263-024-02033-7#ref-CR65" id="ref-link-section-d337817856e357">2016</a>), biology (Gassner et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Gassner, N., Baase, W., &amp; Matthews, B. (1996). A test of the “jigsaw puzzle’’ model for protein folding by multiple methionine substitutions within the core of t4 lysozyme. Proceedings of the National Academy of Sciences, 93(22), 12155–12158." href="/article/10.1007/s11263-024-02033-7#ref-CR24" id="ref-link-section-d337817856e360">1996</a>; Marande &amp; Burger, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Marande, W., &amp; Burger, G. (2007). Mitochondrial dna as a genomic jigsaw puzzle. Science, 318(5849), 415–415." href="/article/10.1007/s11263-024-02033-7#ref-CR41" id="ref-link-section-d337817856e363">2007</a>), earth sciences (Lindström, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Lindström, M. (2019). The geological development of the arctic. In The Arctic (pp. 3–25). Routledge." href="/article/10.1007/s11263-024-02033-7#ref-CR38" id="ref-link-section-d337817856e367">2019</a>), paleontology (Warren et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Warren, L., Quaglio, F., Riccomini, C., Simões, M., Poiré, D., Strikis, N., Anelli, L., &amp; Strikis, P. (2014). The puzzle assembled: Ediacaran guide fossil Cloudina reveals an old proto-Gondwana seaway. Geology 42, 5, 391–394." href="/article/10.1007/s11263-024-02033-7#ref-CR75" id="ref-link-section-d337817856e370">2014</a>), security and forensics (Gao et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Gao, H., Yao, D., Liu, H., Liu, X., &amp; Wang, L. (2010). A novel image based captcha using jigsaw puzzle. In 2010 13th IEEE international conference on computational science and engineering (pp. 351–356). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR23" id="ref-link-section-d337817856e373">2010</a>; Ali et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Ali, F. A. B. H., &amp; Karim, F. B. (2014). Development of captcha system based on puzzle. In 2014 international conference on computer, communications, and control technology (I4CT) (pp. 426–428). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR3" id="ref-link-section-d337817856e376">2014</a>; Gioe, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Gioe, D. (2017). ‘The more things change’: HUMINT in the cyber age. In The Palgrave handbook of security, risk and intelligence (pp. 213–227). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR25" id="ref-link-section-d337817856e379">2017</a>), artificial intelligence (Zhao et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Zhao, F., He, X., Zhang, Y., Lei, W., Ma, W., Zhang, C., &amp; Song, H. (2020). A jigsaw puzzle inspired algorithm for solving large-scale no-wait flow shop scheduling problems. Applied Intelligence, 50, 87–100." href="/article/10.1007/s11263-024-02033-7#ref-CR86" id="ref-link-section-d337817856e382">2020</a>), speech processing (Zhao et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Zhao, Y.-X., Su, M.-C., Chou, Z.-L., &amp; Lee, J. (2007). A puzzle solver and its application in speech descrambling. In WSEAS international conference on computer engineering and applications (pp. 171–176)." href="/article/10.1007/s11263-024-02033-7#ref-CR87" id="ref-link-section-d337817856e386">2007</a>), document reconstruction (Kleber &amp; Sablatnig, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Kleber, F., &amp; Sablatnig, R. (2009). A survey of techniques for document and archaeology artefact reconstruction. In ICDAR (pp. 1061–1065)." href="/article/10.1007/s11263-024-02033-7#ref-CR32" id="ref-link-section-d337817856e389">2009</a>), not to mention direct image editing (Cho et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Cho, T. S., Avidan, S., &amp; Freeman, W. T. (2010). A probabilistic image jigsaw puzzle solver. In 2010 IEEE computer society conference on computer vision and pattern recognition (pp. 183–190). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR13" id="ref-link-section-d337817856e392">2010</a>) and artistic expressions in general (For example, this artist brilliantly uses different jigsaw puzzles to create surreal mashups. <a href="https://mymodernmet.com/montage-puzzle-art-tim-klein/">https://mymodernmet.com/montage-puzzle-art-tim-klein/</a>). While one may conceive jigsaw puzzles of more abstract form, here we will refer to puzzles as <i>visuals</i> if both their fragments (a.k.a. pieces), and the reconstructed “wholes”, are “visual”, namely if they can be understood, analyzed, and reconstructed by a visual system (and in particular, the human visual system). In practical terms, this means that both the pieces and the reconstructed whole are geometrical entities, possibly endowed with some pictorial overlay. If only the global geometric shape of the fragments is used in the process, the puzzle is called ‘<i>apictorial</i>’. If, on the other hand, pictorial information on the fragments is also used for the reconstruction, the puzzle is called ‘<i>pictorial</i>’.</p><p>While solving real-life jigsaw puzzles has occupied humans for millennia, to our best knowledge it was first introduced as a <i>computational</i> task in 1964 by Freeman and Garder (Freeman &amp; Garder, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1964" title="Freeman, H., &amp; Garder, L. (1964). Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition. IEEE Transactions on Electronic Computers, 2, 118–127." href="/article/10.1007/s11263-024-02033-7#ref-CR20" id="ref-link-section-d337817856e418">1964</a>), who discussed the attributes of <i>apictorial</i> jigsaw puzzles and proposed a solver for puzzles of <i>unrestricted shapes</i>. Limited by the computation power of the time, results were of course constrained to very simple and small puzzles. In the last two decades, however, the focus in the computational literature has shifted towards puzzles of <i>square</i> pieces that must be matched into a rectangular image. Since the pieces in such puzzles are all shaped identically as squares, their pictorial content becomes <i>the only</i> source of information available for the reconstruction. While starting modestly, the suggested solvers for such puzzles evolved rapidly in the past decade, and although they cannot guarantee optimal solutions, contemporary methods exist to solve “square jigsaw puzzles” of virtually any practical size.</p><p>As discussed below in the related work, the significant gap between unrestricted puzzles and square jigsaw puzzles was rarely addressed in the literature, although there are numerous methodological and applicative advantages for doing so. In this work, we attempt to do exactly that. We introduce a different puzzle formation process, and a new class of puzzles termed here <i>crossing cuts polygonal puzzles</i>, that are inspired by the celebrated Lazy Caterer’s sequence. Specifically, we consider global convex polygonal shapes (for apictorial puzzles) or convex polygonal images (for pictorial puzzles) that are sliced through by multiple straight cuts of arbitrary positions and directions, thus dividing the puzzle shape into many convex polygonal fragments. We discuss the synthesis of such puzzles, their properties with and without geometric noise, the qualitatively different reconstruction challenges they present for reconstruction, and a novel solver formulation that is based on abstracting the puzzle as a physical mechanical system. We discuss evaluation measures and present both qualitative and quantitative results on large and novel datasets that are made available to the community for future research.</p></div></div></section><section data-title="Related Work"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2"><span class="c-article-section__title-number">2 </span>Related Work</h2><div class="c-article-section__content" id="Sec2-content"><p>As mentioned above, the problem of puzzle solving is one where an orderless set of given fragments should be organized correctly with no overlaps to reconstruct a desired (known or unknown) global shape and possibly also with (typically unknown) pictorial content. In such cases, the pictorial data is yet another reconstruction cue whose degree of importance can vary relative to the apictorial (geometric) ones. Decades after Freeman and Garder’s seminal paper (Freeman &amp; Garder, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1964" title="Freeman, H., &amp; Garder, L. (1964). Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition. IEEE Transactions on Electronic Computers, 2, 118–127." href="/article/10.1007/s11263-024-02033-7#ref-CR20" id="ref-link-section-d337817856e448">1964</a>) the problem was proved NP-complete (Demaine &amp; Demaine, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Demaine, E. D., &amp; Demaine, M. L. (2007). Jigsaw puzzles, edge matching, and polyomino packing: Connections and complexity. Graphs and Combinatorics, 23(1), 195–208." href="/article/10.1007/s11263-024-02033-7#ref-CR16" id="ref-link-section-d337817856e451">2007</a>), leading the literature to focus on devising heuristics, ad-hoc methods, and computational schemes that indeed cannot guarantee optimal solutions in tractable time but nevertheless facilitate successful puzzle solving in many cases, including large scale puzzles of various types.</p><p>Broadly speaking, visual puzzles are generated by taking a coherent global (pictorial or apictorial) object and “breaking” it into a set of orderless or disorganized set of fragments. The details of this “breaking” are called in this paper the “forward” <i>puzzle generation process</i>, which sometimes incorporates additional actions before the puzzle is finalized, such as removing fragments, adding bogus ones, deforming fragments geometry, or distorting the pictorial content (what we will call “geometric noise” and “pictorial noise”, respectively). With this in mind, the types of puzzles addressed in the prior art can be categorized into three different classes of such generation processes. We call these classes “Commercial toy puzzles”, “Square Jigsaw puzzles”, and “Unrestricted puzzles” (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig1">1</a>). Since puzzle reconstruction algorithms attempt to “reverse” the puzzle generation process, the classification also implies that the reconstruction process may be done differently in each class. One evident example is Square Jigsaw puzzles, which unlike their counterparts <i>must be</i> pictorial in order to escape trivial settings. In the following, we elaborate on each class, not necessarily according to their chronological order in the literature.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="428"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The type of visual puzzle classes most studied in the literature. Shown are both the bag of pieces and the reconstructed puzzle. Sketched are only apictorial puzzles of the same global (in this case, rectangular) shape to emphasize the effect of the class on the possible geometry of the pieces. <b>A</b> Commercial toy puzzle. <b>B</b> Square Jigsaw puzzle. Note that while the sketch focuses on their geometry, these puzzles must be pictorial to avoid trivial settings. <b>C</b> Unrestricted puzzle</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec3"><span class="c-article-section__title-number">2.1 </span>Commercial Toy Puzzles</h3><p>Commercial toy puzzles, a set we denote <span class="mathjax-tex">\(\mathcal {P_C}\)</span>, include puzzles one can buy at toy stores and designated as a leisure time activity. As this type of puzzle is specifically meant to be solvable by humans, it follows a common set of very specific constraints and rules (Goldberg et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Goldberg, D., Malon, C., &amp; Bern, M. (2002). A global approach to automatic solution of jigsaw puzzles. In Proceedings of the eighteenth annual symposium on Computational geometry (pp. 82–87). ACM." href="/article/10.1007/s11263-024-02033-7#ref-CR26" id="ref-link-section-d337817856e524">2002</a>). First, the outer border of the puzzle is rectangular. Second, the pieces in a reconstructed puzzle form a sort of rectangular grid so that all pieces except boundary ones have exactly four neighbors. Finally, pieces interlock with their neighbors by tabs (i.e., concave or convex protrusions), so that the shape of the matching tab allows a unique match.<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup></p><p>Although designed for humans, and very limited in their applications, Commercial Toy puzzles consume a fair share of the computational literature, and mostly after the mid-1980s. The uniqueness property suggests that a greedy approach can always solve such problems in low-order polynomial time simply by matching boundary curves. However, the need to scan the pieces and represent their boundaries numerically introduces geometric noise that leads to false positives during the search. With this in mind, the several toy puzzle solvers proposed in the literature share a common scheme. First, the pieces are classified as either border or inner pieces by analyzing their boundary and counting straight segments. Border pieces are then assembled first (just as humans would tend to do), for example by reducing the problem to the traveling salesman problem and solving it via heuristic methods (Wolfson et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Wolfson, H., Schonberg, E., Kalvin, A., &amp; Lamdan, Y. (1988). Solving jigsaw puzzles by computer. Annals of Operations Research, 12(1), 51–64." href="/article/10.1007/s11263-024-02033-7#ref-CR79" id="ref-link-section-d337817856e535">1988</a>). Once the border pieces are placed, the dimensions of the puzzle grid can be deduced and the inner pieces are placed in a grid using either a greedy or an exhaustive search method. Because noise could generate false positives, each piece placement involves a test for geometric violations (e.g., overlaps between pieces), a type of event that results in backtracking. Although the use of backtracking can entail exponential complexity, the shape of the tab is expected to be unique enough to make false positives rare (or even impossible), thus retaining a tractable solution process.</p><p>Given that the matching geometry is unique, <span class="mathjax-tex">\(\mathcal {P_C}\)</span> puzzles need not contain pictorial content for a computer (or for that matter, even humans) to solve, as indeed was the case in several prior studies on the topic (Wolfson et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Wolfson, H., Schonberg, E., Kalvin, A., &amp; Lamdan, Y. (1988). Solving jigsaw puzzles by computer. Annals of Operations Research, 12(1), 51–64." href="/article/10.1007/s11263-024-02033-7#ref-CR79" id="ref-link-section-d337817856e565">1988</a>; Burdea &amp; Wolfson, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1989" title="Burdea, B., &amp; Wolfson, H. J. (1989). Solving jigsaw puzzles by a robot. IEEE Transactions on Robotics and Automation, 5(6), 752–764." href="/article/10.1007/s11263-024-02033-7#ref-CR10" id="ref-link-section-d337817856e568">1989</a>; Webster et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Webster, R. W., LaFollette, P. S., &amp; Stafford, R. L. (1991). Isthmus critical points for solving jigsaw puzzles in computer vision. IEEE Transactions on Systems, Man, and Cybernetics, 21(5), 1271–1278." href="/article/10.1007/s11263-024-02033-7#ref-CR76" id="ref-link-section-d337817856e571">1991</a>; Bunke &amp; Kaufmann, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Bunke, H., &amp; Kaufmann, G. (1993). Jigsaw puzzle solving using approximate string matching and best-first search. In International conference on computer analysis of images and patterns (pp. 299–308). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR9" id="ref-link-section-d337817856e574">1993</a>; De Bock et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="De Bock, J., De Smet, R., Philips, W., &amp; D’Haeyer, J. (2004). Constructing the topological solution of jigsaw puzzles. In 2004 International conference on image processing, 2004. ICIP’04. (Vol. 3, pp. 2127–2130). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR15" id="ref-link-section-d337817856e578">2004</a>; Goldberg et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Goldberg, D., Malon, C., &amp; Bern, M. (2002). A global approach to automatic solution of jigsaw puzzles. In Proceedings of the eighteenth annual symposium on Computational geometry (pp. 82–87). ACM." href="/article/10.1007/s11263-024-02033-7#ref-CR26" id="ref-link-section-d337817856e581">2002</a>). That being said, pictorial extensions <i>do</i> exist, addressing the full real-life toy jigsaw puzzle challenge (except for the fact that toy puzzles usually include the reconstructed image printed on their box cover). Such pictorial toy puzzle solvers (Kosiba et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Kosiba, D. A., Devaux, P. M., Balasubramanian, S., Gandhi, T. L., &amp; Kasturi, K. (1994). An automatic jigsaw puzzle solver. In Proceedings of 12th international conference on pattern recognition, (Vol. 1, pp. 616–618). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR35" id="ref-link-section-d337817856e587">1994</a>; Chung et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Chung, M. G., Fleck, M. M., &amp; Forsyth, D. A. (1998). Jigsaw puzzle solver using shape and color. In ICSP’98. 1998 Fourth international conference on signal processing (Cat. No. 98TH8344) (Vol. 2, pp. 877–880). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR14" id="ref-link-section-d337817856e590">1998</a>; Yao &amp; Shao, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Yao, F.-H., &amp; Shao, G.-F. (2003). A shape and image merging technique to solve jigsaw puzzles. Pattern Recognition Letters, 24(12), 1819–1835." href="/article/10.1007/s11263-024-02033-7#ref-CR82" id="ref-link-section-d337817856e593">2003</a>; Nielsen et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Nielsen, T. R., Drewsen, P., &amp; Hansen, K. (2008). Solving jigsaw puzzles using image features. Pattern Recognition Letters, 29(14), 1924–1933." href="/article/10.1007/s11263-024-02033-7#ref-CR48" id="ref-link-section-d337817856e597">2008</a>) can clearly utilize an additional constraint of visual coherence (e.g., continuity) across neighboring pieces to improve the accuracy of potential mates, lower the risk of false positives, and thus reduce the search space. Thus far, the biggest pictorial toy puzzle solved this way was sized at 320 pieces (Nielsen et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Nielsen, T. R., Drewsen, P., &amp; Hansen, K. (2008). Solving jigsaw puzzles using image features. Pattern Recognition Letters, 29(14), 1924–1933." href="/article/10.1007/s11263-024-02033-7#ref-CR48" id="ref-link-section-d337817856e600">2008</a>). Unfortunately, given the possibility of solving such puzzles perfectly in tractable time, no performance metrics (other than testing for perfect reconstruction) or statistical benchmark experimentation are typically performed.</p><h3 class="c-article__sub-heading" id="Sec4"><span class="c-article-section__title-number">2.2 </span>Square Jigsaw Puzzles</h3><p>Square Jigsaw puzzles, denoted <span class="mathjax-tex">\(\mathcal {P_S}\)</span>, are the type of visual puzzles discussed most frequently in the last two decades. They are the simplest geometrically and based on a generation process that cuts a rectangular image into a grid of identically shaped square pieces. The problem is considerably different than the commercial toy puzzles since with identical boundaries to all pieces, the reconstruction must fully rely on the pictorial content.</p><p>Square Jigsaw puzzles also tend to share a similar algorithmic flow. First, a measure of dissimilarity between every two potential neighbors is pre-calculated. Then, the dissimilarity is used to derive neighbors’ compatibility scores to represent the confidence that they should be paired. Then neighboring pieces are matched, placed, and aggregated to maximize global compatibility, either in a greedy fashion or by employing heuristics to globally search the solution space. Since state-of-the-art square-piece puzzle solving now tends to deal with rather large-scale problems, backtracking is typically avoided as the number of search paths is intractable. The many variants of this general scheme include solvers for Square Jigsaw puzzles with pieces of <i>known</i> size and piece orientation (Toyama et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Toyama, F., Fujiki, Y., Shoji, K., &amp; Miyamichi, J. (2002). Assembly of puzzles using a genetic algorithm. In Object recognition supported by user interaction for service robots (Vol. 4, IEEE, pp. 389–392)." href="/article/10.1007/s11263-024-02033-7#ref-CR73" id="ref-link-section-d337817856e641">2002</a>; Fei et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Fei, N., Zhuang, F., Renqiang, L., Qixin, C., &amp; Yanzheng, Z. (2007). An image processing approach for jigsaw puzzle assembly. Assembly Automation, 27(1), 25–30." href="/article/10.1007/s11263-024-02033-7#ref-CR19" id="ref-link-section-d337817856e644">2007</a>; Zhao et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Zhao, Y.-X., Su, M.-C., Chou, Z.-L., &amp; Lee, J. (2007). A puzzle solver and its application in speech descrambling. In WSEAS international conference on computer engineering and applications (pp. 171–176)." href="/article/10.1007/s11263-024-02033-7#ref-CR87" id="ref-link-section-d337817856e647">2007</a>; Murakami et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Murakami, T., Toyama, F., Shoji, K., &amp; Miyamichi, J. (2008). Assembly of puzzles by connecting between blocks. In 2008 19th international conference on pattern recognition (pp. 1–4). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR47" id="ref-link-section-d337817856e650">2008</a>; Alajlan, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Alajlan, N. (2009). Solving square jigsaw puzzles using dynamic programming and the Hungarian procedure. American Journal of Applied Sciences, 6(11), 1941." href="/article/10.1007/s11263-024-02033-7#ref-CR2" id="ref-link-section-d337817856e654">2009</a>; Cho et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Cho, T. S., Avidan, S., &amp; Freeman, W. T. (2010). A probabilistic image jigsaw puzzle solver. In 2010 IEEE computer society conference on computer vision and pattern recognition (pp. 183–190). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR13" id="ref-link-section-d337817856e657">2010</a>; Pomeranz et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Pomeranz, D., Shemesh, M., &amp; Ben-Shahar, O. (2011). A fully automated greedy square jigsaw puzzle solver. In CVPR 2011, (pp. 9–16). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR57" id="ref-link-section-d337817856e660">2011</a>; Yang et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Yang, X., Adluru, N., &amp; Latecki, L. J. (2011). Particle filter with state permutations for solving image jigsaw puzzles. In CVPR 2011, (pp. 2873–2880). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR81" id="ref-link-section-d337817856e663">2011</a>; Sholomon et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Sholomon, D., David, O., &amp; Netanyahu, N. S. (2013). A genetic algorithm-based solver for very large jigsaw puzzles. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1767–1774)." href="/article/10.1007/s11263-024-02033-7#ref-CR63" id="ref-link-section-d337817856e666">2013</a>; Adluru et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Adluru, N., Yang, X., &amp; Latecki, L. J. (2015). Sequential monte carlo for maximum weight subgraphs with application to solving image jigsaw puzzles. International Journal of Computer Vision, 112(3), 319–341." href="/article/10.1007/s11263-024-02033-7#ref-CR1" id="ref-link-section-d337817856e669">2015</a>; Andalo et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Andalo, F., Taubin, G., &amp; Goldenstein, S. (2016). PSQP: Puzzle solving by quadratic programming. IEEE PAMI, 39(2), 385–396." href="/article/10.1007/s11263-024-02033-7#ref-CR4" id="ref-link-section-d337817856e673">2016</a>), puzzles where the orientation of the pieces is <i>unknown</i> (Gallagher, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Gallagher, A. C. (2012). Jigsaw puzzles with pieces of unknown orientation. In 2012 IEEE conference on computer vision and pattern recognition (pp. 382–389). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR22" id="ref-link-section-d337817856e679">2012</a>; Mondal et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Mondal, D., Wang, Y., &amp; Durocher, S. (2013). Robust solvers for square jigsaw puzzles. In 2013 international conference on computer and robot vision(pp. 249–256). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR45" id="ref-link-section-d337817856e682">2013</a>; Sholomon et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Sholomon, D., David, O. E., &amp; Netanyahu, N. S. (2014). A generalized genetic algorithm-based solver for very large jigsaw puzzles of complex types. In Twenty-eighth AAAI conference on artificial intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR64" id="ref-link-section-d337817856e685">2014</a>; Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Son, K., Hays, J., &amp; Cooper, D. B. (2014). Solving square jigsaw puzzles with loop constraints. In European conference on computer vision, (pp. 32–46). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR66" id="ref-link-section-d337817856e688">2014</a>; Yu et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Yu, R., Russell, C., &amp; Agapito, L. (2015). Solving jigsaw puzzles with linear programming. arXiv preprint &#xA;                  arXiv:1511.04472&#xA;                  &#xA;                ." href="/article/10.1007/s11263-024-02033-7#ref-CR83" id="ref-link-section-d337817856e692">2015</a>; Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Son, K., Hays, J., Cooper, &amp; D. B., et al. (2016). Solving small-piece jigsaw puzzles by growing consensus. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1193–1201)." href="/article/10.1007/s11263-024-02033-7#ref-CR68" id="ref-link-section-d337817856e695">2016</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR67" id="ref-link-section-d337817856e698">2018</a>; Rika et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Rika, D., Sholomon, D., David, E. O., &amp; Netanyahu, N. S. (2019). A novel hybrid scheme using genetic algorithms and deep learning for the reconstruction of portuguese tile panels. In Proceedings of the genetic and evolutionary computation conference, (pp. 1319–1327). ACM." href="/article/10.1007/s11263-024-02033-7#ref-CR59" id="ref-link-section-d337817856e701">2019</a>), challenges with mixed set of pieces from multiple puzzles (Gallagher, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Gallagher, A. C. (2012). Jigsaw puzzles with pieces of unknown orientation. In 2012 IEEE conference on computer vision and pattern recognition (pp. 382–389). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR22" id="ref-link-section-d337817856e704">2012</a>; Mondal et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Mondal, D., Wang, Y., &amp; Durocher, S. (2013). Robust solvers for square jigsaw puzzles. In 2013 international conference on computer and robot vision(pp. 249–256). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR45" id="ref-link-section-d337817856e707">2013</a>; Paikin &amp; Tal, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Paikin, G., &amp; Tal, A. (2015). Solving multiple square jigsaw puzzles with missing pieces. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4832–4839)." href="/article/10.1007/s11263-024-02033-7#ref-CR50" id="ref-link-section-d337817856e711">2015</a>; Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Son, K., Hays, J., Cooper, &amp; D. B., et al. (2016). Solving small-piece jigsaw puzzles by growing consensus. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1193–1201)." href="/article/10.1007/s11263-024-02033-7#ref-CR68" id="ref-link-section-d337817856e714">2016</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR67" id="ref-link-section-d337817856e717">2018</a>), missing pieces (Gallagher, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Gallagher, A. C. (2012). Jigsaw puzzles with pieces of unknown orientation. In 2012 IEEE conference on computer vision and pattern recognition (pp. 382–389). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR22" id="ref-link-section-d337817856e720">2012</a>; Mondal et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Mondal, D., Wang, Y., &amp; Durocher, S. (2013). Robust solvers for square jigsaw puzzles. In 2013 international conference on computer and robot vision(pp. 249–256). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR45" id="ref-link-section-d337817856e723">2013</a>; Paikin &amp; Tal, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Paikin, G., &amp; Tal, A. (2015). Solving multiple square jigsaw puzzles with missing pieces. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4832–4839)." href="/article/10.1007/s11263-024-02033-7#ref-CR50" id="ref-link-section-d337817856e726">2015</a>; Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Son, K., Hays, J., Cooper, &amp; D. B., et al. (2016). Solving small-piece jigsaw puzzles by growing consensus. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1193–1201)." href="/article/10.1007/s11263-024-02033-7#ref-CR68" id="ref-link-section-d337817856e730">2016</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR67" id="ref-link-section-d337817856e733">2018</a>) noisy pictorial content (Mondal et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Mondal, D., Wang, Y., &amp; Durocher, S. (2013). Robust solvers for square jigsaw puzzles. In 2013 international conference on computer and robot vision(pp. 249–256). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR45" id="ref-link-section-d337817856e736">2013</a>; Brandão &amp; Marques, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Brandão, S., &amp; Marques, M. (2016). Hot tiles: A heat diffusion based descriptor for automatic tile panel assembly. In European conference on computer vision (pp. 768–782). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR7" id="ref-link-section-d337817856e739">2016</a>; Rika et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Rika, D., Sholomon, D., David, E. O., &amp; Netanyahu, N. S. (2019). A novel hybrid scheme using genetic algorithms and deep learning for the reconstruction of portuguese tile panels. In Proceedings of the genetic and evolutionary computation conference, (pp. 1319–1327). ACM." href="/article/10.1007/s11263-024-02033-7#ref-CR59" id="ref-link-section-d337817856e742">2019</a>; Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Son, K., Hays, J., &amp; Cooper, D. B. (2014). Solving square jigsaw puzzles with loop constraints. In European conference on computer vision, (pp. 32–46). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR66" id="ref-link-section-d337817856e745">2014</a>; Yu et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Yu, R., Russell, C., &amp; Agapito, L. (2015). Solving jigsaw puzzles with linear programming. arXiv preprint &#xA;                  arXiv:1511.04472&#xA;                  &#xA;                ." href="/article/10.1007/s11263-024-02033-7#ref-CR83" id="ref-link-section-d337817856e749">2015</a>; Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR67" id="ref-link-section-d337817856e752">2018</a>), gaps between pieces (Paumard et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Paumard, M.-M., Picard, D., &amp; Tabia, H. (2020). Deepzzle: Solving visual jigsaw puzzles with deep learning and shortest path optimization. IEEE Transactions on Image Processing, 29, 3569–3581." href="/article/10.1007/s11263-024-02033-7#ref-CR55" id="ref-link-section-d337817856e755">2020</a>; Derech et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Derech, N., Tal, A., &amp; Shimshoni, I. (2021). Solving archaeological puzzles. Pattern Recognition, 108065." href="/article/10.1007/s11263-024-02033-7#ref-CR17" id="ref-link-section-d337817856e758">2021</a>), and even restricted deformations to the shapes of fragments (Gur &amp; Ben-Shahar, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Gur, S., &amp; Ben-Shahar, O. (2017). From square pieces to brick walls: The next challenge in solving jigsaw puzzles. In Proceedings of the IEEE international conference on computer vision (pp. 4029–4037)." href="/article/10.1007/s11263-024-02033-7#ref-CR28" id="ref-link-section-d337817856e761">2017</a>).</p><p>Indeed, earlier attempts to address the problem assumed known dimensions, known piece orientation, and even some prior knowledge regarding the solution. For example, Cho et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Cho, T. S., Avidan, S., &amp; Freeman, W. T. (2010). A probabilistic image jigsaw puzzle solver. In 2010 IEEE computer society conference on computer vision and pattern recognition (pp. 183–190). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR13" id="ref-link-section-d337817856e767">2010</a>) used prior knowledge in the form of ground truth anchor pieces or low-resolution images of the solved puzzle. Color differences along abutting piece boundaries were used for the compatibility score and the reconstruction was based on achieving maximum likelihood for both piece compatibility and the prior knowledge. Shortly after, Pomeranz et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Pomeranz, D., Shemesh, M., &amp; Ben-Shahar, O. (2011). A fully automated greedy square jigsaw puzzle solver. In CVPR 2011, (pp. 9–16). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR57" id="ref-link-section-d337817856e770">2011</a>) were the first to solve the Square Jigsaw puzzle fully autonomously and <i>without</i> any prior knowledge (except for the puzzle dimensions) and increased the size of solvable puzzles an order of magnitude over the prior art to puzzles of thousands of pieces. Among the contributions were an iterative greedy approach, prediction of pictorial content across piece boundary for the dissimilarity metric, and the introduction of the <i>best-buddies</i> concept that influenced much of the later works and served as a precursor for the employment of loopy constraints to reduce the search space (see below). Sholomon et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Sholomon, D., David, O., &amp; Netanyahu, N. S. (2013). A genetic algorithm-based solver for very large jigsaw puzzles. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1767–1774)." href="/article/10.1007/s11263-024-02033-7#ref-CR63" id="ref-link-section-d337817856e779">2013</a>) introduced a different type of solver based on a genetic algorithm and the best-buddies idea, a combination that proved successful in solving even larger puzzles, exceeding the likely capacity of human solvers.</p><p>Pieces of unknown orientation add another layer of complexity to the Square Jigsaw puzzle problem, as the number of possible configurations increases by a factor of <span class="mathjax-tex">\(4^K\)</span> (for puzzles of <i>K</i> pieces). Gallagher (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Gallagher, A. C. (2012). Jigsaw puzzles with pieces of unknown orientation. In 2012 IEEE conference on computer vision and pattern recognition (pp. 382–389). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR22" id="ref-link-section-d337817856e810">2012</a>) was the first to tackle such puzzles while introducing a gradient-based dissimilarity score and a greedy spanning tree-based solver. Yu et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Yu, R., Russell, C., &amp; Agapito, L. (2015). Solving jigsaw puzzles with linear programming. arXiv preprint &#xA;                  arXiv:1511.04472&#xA;                  &#xA;                ." href="/article/10.1007/s11263-024-02033-7#ref-CR83" id="ref-link-section-d337817856e813">2015</a>) also dealt with unknown orientation by using a global optimization in the form of relaxed linear programming, and Sholomon et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Sholomon, D., David, O. E., &amp; Netanyahu, N. S. (2014). A generalized genetic algorithm-based solver for very large jigsaw puzzles of complex types. In Twenty-eighth AAAI conference on artificial intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR64" id="ref-link-section-d337817856e816">2014</a>) modified their original genetic algorithm to also handle unknown orientations in puzzles with a very large number of pieces.</p><p>Noise in the pictorial data increases the difficulty of the problem since the dissimilarity metric becomes less reliable and false matches are even more likely, prompting some studies to seek more robust compatibility metric (e.g., Mondal et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Mondal, D., Wang, Y., &amp; Durocher, S. (2013). Robust solvers for square jigsaw puzzles. In 2013 international conference on computer and robot vision(pp. 249–256). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR45" id="ref-link-section-d337817856e823">2013</a>; Brandão &amp; Marques, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Brandão, S., &amp; Marques, M. (2016). Hot tiles: A heat diffusion based descriptor for automatic tile panel assembly. In European conference on computer vision (pp. 768–782). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR7" id="ref-link-section-d337817856e826">2016</a>; Rika et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Rika, D., Sholomon, D., David, E. O., &amp; Netanyahu, N. S. (2019). A novel hybrid scheme using genetic algorithms and deep learning for the reconstruction of portuguese tile panels. In Proceedings of the genetic and evolutionary computation conference, (pp. 1319–1327). ACM." href="/article/10.1007/s11263-024-02033-7#ref-CR59" id="ref-link-section-d337817856e829">2019</a>). Toward that end, Mondal et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Mondal, D., Wang, Y., &amp; Durocher, S. (2013). Robust solvers for square jigsaw puzzles. In 2013 international conference on computer and robot vision(pp. 249–256). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR45" id="ref-link-section-d337817856e832">2013</a>) combined two previously used dissimilarity metrics while Brandão and Marques (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Brandão, S., &amp; Marques, M. (2016). Hot tiles: A heat diffusion based descriptor for automatic tile panel assembly. In European conference on computer vision (pp. 768–782). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR7" id="ref-link-section-d337817856e835">2016</a>) measured the dissimilarity using a heat-based affinity measure that utilizes a pixel environment larger than the piece boundary. Rika et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Rika, D., Sholomon, D., David, E. O., &amp; Netanyahu, N. S. (2019). A novel hybrid scheme using genetic algorithms and deep learning for the reconstruction of portuguese tile panels. In Proceedings of the genetic and evolutionary computation conference, (pp. 1319–1327). ACM." href="/article/10.1007/s11263-024-02033-7#ref-CR59" id="ref-link-section-d337817856e839">2019</a>) used deep learning as a mechanism to assess the compatibility between pairs of pieces, taking the whole piece as input. Taking a different approach, Yu et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Yu, R., Russell, C., &amp; Agapito, L. (2015). Solving jigsaw puzzles with linear programming. arXiv preprint &#xA;                  arXiv:1511.04472&#xA;                  &#xA;                ." href="/article/10.1007/s11263-024-02033-7#ref-CR83" id="ref-link-section-d337817856e842">2015</a>) and Son et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Son, K., Hays, J., &amp; Cooper, D. B. (2014). Solving square jigsaw puzzles with loop constraints. In European conference on computer vision, (pp. 32–46). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR66" id="ref-link-section-d337817856e845">2014</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR67" id="ref-link-section-d337817856e848">2018</a>) dealt with noise by applying a reconstruction algorithm that demands a consensus in an environment larger than the immediate neighbors of each piece. The former used a relaxed linear programming algorithm that rewards global piece consensus while the latter introduced the notion of loopy constraint - a requirement for compatibility consensus in loops of pieces.</p><p>Present-day state-of-the-art solvers for the Square Jigsaw puzzle can solve puzzles with over 20, 000 pieces (Sholomon et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Sholomon, D., David, O. E., &amp; Netanyahu, N. S. (2014). A generalized genetic algorithm-based solver for very large jigsaw puzzles of complex types. In Twenty-eighth AAAI conference on artificial intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR64" id="ref-link-section-d337817856e854">2014</a>). For historical reasons, most of the prior art experimented with square pieces of <span class="mathjax-tex">\(28{\times }28\)</span> pixels in size in order to allow enough pictorial data while measuring the compatibility of pieces. However, recent works now extend this convention to pieces as small as <span class="mathjax-tex">\(7\times 7\)</span> pixels (Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Son, K., Hays, J., &amp; Cooper, D. B. (2014). Solving square jigsaw puzzles with loop constraints. In European conference on computer vision, (pp. 32–46). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR66" id="ref-link-section-d337817856e905">2014</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR67" id="ref-link-section-d337817856e908">2018</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="368"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>The elements of a crossing cuts puzzle. <b>A</b> The puzzle is created by cutting a convex polygon using multiple (here 3) straight lines. <b>B</b> The puzzle problem constitutes of an un-ordered and arbitrarily transformed set of pieces. Note that different pieces may vary vastly in size (e.g., compare pieces <span class="mathjax-tex">\(p_B\)</span> and <span class="mathjax-tex">\(p_D\)</span>. <b>C</b> The mating graph matches pairs of edges of two different pieces and here it includes <span class="mathjax-tex">\(\{ \{ e_A^1, e_B^4 \},\{ e_A^2, e_C^0 \},\{ e_B^2, e_E^1 \},\{ e_B^3, e_D^1 \},\{ e_B^3, e_D^1 \},\{ e_C^1, e_D^0 \},\{ e_C^2, e_F^2 \},\{ e_D^2, e_G^1 \},\{ e_E^0, e_G^2 \},\{ e_F^3, e_G^0 \} \}\)</span>. Note that pieces end up having different numbers of edges and thus different numbers of mates. <b>D</b> A pictorial crossing cuts puzzle is one with an image (or any other visual content) covering the polygon that is being cut. <b>E</b> Once cut and shuffled, the pictorial pieces represent the puzzle to be solved</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="356"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>The representation of a crossing cuts puzzle and its solution, illustrated here for the simplest 2 cuts (and 3 pieces) puzzle. <b>A</b> Each piece <span class="mathjax-tex">\(\{p_1,p_2,p_3\}\)</span> is represented by its vertices and edges in some arbitrary Euclidean coordinate system (which conveniently may be centered at the center of mass). <b>B</b> Each mating pairs two edges of two different pieces. In our case it takes just the matings <span class="mathjax-tex">\(\{ \{ e_A^3, e_B^1 \}, \{e_B^3, e_C^1\}\}\)</span>. <b>C</b> After the application of the Euclidean transformations <span class="mathjax-tex">\((t_i, R_i) \forall \ i = 1..3\)</span>, the puzzle is reconstructed (up to some global Euclidean transformation)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec5"><span class="c-article-section__title-number">2.3 </span>Unrestricted Puzzles</h3><p>Unrestricted puzzles, the class we denote <span class="mathjax-tex">\(\mathcal {P_U}\)</span>, contain puzzles that do not have a formal generation process or constraints on the shape of their pieces. In such puzzles, the representation of the pieces is far more complex (than <span class="mathjax-tex">\(\mathcal {P_S}\)</span> or <span class="mathjax-tex">\(\mathcal {P_C}\)</span>), they can be matched to an arbitrary number of neighbors abutting arbitrary sections of their boundary, and the reconstruction of such 2D puzzles can be described as a general planar adjacency graph of arbitrary maximal degree (unlike the degree 4 that characterizes the reconstructions of 2D puzzles in <span class="mathjax-tex">\(\mathcal {P_C}\)</span> or <span class="mathjax-tex">\(\mathcal {P_S}\)</span>). Despite these complications, and somewhat unexpectedly, the very first work on computational puzzle solving (Freeman &amp; Garder, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1964" title="Freeman, H., &amp; Garder, L. (1964). Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition. IEEE Transactions on Electronic Computers, 2, 118–127." href="/article/10.1007/s11263-024-02033-7#ref-CR20" id="ref-link-section-d337817856e1675">1964</a>) belongs to this class.</p><p><i>Apictorial</i> unrestricted puzzle solvers typically use curve matching to find potential matching pieces (Freeman &amp; Garder, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1964" title="Freeman, H., &amp; Garder, L. (1964). Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition. IEEE Transactions on Electronic Computers, 2, 118–127." href="/article/10.1007/s11263-024-02033-7#ref-CR20" id="ref-link-section-d337817856e1683">1964</a>; Radack &amp; Badler, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1982" title="Radack, G. M., &amp; Badler, N. I. (1982). Jigsaw puzzle matching using a boundary-centered polar encoding. Computer Graphics and Image Processing, 19(1), 1–17." href="/article/10.1007/s11263-024-02033-7#ref-CR58" id="ref-link-section-d337817856e1686">1982</a>; Kong &amp; Kimia, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Kong, W., &amp; Kimia, B. B. (2001). On solving 2d and 3d puzzles using curve matching. In Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001 (Vol. 2, pp. II–II). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR34" id="ref-link-section-d337817856e1689">2001</a>). As mentioned above, the first to explore such an approach (or computational puzzle solving in general) were Freeman and Garder (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1964" title="Freeman, H., &amp; Garder, L. (1964). Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition. IEEE Transactions on Electronic Computers, 2, 118–127." href="/article/10.1007/s11263-024-02033-7#ref-CR20" id="ref-link-section-d337817856e1692">1964</a>), who also introduced a solver capable of dealing with a large variety of piece shapes and junction types. Their solver matches curves using a chain encoding scheme and then assembles the puzzle using a greedy algorithm that backtracks on errors, an exhaustive scheme possible only because of the very small scale problems considered. The solver tried to reconstruct coherently around junctions, thus seeking neighbors with loopy consensus, perhaps leading the way to the future use of loopy constraints in the field (Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Son, K., Hays, J., &amp; Cooper, D. B. (2014). Solving square jigsaw puzzles with loop constraints. In European conference on computer vision, (pp. 32–46). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR66" id="ref-link-section-d337817856e1695">2014</a>). Owing to the small computational resources of the time, the single evaluation on a 9-piece puzzle of highly discriminated pieces did not permit later experimental comparison to contemporary contributions. Forty years later, Kong and Kimia (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Kong, W., &amp; Kimia, B. B. (2001). On solving 2d and 3d puzzles using curve matching. In Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001 (Vol. 2, pp. II–II). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR34" id="ref-link-section-d337817856e1699">2001</a>) used a coarse-to-fine approach to curve matching and a greedy merging of piece triplets and backtracking upon spatial overlap. While the geometrical treatment was significantly more rigorous, here too the experimentation was limited to few puzzles of up to 25 pieces, most of which had near-convex low-order polygonal shapes. An interesting question that emerges is whether or not such data represent realistic scenarios, at least on average. Of course, it is difficult to address such questions without some formal puzzle generation model, an observation that is key to the suggested research in this paper (see below).</p><p>Extending the basic computational flow of the above, solvers for unrestricted <i>pictorial</i> puzzles (Tsamoura &amp; Pitas, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Tsamoura, E., &amp; Pitas, I. (2009). Automatic color based reassembly of fragmented images and paintings. IEEE Transactions on Image Processing, 19(3), 680–690." href="/article/10.1007/s11263-024-02033-7#ref-CR74" id="ref-link-section-d337817856e1708">2009</a>; Liu et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Liu, H., Cao, S., &amp; Yan, S. (2011). Automated assembly of shredded pieces from multiple photos. IEEE Transactions on Multimedia, 13(5), 1154–1162." href="/article/10.1007/s11263-024-02033-7#ref-CR39" id="ref-link-section-d337817856e1711">2011</a>; Makridis &amp; Papamarkos, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Makridis, M., &amp; Papamarkos, N. (2006). A new technique for solving a jigsaw puzzle. In 2006 international conference on image processing (pp. 2001–2004). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR40" id="ref-link-section-d337817856e1714">2006</a>; Sağıroğlu &amp; Erçil, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Sağıroğlu, M. Ş, &amp; Erçil, A. (2010). Optimization for automated assembly of puzzles. Top, 18(2), 321–338." href="/article/10.1007/s11263-024-02033-7#ref-CR61" id="ref-link-section-d337817856e1717">2010</a>; Zhang &amp; Li, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Zhang, K., &amp; Li, X. (2014). A graph-based optimization algorithm for fragmented image reassembly. Graphical Models, 76(5), 484–495." href="/article/10.1007/s11263-024-02033-7#ref-CR85" id="ref-link-section-d337817856e1721">2014</a>; Le &amp; Li, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Le, C., &amp; Li, X. (2019). Jigsawnet: Shredded image reassembly using convolutional neural network and loop-based composition. IEEE Transactions on Image Processing ." href="/article/10.1007/s11263-024-02033-7#ref-CR36" id="ref-link-section-d337817856e1724">2019</a>) use the pictorial content as well as geometrical boundaries to match pieces and reconstruct the puzzle. Sağıroğlu and Erçil (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Sağıroğlu, M. Ş, &amp; Erçil, A. (2010). Optimization for automated assembly of puzzles. Top, 18(2), 321–338." href="/article/10.1007/s11263-024-02033-7#ref-CR61" id="ref-link-section-d337817856e1727">2010</a>) used an extrapolation method to approximate the content of the pictorial data in a band around each piece. This allowed for a pictorial score by comparing the extrapolated bands to the content of prospective neighbors. Then, the Fourier transform translation property was used to find an alignment that maximizes the correlation between pieces while satisfying the geometrical constraints. The reconstruction itself was done in a greedy fashion, starting from a random configuration and improving the global score one piece at a time. To escape local minima, the reconstruction process was restarted multiple times with different random seed configurations. The experimental evaluation was limited to assemblies of 21 pieces, most of which had very distinctive boundaries. A related approach with fragment extrapolation for registration of neighboring candidates was proposed by Derech et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Derech, N., Tal, A., &amp; Shimshoni, I. (2021). Solving archaeological puzzles. Pattern Recognition, 108065." href="/article/10.1007/s11263-024-02033-7#ref-CR17" id="ref-link-section-d337817856e1730">2021</a>).</p><p>Recently, Le and Li (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Le, C., &amp; Li, X. (2019). Jigsawnet: Shredded image reassembly using convolutional neural network and loop-based composition. IEEE Transactions on Image Processing ." href="/article/10.1007/s11263-024-02033-7#ref-CR36" id="ref-link-section-d337817856e1736">2019</a>) introduced a novel approach for fragment matching using a Convolutional Neural Network that utilizes both boundary shape and pictorial data with a hierarchical loops approach for the reconstruction. The solver was tested successfully on puzzles of up to 400 pieces, significantly bigger than prior work. Moreover, evaluation was performed quantitatively and on a relatively large number of puzzle problems, two advances over the prior art in the unrestricted puzzle literature. That being said, the test data published alongside the paper contains a relatively constrained shape for the pieces as all of them were roughly perturbed rectangles.</p><p>It should be mentioned that much work on (typically apictorial) unrestricted puzzles is performed in the archaeological domain, where computational tools have generated a revolution (Grosman, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Grosman, L. (2016). Reaching the point of no return: The computational revolution in archaeology. Annual Review of Anthropology, 45, 129–145." href="/article/10.1007/s11263-024-02033-7#ref-CR27" id="ref-link-section-d337817856e1743">2016</a>) and visual puzzles are typically not 2D, but either 2.5D (“thick” 2D manifolds) or 3D. For their different focus we omit a detailed review of that literature, referring the reader to selected references from the last two decades (Papaioannou et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Papaioannou, G., Karabassi, E.-A., &amp; Theoharis, T. (2001). Virtual archaeologist: Assembling the past. IEEE Computer Graphics and Applications, 21, 53–59." href="/article/10.1007/s11263-024-02033-7#ref-CR53" id="ref-link-section-d337817856e1746">2001</a>; Papaodysseus et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Papaodysseus, C., Panagopoulos, T., Exarhos, M., Triantafillou, C., Fragoulis, D., &amp; Doumas, C. (2002). Contour-shape based reconstruction of fragmented, 1600 bc wall paintings. IEEE Transactions on Signal Processing, 50, 1277–1288." href="/article/10.1007/s11263-024-02033-7#ref-CR54" id="ref-link-section-d337817856e1749">2002</a>; Papaioannou &amp; Karabassi, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Papaioannou, G., &amp; Karabassi, E.-A. (2003). On the automatic assemblage of arbitrary broken solid artefacts. Image and Vision Computing, 21, 401–412." href="/article/10.1007/s11263-024-02033-7#ref-CR52" id="ref-link-section-d337817856e1752">2003</a>; Koller &amp; Levoy, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Koller, D., &amp; Levoy, M. (2006). Computer-aided reconstruction and new matches in the forma urbis romae. Bullettino Della Commissione Archeologica Comunale di Roma, 2, 103–125." href="/article/10.1007/s11263-024-02033-7#ref-CR33" id="ref-link-section-d337817856e1755">2006</a>; Huang et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Huang, Q., Flöry, S., Gelfand, N., Hofer, M., &amp; Pottmann, H. (2006). Reassembling fractured objects by geometric matching. ACM Transaction Graph., 25, 569–578." href="/article/10.1007/s11263-024-02033-7#ref-CR29" id="ref-link-section-d337817856e1759">2006</a>; Willis &amp; Cooper, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Willis, A., &amp; Cooper, D. (2008). Computational reconstruction of ancient artifacts. IEEE Signal Processing Magazine. 25." href="/article/10.1007/s11263-024-02033-7#ref-CR78" id="ref-link-section-d337817856e1762">2008</a>; Kleber &amp; Sablatnig, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Kleber, F., &amp; Sablatnig, R. (2009). A survey of techniques for document and archaeology artefact reconstruction. In ICDAR (pp. 1061–1065)." href="/article/10.1007/s11263-024-02033-7#ref-CR32" id="ref-link-section-d337817856e1765">2009</a>; Mellado et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Mellado, N., Reuter, P., &amp; Schlick, C. (2010). Semi-automatic geometry-driven reassembly of fractured archeological objects. In VAST." href="/article/10.1007/s11263-024-02033-7#ref-CR44" id="ref-link-section-d337817856e1768">2010</a>; Toler-Franklin et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Toler-Franklin, C., Brown, B. J., Weyrich, T., Funkhouser, T., &amp; Rusinkiewicz, S. (2010). Multi-feature matching of fresco fragments. In SIGGRAPH 2010." href="/article/10.1007/s11263-024-02033-7#ref-CR72" id="ref-link-section-d337817856e1771">2010</a>; Castañeda et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Castañeda, A., Brown, B. J., Rusinkiewicz, S., Funkhouser, T., &amp; Weyrich, T. (2011). Global consistency in the automatic assembly of fragmented artefacts. In VAST." href="/article/10.1007/s11263-024-02033-7#ref-CR11" id="ref-link-section-d337817856e1774">2011</a>; Funkhouser et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Funkhouser, T., Shin, H., Toler-Franklin, C., Castañeda, A., Brown, B. J., Dobkin, D., Rusinkiewicz, S., &amp; Weyrich, T. (2011). Learning how to match fresco fragments. ACM Journal on Computing and Cultural Heritage, 4, 7:1-7:13." href="/article/10.1007/s11263-024-02033-7#ref-CR21" id="ref-link-section-d337817856e1778">2011</a>; Oxholm &amp; Nishino, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Oxholm, G., &amp; Nishino, K. (2011). Reassembling thin artifacts of unknown geometry. In VAST." href="/article/10.1007/s11263-024-02033-7#ref-CR49" id="ref-link-section-d337817856e1781">2011</a>; Brown et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Brown, B. J., Laken, L., Dutré, P., Gool, L., Rusinkiewicz, S., &amp; Weyrich, T. (2012). Tools for virtual reassembly of fresco fragments. International Journal of Heritage in the Digital Era, 1, 313–329." href="/article/10.1007/s11263-024-02033-7#ref-CR8" id="ref-link-section-d337817856e1784">2012</a>; Shin et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Shin, H., Doumas, C., Funkhouser, T., Rusinkiewicz, S., Steiglitz, K., Vlachopoulos, A., &amp; Weyrich, T. (2012). Analyzing and simulating fracture patterns of theran wall paintings. Journal on Computing and Cultural Heritage (JOCCH), 5(3), 10." href="/article/10.1007/s11263-024-02033-7#ref-CR62" id="ref-link-section-d337817856e1787">2012</a>; Palmas et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Palmas, G., Pietroni, N., Cignoni, P., &amp; Scopigno, R. (2013). A computer-assisted constraint-based system for assembling fragmented objects. 2013 Digital Heritage International Congress (DigitalHeritage), 1, 529–536." href="/article/10.1007/s11263-024-02033-7#ref-CR51" id="ref-link-section-d337817856e1790">2013</a>; Pintus et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Pintus, R., Pal, K., Yang, Y., Weyrich, T., Gobbetti, E., &amp; Rushmeier, H. E. (2014) Geometric analysis in cultural heritage. In GCH, pp. 117–133." href="/article/10.1007/s11263-024-02033-7#ref-CR56" id="ref-link-section-d337817856e1793">2014</a>; Mavridis et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Mavridis, P., Andreadis, A., &amp; Papaioannou, G. (2015). Fractured object reassembly via robust surface registration. In Eurographics." href="/article/10.1007/s11263-024-02033-7#ref-CR43" id="ref-link-section-d337817856e1797">2015</a>; Andaló et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Andaló, F. A., Carneiro, G., Taubin, G., Goldenstein, S., &amp; Velho, L. (2016). Automatic reconstruction of ancient Portuguese tile panels. Graphics Appl: IEEE Comput." href="/article/10.1007/s11263-024-02033-7#ref-CR5" id="ref-link-section-d337817856e1800">2016</a>; Brandão &amp; Marques, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Brandão, S., &amp; Marques, M. (2016). Hot tiles: A heat diffusion based descriptor for automatic tile panel assembly. In European conference on computer vision (pp. 768–782). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR7" id="ref-link-section-d337817856e1803">2016</a>; Li et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Li, Q., Geng, G., &amp; Zhou, M. (2020). Pairwise matching for 3d fragment reassembly based on boundary curves and concave-convex patches. IEEE Access, 8, 6153–6161." href="/article/10.1007/s11263-024-02033-7#ref-CR37" id="ref-link-section-d337817856e1806">2020</a>; Ylmaz &amp; Nabiyev, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2023" title="Ylmaz, S., &amp; Nabiyev, V. V. (2023). Comprehensive survey of the solving puzzle problems. Computer Science Review, 50, 100586." href="/article/10.1007/s11263-024-02033-7#ref-CR84" id="ref-link-section-d337817856e1809">2023</a>; Markaki &amp; Panagiotakis, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2023" title="Markaki, S., &amp; Panagiotakis, C. (2023). Jigsaw puzzle solving techniques and applications: A survey. The Visual Computer, 39(10), 4405–4421." href="/article/10.1007/s11263-024-02033-7#ref-CR42" id="ref-link-section-d337817856e1812">2023</a>). That being said, the computational flow in most of these studies is similar and constitutes several steps, including scanning the artifacts to point clouds, processing these point clouds into meshes, segmenting the meshes to facets, and extracting geometrical features either on the facets or their boundary curves. Facets of different fragments are then registered through the raw geometrical point cloud data (e.g., using ICP) or the processed features. The final stage of combining the pairwise matches into a global assembly is done with a variety of methods, often including human intervention.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="207"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>In (generic) crossing cuts puzzles only matings of type 1 are allowed, while configurations of type 2 or 3 are prohibited. In particular, mates must be of equal length and overlap</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Fig. 5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="457"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>The mate angle constraint dictates <span class="mathjax-tex">\(\alpha _1 + \beta _1 = \alpha _2 + \beta _2=\pi \)</span></p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec6"><span class="c-article-section__title-number">2.4 </span>A Missing Link in the Puzzle Solving Chain?</h3><p>The scientific background covered above suggests that even though the basic problem is one, research into visual puzzle solving has been conducted in “parallel tracks” that affected progress in ways that are not necessarily optimal. Related to this are observations like the following</p><ul class="u-list-style-bullet">
                  <li>
                    <p>Solving commercial jigsaw puzzles computationally is very anecdotal in terms of its application value and serves mostly as an intellectual challenge.</p>
                  </li>
                  <li>
                    <p>Markedly inconsistent with the popularity of <span class="mathjax-tex">\(\mathcal {P_S}\)</span> in the literature, there are almost no real-life applications that can be abstracted as strict Square Jigsaw puzzles. For example, although most studies of Square Jigsaw puzzles cite archaeology as a possible application domain, archeological puzzles are virtually never square, and to our best knowledge there is exactly one case in the computational archeology literature for which Square Jigsaw puzzle solvers may be relevant (Brandão &amp; Marques, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Brandão, S., &amp; Marques, M. (2016). Hot tiles: A heat diffusion based descriptor for automatic tile panel assembly. In European conference on computer vision (pp. 768–782). Springer." href="/article/10.1007/s11263-024-02033-7#ref-CR7" id="ref-link-section-d337817856e1951">2016</a>).</p>
                  </li>
                  <li>
                    <p>Unrestricted puzzles do have the potential to serve numerous applications, but their unrestricted generation model makes it difficult to study them rigorously, obtain useful insights, or allow any type of guarantees related to the solution process. Rigorous analysis means answering questions about puzzle properties (e.g., the expected number of pieces in a puzzle, the statistical properties of the area of puzzle pieces, etc.) and about the developed algorithms (e.g., how many false positive matches may occur to determine the worst time complexity of a particular algorithmic step). Such understanding of the problem or the solutions is typically missing for this class.</p>
                  </li>
                  <li>
                    <p>The fact that <span class="mathjax-tex">\(\mathcal {P_U}\)</span>, <span class="mathjax-tex">\(\mathcal {P_S}\)</span>, and <span class="mathjax-tex">\(\mathcal {P_C}\)</span> are so different makes it practically impossible to apply tools (e.g., solvers or performance measures) from one class to another, even though both <span class="mathjax-tex">\(\mathcal {P_S}\)</span> and <span class="mathjax-tex">\(\mathcal {P_C}\)</span> are subsets of <span class="mathjax-tex">\(\mathcal {P_U}\)</span> (and under certain relaxation one can even view <span class="mathjax-tex">\(\mathcal {P_S}\)</span> as a subset of <span class="mathjax-tex">\(\mathcal {P_C}\)</span>). This gap manifests itself not only at the level of algorithms, but also in the representation of the problem (e.g., for I/O), data structures and formats used, and operational assumptions.</p>
                  </li>
                </ul><p>Generally speaking, a trade-off emerges between how constrained a puzzle class is, how relevant it is for real-life applications, how rigorous the analysis it permits, and how applicable are its solvers to other classes. Our present work tries to address this trade-off by suggesting a new puzzle generation model that is more restricted than <span class="mathjax-tex">\(\mathcal {P_U}\)</span> puzzles and thus allows rigorous analysis while being much more general than <span class="mathjax-tex">\(\mathcal {P_S}\)</span> and thus extends the applicability and usability to real-life challenges. In general, such an approach may refer to a new class of puzzles one may term <i>restricted modeled puzzles</i>, where some formal restrictions are defined for the puzzle generation process in a way that rigorous analysis is still possible while the range of applications remains viable. We hope that the present research will encourage the community to explore this direction further.</p></div></div></section><section data-title="Model Formulation"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7"><span class="c-article-section__title-number">3 </span>Model Formulation</h2><div class="c-article-section__content" id="Sec7-content"><p>Recall that the pieces (or fragments) of square jigsaw puzzles are all identical in shape, a setup that drives all reconstruction decisions to be solely pictorial. However, real-world puzzles usually have pieces of a more general form (e.g., Shin et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Shin, H., Doumas, C., Funkhouser, T., Rusinkiewicz, S., Steiglitz, K., Vlachopoulos, A., &amp; Weyrich, T. (2012). Analyzing and simulating fracture patterns of theran wall paintings. Journal on Computing and Cultural Heritage (JOCCH), 5(3), 10." href="/article/10.1007/s11263-024-02033-7#ref-CR62" id="ref-link-section-d337817856e2222">2012</a>), leading to a different set of challenges. Here we try to formulate a new class of puzzles that is both general enough for more real-world cases and yet formal enough for rigorous analysis and exploration. We call this class the <i>crossing cuts puzzles</i>.</p><p>A crossing cuts puzzle is created by cutting through a convex polygon<sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> with <span class="mathjax-tex">\(a \in \mathbb {N}\)</span> arbitrary (random) straight cuts <span class="mathjax-tex">\(Cuts = \{c_1, \dots c_a\}\)</span>. The pieces of such puzzles are thus convex polygons where every piece (except border pieces) has a single neighbor along each of its edges. This puzzle generation model is inspired by the procedure that produces the Lazy Caterer’s sequence<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> (Wetzel, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1978" title="Wetzel, J. E. (1978). On the division of the plane by lines. The American Mathematical Monthly, 85(8), 647–656." href="/article/10.1007/s11263-024-02033-7#ref-CR77" id="ref-link-section-d337817856e2336">1978</a>; Yaglom &amp; Yaglom, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Yaglom, A. M., &amp; Yaglom, I. M. (1987). Challenging Mathematical Problems with Elementary Solutions, vol. 1. Dover Publications." href="/article/10.1007/s11263-024-02033-7#ref-CR80" id="ref-link-section-d337817856e2340">1987</a>), but unlike the latter, in our case, the cuts are completely arbitrary and there is neither guarantee nor desire to maximize the number of pieces.<sup><a href="#Fn4"><span class="u-visually-hidden">Footnote </span>4</a></sup> This proposed model can also be used to address and simulate the <i>realistic</i> and/or <i>physical</i> generation of puzzles already discussed in literature, such as square jigsaw puzzles. For example, while using a pair of scissors or a ruler and a blade, one can create a real-life square jigsaw puzzle by cutting a picture, where cuts are not strictly parallel or equidistant due to human error or lack of sensitivity. The result will be a <i>noisy</i> square jigsaw puzzle (see below), which is a crossing cut puzzle.</p><p>Geometrically, square piece puzzles are indeed a very special case of crossing cuts puzzles and thus the latter require a more general mechanism to represent them. Towards that end, and inspired by Freeman and Garder (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1964" title="Freeman, H., &amp; Garder, L. (1964). Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition. IEEE Transactions on Electronic Computers, 2, 118–127." href="/article/10.1007/s11263-024-02033-7#ref-CR20" id="ref-link-section-d337817856e2361">1964</a>), we define the <i>mating graph</i> to be a planar graph whose nodes are the edges of the puzzle pieces and whose links,<sup><a href="#Fn5"><span class="u-visually-hidden">Footnote </span>5</a></sup> dubbed <i>matings</i>, represent immediate neighborhood relationship. The connected pieces will be called <i>neighbors</i> or <i>neighboring pieces</i> while the edges matched by a mating will be called <i>mates</i>. Note that in the ideal case, when no geometric noise is present, a mating in the solved puzzle represents two overlapping mates with identical lengths.</p><p>Unlike in square piece (and also commercial toy) jigsaw puzzles, which have a constant number of neighbors for each piece (except boundary pieces), the mating graph of a crossing cuts puzzle is more general since the number of matings a piece can have varies (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig2">2</a>A–C). Moreover, the number of possible Euclidean transformations of the pieces of crossing cuts puzzles adds additional complexity, since unlike for square or toy puzzles, it is infinite in cardinality and selected from a continuous range. Hence, on the one hand, the representation of the puzzle must account for these new degrees of freedom. On the other hand, the geometrical shape of the pieces provides more information that is not present in the square jigsaw problem and may facilitate reconstruction algorithms that rely only on the shape of the pieces. Just as in any other type of puzzles (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec2">2</a>), an <i>apictorial</i> crossing cuts puzzle is one whose initial polygon contains no visual content (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig2">2</a>A, B) while a <i>pictorial</i> crossing cuts puzzle is generated from a polygon covered with an image. (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig2">2</a>D, E). In this paper, we start our analysis with apictorial puzzles and gradually incorporate pictorial aspects while arguing that under most realistic scenarios, pictorial content is critical for successful and efficient crossing cuts puzzle solvers.</p><p>To facilitate a constructive discussion towards computational solutions to our problem, one needs to differentiate the representation of the puzzle itself (in the sense of the riddle to solve) and its possible solutions. A crossing cuts <i>puzzle</i> is thus a representation of the unordered puzzle pieces after the complete polygon was cut (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig2">2</a>B, E). Formally, let <span class="mathjax-tex">\(P = \{p_1, \dots p_n\}\)</span> be a set of <i>pieces</i>, where each <span class="mathjax-tex">\(p_i\)</span> is a convex polygon of <span class="mathjax-tex">\(N_i \ge 3\)</span> vertices. By convention, we order these vertices clockwise around the polygon’s center of mass and denote them</p><div id="Equ19" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} V_i = \left\{ \vec {v\,}_i^{1}, \vec {v\,}_i^{2},\dots , \vec {v\,}_i^{N_i}\right\} \;. \end{aligned}$$</span></div></div><p>Correspondingly we label the piece edges between these consecutive vertices by</p><div id="Equ20" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E_i = \left\{ {e_i^1} , {e_i^2} ,\ldots , {e_i^{N_i}} \right\} = \left\{ (\vec {v\,}_i^1, \vec {v\,}_i^2 ) , (\vec {v\,}_i^2, \vec {v\,}_i^3 ) ,\ldots , (\vec {v\,}_i^{N_i}, \vec {v\,}_i^1 ) \right\} \;. \end{aligned}$$</span></div></div><p> A <i>solution</i> to a crossing cuts puzzle requires positioning each piece in its ”correct” position relative to all other pieces, and while this requires the determination of a Euclidean transformation (position and rotation) for each piece, in practice this will first require to resolve the neighborhood relationships between the pieces, i.e., the ”correct” mating graph. An algorithm to obtain a solution thus needs to determine both </p><ol class="u-list-style-none">
                <li>
                  <span class="u-custom-list-number">i.</span>
                  
                    <p>the pairwise matings <span class="mathjax-tex">\(M = \left\{ m_1, \dots m_{|M|}\right\} \)</span> of all pieces, i.e., all unordered pairs of edges <span class="mathjax-tex">\(m_q=\{ e_i^j, e_k^l \}\)</span> of two different pieces that should be matched (and in an ideal setting, truly overlap) in order to reconstruct the puzzle, and</p>
                  
                </li>
                <li>
                  <span class="u-custom-list-number">ii.</span>
                  
                    <p>the 2D Euclidean transformation of each piece <span class="mathjax-tex">\(p_i\)</span>, from its given input representation <span class="mathjax-tex">\(V_i\)</span> to the one in the reconstructed puzzle. The transformation of piece <span class="mathjax-tex">\(p_i\)</span> involves a translation <span class="mathjax-tex">\(t_i \in \mathcal {R}^2\)</span> and a rotation <span class="mathjax-tex">\(R_i \in \mathcal {S}^1\)</span>. With the rotation typically represented by an orthonormal matrix <span class="mathjax-tex">\(R_i \in \mathcal {R}^{2 \times 2}\)</span>, the pose of the piece in the reconstructed puzzle will be </p><div id="Equ21" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} p_i' = \left\{ R_i \cdot \vec {v\,}_i^1 + \vec {t\,}_i, R_i \cdot \vec {v\,}_i^2 + \vec {t\,}_i,\ldots , R_i \cdot \vec {v\,}_i^{N_i} + \vec {t\,}_i\right\} \end{aligned}$$</span></div></div>
                  
                </li>
              </ol><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig3">3</a> illustrates both the puzzle and the aspects of its solution as just discussed. It should be noted that while the mating graph may have only one “correct” solution, the Euclidean transformations of the pieces can be correct up to some global Euclidean transformation that describes a rigid motion of the entire reconstructed puzzle.</p></div></div></section><section data-title="Mating Constraints and a Greedy Solver"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8"><span class="c-article-section__title-number">4 </span>Mating Constraints and a Greedy Solver</h2><div class="c-article-section__content" id="Sec8-content"><p>With the crossing cuts puzzles defined as above, and assuming no noise, idealized infinite precision in the representation of the geometrical objects, and random uniform distribution of the crossing cuts themselves, it is immediate to observe that the probability of (i) more than two crossing cuts to meet at a point, and (ii) having more than two edges with <i>identical</i> lengths, is nil in both cases. These properties of the <i>generic</i> (i.e., non-accidental) puzzle entail two key constraints for the formation of plausible matings: </p><dl class="c-abbreviation_list"><dt class="c-abbreviation_list__term u-text-bold u-float-left u-pr-16" style="min-width:50px;"><dfn><span class="mathjax-tex">\(C_1\)</span>::</dfn></dt><dd class="c-abbreviation_list__description u-mb-24">
                    <p><i>The mate length constraint</i> Since plausible matings should match complete edges, it follows that they must match mates of the very same length (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig4">4</a>).</p>
                  </dd><dt class="c-abbreviation_list__term u-text-bold u-float-left u-pr-16" style="min-width:50px;"><dfn><span class="mathjax-tex">\(C_2\)</span>::</dfn></dt><dd class="c-abbreviation_list__description u-mb-24">
                    <p><i>The mate angle constraint</i> Since the mates of plausible matings have vertices emerging from just 2 crossing cuts, their adjacent edges must form a straight line (which simply overlaps with two different crossing cuts). It follows that the two pairs of adjacent angles of the neighboring pieces must complete to <span class="mathjax-tex">\(\pi \)</span>, i.e., be supplementary (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig5">5</a>).</p>
                  </dd></dl><p>In the following, we will refer to the mating constraints also as predicates, i.e.,</p><div id="Equ22" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \forall i\in \{1,2\} \quad C_i\left( e_i^j, e_k^l\right) = \text {true} \; \Leftrightarrow \; e_i^j\text { and }e_k^l \text { satisfy } C_i \;. \end{aligned}$$</span></div></div><p>Clearly, the constraints just outlined entail the simple and <i>greedy</i> solver in Algorithm 1 that progressively moves pieces from the set <i>U</i> of unassigned pieces to the set <i>R</i> of the reconstructed assembly, while forming the mating graph <span class="mathjax-tex">\(G_M\)</span>. This simple algorithm uses only constraint <span class="mathjax-tex">\(C_1\)</span>, but versions using <span class="mathjax-tex">\(C_2\)</span> are possible also. Either case, these greedy schemes are clearly sound, complete, and tractable, they do not need pictorial information and they can solve both apictorial and pictorial puzzles using the geometric information alone. As we discuss shortly, all this changes fundamentally once we introduce geometric noise to the puzzle.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-a" data-title="Algorithm 1"><figure><figcaption><b id="Figa" class="c-article-section__figure-caption" data-test="figure-caption-text">Algorithm 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/a" rel="nofollow"><picture><img aria-describedby="Figa" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Figa_HTML.png" alt="figure a" loading="lazy" width="685" height="218"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-a-desc"><p> A basic greedy algorithm for solving crossing cuts puzzles under ideal conditions </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/a" data-track-dest="link:Figurea Full size image" aria-label="Full size image figure a" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="Noisy Crossing Cuts Puzzles"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9"><span class="c-article-section__title-number">5 </span>Noisy Crossing Cuts Puzzles</h2><div class="c-article-section__content" id="Sec9-content"><p>Real-world data, its measurement, or its representation, are never completely accurate. Even if the measurement or the digital representation of the pieces were devoid of errors, <i>real life</i> crossing cuts puzzles (or geometric puzzles in general) may incorporate deformations to the shapes of the pieces, as well as to their visual content (in pictorial puzzles). In fact, geometric noise also affects how pictorial information can be leveraged, even if no pictorial noise is present. For this reason we begin by formalizing the geometric noise, and extend the discussion to pictorial puzzles only later.</p><p>Clearly, geometric noise can be modeled in many different ways, though one particular appealing is material degradation, and thus piece shrinkage, a process clearly relevant for applications involving physical pieces (e.g. in archaeology). To incorporate material degradation without escaping the crossing cuts framework, we model this deformation process by preserving the number of vertices of each piece, but shifting each of them <i>inward</i> by a random distance that is distributed (in our case, uniformly) in a given range. We note that the particular distribution of such noise may affect certain statistical properties (see Chapter <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec20">7</a> below), but otherwise it is less significant for the reconstruction algorithm discussed later.</p><h3 class="c-article__sub-heading" id="Sec10"><span class="c-article-section__title-number">5.1 </span>Noise Formulation</h3><p>Formally, a vertex <span class="mathjax-tex">\(\vec {v\,}_i^j\)</span> of piece <span class="mathjax-tex">\(p_i\)</span> is perturbed inwards by a distance <span class="mathjax-tex">\(\vec {\epsilon \,}_i^j\)</span> that is bounded by some maximal noise level <span class="mathjax-tex">\(\varepsilon \ge 0\)</span>. It is convenient to set that bound relative to a reference value that is based on the puzzles’ geometrical properties. In our case, we use the puzzle diameter <i>D</i>, i.e., the distance between the furthest vertices. Formally, we define a relative bound <span class="mathjax-tex">\(\xi \)</span> that sets the absolute noise level at <span class="mathjax-tex">\(\varepsilon =\xi \cdot D\)</span>, and let <span class="mathjax-tex">\(\bar{\xi }\)</span> be the corresponding noise level relative to the average edge length (to be derived later). An original piece <span class="mathjax-tex">\(p_i = \left\{ \vec {v\,}_i^1, \dots \vec {v\,}_i^{N_i} \right\} \)</span> ends up as the <span class="mathjax-tex">\(\varepsilon \)</span>-noisy  piece <span class="mathjax-tex">\( \tilde{p}_i = \left\{ \vec {v\,}_i^1 + \vec {\epsilon \,}_i^1, \dots , \vec {v\,}_i^{N_i} + \vec {\epsilon \,}_i^{N_i} \right\} \)</span> where the noise magnitude <span class="mathjax-tex">\(\left\Vert \vec {\epsilon \,}_i^j \right\Vert \sim \text {U}(0,\varepsilon )\)</span> and the noise direction is selected from the sector originating from <span class="mathjax-tex">\(\vec {v\,}_i^j\)</span> towards the two nearby vertices, namely <span class="mathjax-tex">\(\measuredangle \vec {\epsilon \,}_i^j \sim \text {U} \left( \measuredangle \left( \vec {v_i^{j - 1}\,} - \vec {v_i^j\,} \right) , \measuredangle \left( \vec {v_i^{j + 1}\,} - \vec {v_i^j\,} \right) \right) \)</span>. This limits the random perturbation angle of <span class="mathjax-tex">\(\vec {\epsilon \,}_i^j\)</span> and constrains it to be <i>inward</i>, i.e., an erosion-like process “into” the material. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig6">6</a>A illustrates how such noise could affect the shape of a quadrilateral (4-edges) piece.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Fig. 6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="402"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>The effect of noise on edge length. <b>A</b> Each of the vertices of a piece <span class="mathjax-tex">\(p_i\)</span> is perturbed inwards along a uniformly distributed direction <span class="mathjax-tex">\(\measuredangle \vec {\epsilon \,}_i^j\)</span> and as far as a uniformly distributed distance <span class="mathjax-tex">\(||\vec {\epsilon \,}_i^j||\)</span> to create the <span class="mathjax-tex">\(\varepsilon \)</span>-noisy piece <span class="mathjax-tex">\(\tilde{p}_i\)</span>. <b>B</b> A case where edge <i>e</i> increases in size after the application of noise, even though all the vertices collapsed inwards to end up as <span class="mathjax-tex">\(\tilde{e}\)</span>. Clearly, <span class="mathjax-tex">\(||\tilde{e}||\)</span> is bounded by <span class="mathjax-tex">\(||e||+2\varepsilon \)</span></p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Naturally, the incorporation of noise affects the validity of our constraints on mating. In particular, the number of potential mates now increases drastically and far from uniqueness, and the implications on a reconstruction algorithm are paramount. In this sense, <span class="mathjax-tex">\(C_1\)</span> and <span class="mathjax-tex">\(C_2\)</span> must be revised, as discussed next.</p><h3 class="c-article__sub-heading" id="Sec11"><span class="c-article-section__title-number">5.2 </span>
                           <span class="mathjax-tex">\(\tilde{C}_1\)</span>: Mate Length Constraint Under Noise</h3><p>Since now plausible matings should match edges that have been perturbed differently, the mate length constraint must be relaxed to accommodate these independent perturbations. Let <i>e</i> and <span class="mathjax-tex">\(e'\)</span> be the matching edges before applying the noise while <span class="mathjax-tex">\(\tilde{e}\)</span> and <span class="mathjax-tex">\(\tilde{e}'\)</span> denote their corresponding <span class="mathjax-tex">\(\varepsilon \)</span>-noisy edges. It follows that <span class="mathjax-tex">\(\tilde{e}\)</span> and <span class="mathjax-tex">\(\tilde{e}'\)</span> might have respective lengths <span class="mathjax-tex">\(\tilde{L}\)</span> and <span class="mathjax-tex">\(\tilde{L}'\)</span> that satisfy</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} |\tilde{L} - \tilde{L}'| \le 4 \varepsilon \;. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (1)
                </div></div><p>The maximum error (<span class="mathjax-tex">\(4 \varepsilon \)</span>) can occur when one of the edges is shortened by <span class="mathjax-tex">\(2\varepsilon \)</span> and the other is lengthened by <span class="mathjax-tex">\(2\varepsilon \)</span>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig6">6</a>B exemplifies how edges may become longer even though the deformation represents the <i>erosion</i> of material.</p><h3 class="c-article__sub-heading" id="Sec12"><span class="c-article-section__title-number">5.3 </span>
                           <span class="mathjax-tex">\(\tilde{C}_2\)</span>: Mate Angle Constraint Under Noise</h3><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Fig. 7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig7_HTML.png?as=webp"><img aria-describedby="Fig7" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig7_HTML.png" alt="figure 7" loading="lazy" width="685" height="201"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>If the “clean” edge <i>e</i> (in green) stretches (w.l.o.g) from <span class="mathjax-tex">\(u_1 = (0,0)\)</span> to <span class="mathjax-tex">\(u_2 = (L, 0)\)</span>, the vertices of the <span class="mathjax-tex">\(\varepsilon \)</span>-noisy edge must lie inside the corresponding error zones (in cyan). When considering the angle of the <span class="mathjax-tex">\(\varepsilon \)</span>-noisy edge <span class="mathjax-tex">\(\tilde{e}\)</span> (in red), the worst case occurs when one of the vertices (say, <span class="mathjax-tex">\(u_1\)</span>) is only perturbed horizontally by <span class="mathjax-tex">\(\varepsilon \)</span>, while the other (say, <span class="mathjax-tex">\(u_2\)</span>) is perturbed to maximize the rotation, i.e, to a point <span class="mathjax-tex">\(\tilde{u}_2 = (\tilde{x}, \tilde{y})\)</span> that makes <span class="mathjax-tex">\(\tilde{e}\)</span> tangent to the error zone. This bound is expressed in Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ2">2</a> (Color figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>While it is clear that vertices of neighboring pieces may not meet if either sustains noise, and thus may no longer be expected to generate two supplementary angles in a strict way, one can still bound the deviation from that ideal behavior. To do so we first analyze the effect of noise on the degree of rotation of any single edge relative to its noiseless configuration and then leverage that result for the desired bound on the angles of mating edges under noise. </p><ol class="u-list-style-none">
                  <li>
                    <span class="u-custom-list-number">i.</span>
                    
                      <p><span class="mathjax-tex">\({{\mathbf{Bound\, on\, the\, rotation\, of\, a\, single }}\, \varepsilon -\mathrm{noisy~ edge}}\)</span></p>
                      <p>Let <span class="mathjax-tex">\(e = (\vec {u}_1, \vec {u}_2)\)</span> be an edge (of some puzzle piece) with coordinates <span class="mathjax-tex">\(\vec {u}_1= (x_1, y_1), \vec {u}_2=(x_2, y_2)\)</span> and size <span class="mathjax-tex">\({\left\Vert \vec {u}_1-\vec {u}_2\right\Vert =L}\)</span>, and assume (without loss of generality) that this edge is aligned with the origin and the <i>X</i> axis of some reference coordinate frame and thus stretches from <span class="mathjax-tex">\(\vec {u}_1 = (0, 0) \)</span> to <span class="mathjax-tex">\(\vec {u}_2 = (L, 0)\)</span>. The orientation of this edge is of course <span class="mathjax-tex">\(\measuredangle e=0^{o}\)</span>, as illustrated by the green edge in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig7">7</a>.    Let us now denote by <span class="mathjax-tex">\(\tilde{e} = (\vec {\tilde{u}}_1, \vec {\tilde{u}}_2) = ((\tilde{x}_1, \tilde{y}_1),(\tilde{x}_2, \tilde{y}_2))\)</span> the same edge after applying the noise. Except for accidental cases, the orientation <span class="mathjax-tex">\(\measuredangle \tilde{e}\)</span> will be different than <span class="mathjax-tex">\(\measuredangle e\)</span>, as was already exemplified in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig6">6</a>. Let <span class="mathjax-tex">\(\Delta \Theta _e(L, \varepsilon )\)</span> be the bound on the difference between these two orientations over all possible <span class="mathjax-tex">\(\varepsilon \)</span>-noisy edges <span class="mathjax-tex">\(\tilde{e}\)</span>, i.e., over all combinations of the noisy vertices <span class="mathjax-tex">\((\vec {\tilde{u}}_1, \vec {\tilde{u}}_2)\)</span> that are possible under the noise model. In our case, </p><div id="Equ23" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \Delta \Theta _e(L, \varepsilon )&amp;= \max _{\tilde{e}} \left| \measuredangle \tilde{e}- \measuredangle e \right| = \max _{\tilde{e}} \left| \measuredangle \tilde{e}\right| \;. \end{aligned}$$</span></div></div>
                      <p>To obtain the maximal (i.e. worst case) orientation change <span class="mathjax-tex">\(\Delta \Theta _e\)</span> while the vertices of <span class="mathjax-tex">\(\tilde{e}\)</span> remain in their respective error zones (cyan semi-disks in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig7">7</a>), it is needed to perturb one of the vertices only horizontally while the other is perturbed vertically as much as possible. This happens when <span class="mathjax-tex">\(\tilde{e}\)</span> becomes tangent to the error zone as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig7">7</a> and thus the bound is: </p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \Delta \Theta _e(L, \varepsilon ) = {\left\{ \begin{array}{ll} \arcsin \left( \frac{\varepsilon }{L - \varepsilon } \right) &amp;{} L &gt; 2\varepsilon \\ \infty &amp;{} L \le 2 \varepsilon \end{array}\right. }\;\;. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (2)
                </div></div><p> Note that “short” edges (<span class="mathjax-tex">\(L \le 2 \varepsilon \)</span>) are special since the error zones intersect and thus the <span class="mathjax-tex">\(\varepsilon \)</span>-noisy edge might take arbitrary orientation or simply vanish altogether. In these cases, we set the bound to infinity (<span class="mathjax-tex">\(\infty \)</span>) to represent the fact that the angle constraint cannot contribute useful information and thus cannot be employed constructively. In practice, a finite value of <span class="mathjax-tex">\(\frac{\pi }{2}\)</span> (the bound of <span class="mathjax-tex">\(\arcsin \)</span>) can serve our purpose equally well.</p>
                      <p>Equation <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ2">2</a> requires the length of the original (“clean”) edge <i>L</i>, but in practice only <span class="mathjax-tex">\(\tilde{L}\)</span> can be measured. However, following the same arguments behind constraint <span class="mathjax-tex">\(\tilde{C}_1\)</span> (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec11">5.2</a>), it holds that <span class="mathjax-tex">\(L \ge \tilde{L} - 2\varepsilon \)</span> and this lower bound can be used as a worst case. We therefore conclude that an <span class="mathjax-tex">\(\varepsilon \)</span>-noisy edge <span class="mathjax-tex">\(\tilde{e}\)</span> with length <span class="mathjax-tex">\(\tilde{L}\)</span> might be rotated relative to the original “clean” edge no more than </p><div id="Equ3" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \Delta \Theta _e(L, \varepsilon ) \le {\left\{ \begin{array}{ll} \arcsin \left( \frac{\varepsilon }{\tilde{L} - 3 \varepsilon } \right) &amp;{} \tilde{L} &gt; 4\varepsilon \\ \infty &amp;{} \tilde{L} \le 4 \varepsilon \end{array}\right. } \;. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (3)
                </div></div>
                    
                  </li>
                  <li>
                    <span class="u-custom-list-number">ii.</span>
                    
                      <p><b>Bound on the angle difference of two corresponding mates</b></p>
                      <p>Let <i>e</i> and <span class="mathjax-tex">\(e'\)</span> be two “clean” mates and denote the corresponding lengths of the edges <i>before</i>, <i>at</i>, and <i>after</i> these mates as <span class="mathjax-tex">\(L_{-1}, L_{0}, L_{1}\)</span> and <span class="mathjax-tex">\(L'_{-1}, L'_{0}, L'_{1}\)</span>, respectively, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig8">8</a>A. Let <span class="mathjax-tex">\(\alpha _1, \beta _1\)</span> and <span class="mathjax-tex">\(\alpha _2, \beta _2\)</span> be the two pairs of supplementary angles these mates form with their adjacent edges at their vertices, also as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig8">8</a>A. Recall that the mate angle constraint <span class="mathjax-tex">\(C_2\)</span> dictates that </p><div id="Equ24" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;\alpha _1 + \beta _1 = \alpha _2 + \beta _2 = \pi \;\;. \end{aligned}$$</span></div></div>
                      <p>Let <span class="mathjax-tex">\(\tilde{\alpha }_i, \tilde{\beta }_i\)</span> <span class="mathjax-tex">\(i\in \{1,2\}\)</span> be the angles corresponding to <span class="mathjax-tex">\(\alpha _i, \beta _i\)</span> after applying the noise, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig8">8</a>B. It is clear that the bound on how different <span class="mathjax-tex">\(\tilde{\alpha }_i, \tilde{\beta }_i\)</span> from their “clean” versions <span class="mathjax-tex">\(\alpha _i, \beta _i\)</span> is determined by the maximal change of orientation of each of their constituent rays (i.e., edges), as expressed in Eqs. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ2">2</a>,<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ3">3</a>. We thus get </p><div id="Equ25" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;|\alpha _1 - \tilde{\alpha }_1| \le \Delta \Theta _e (L_0,\varepsilon ) + \Delta \Theta _e (L_{-1},\varepsilon )\\&amp;|\alpha _2 - \tilde{\alpha }_2| \le \Delta \Theta _e (L_0,\varepsilon ) + \Delta \Theta _e (L_{1},\varepsilon )\\&amp;|\beta _1 - \tilde{\beta }_1| \le \Delta \Theta _e (L'_0,\varepsilon ) + \Delta \Theta _e (L'_{-1},\varepsilon )\\&amp;|\beta _2 - \tilde{\beta }_2| \le \Delta \Theta _e (L'_0,\varepsilon ) + \Delta \Theta _e (L'_{1},\varepsilon ) \end{aligned}$$</span></div></div><p> Combining with the mate angle constraint we obtain </p><div id="Equ26" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} |\pi - \tilde{\alpha }_1 - \tilde{\beta }_1| \le&amp;\Delta \Theta _e (L_0,\varepsilon ) + \Delta \Theta _e (L_{-1},\varepsilon ) +\\&amp;\Delta \Theta _e (L'_0,\varepsilon ) + \Delta \Theta _e (L'_{-1},\varepsilon )\\ |\pi - \tilde{\alpha }_2 - \tilde{\beta }_2| \le&amp;\Delta \Theta _e (L_0,\varepsilon ) + \Delta \Theta _e (L_{1},\varepsilon ) +\\&amp;\Delta \Theta _e (L'_0,\varepsilon ) + \Delta \Theta _e (L'_{1},\varepsilon ) \;, \end{aligned}$$</span></div></div><p> and finally we apply the bound in Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ3">3</a> to reflect the fact that the true edge lengths are unknown. <span class="mathjax-tex">\(\tilde{C}_2\)</span>, the final mate angle constraint under noise thus incorporates the following two inequalities </p><div id="Equ27" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {\begin{matrix} |\pi \!- \!\tilde{\alpha }_1 \!-\! \tilde{\beta }_1| &amp;{}\le \Delta \Theta _e(\tilde{L}_0 - 2\varepsilon ,\varepsilon ) \!+\! \Delta \Theta _e(\tilde{L}_{-1} - 2\varepsilon ,\varepsilon )\\ &amp;{}\quad + \Delta \Theta _e(\tilde{L}'_0 \!- \!2\varepsilon ,\varepsilon ) \!+\! \Delta \Theta _e(\tilde{L}'_{-1} \!- \!2\varepsilon ,\varepsilon ) \end{matrix}}\\ {\begin{matrix} |\pi \!-\! \tilde{\alpha }_2\! -\! \tilde{\beta }_2| &amp;{}\le \Delta \Theta _e(\tilde{L}_0 - 2\varepsilon ,\varepsilon )\! +\! \Delta \Theta _e(\tilde{L}_{1} - 2\varepsilon ,\varepsilon )\\ &amp;{}\quad + \Delta \Theta _e(\tilde{L}'_0 - 2\varepsilon ,\varepsilon )\! +\! \Delta \Theta _e(\tilde{L}'_{1} \!-\! 2\varepsilon ,\varepsilon ) \;\;. \end{matrix}} \end{aligned}$$</span></div></div>
                    
                  </li>
                </ol><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8" data-title="Fig. 8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/8" rel="nofollow"><picture><img aria-describedby="Fig8" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig8_HTML.png" alt="figure 8" loading="lazy" width="685" height="187"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>The effect of noise on the mate angle constraint. <b>A</b> Without noise, angles must comply to the original constraint <span class="mathjax-tex">\(\alpha _1 + \beta _1 = \alpha _2 + \beta _2= \pi \)</span>. <b>B</b> After applying the noise the <span class="mathjax-tex">\(\varepsilon \)</span>-noisy angles are affected by the change in orientation in all edges that meet at both vertices of both mates, to result in the bound in the text</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/8" data-track-dest="link:Figure8 Full size image" aria-label="Full size image figure 8" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>To conclude this analysis, and similar to the mating constraints in the “clean” case, we may refer to the noisy mating constraints as predicates:</p><div id="Equ28" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \forall i\in \{1,2\} \quad \tilde{C}_i\left( e_i^j, e_k^l\right) = \text {true} \; \Leftrightarrow \; e_i^j\text { and }e_k^l \text { satisfy } \tilde{C}_i \;. \end{aligned}$$</span></div></div><h3 class="c-article__sub-heading" id="Sec13"><span class="c-article-section__title-number">5.4 </span>Noise-Induced Erased Pieces</h3><p>An inevitable consequence of applying erosion to a puzzle with pieces of various sizes is the potential risk of piece disappearance. Not unlike in the physical world, relatively smaller pieces are at greater risk of being completely eroded and thus practically disappear. In practice, in our noise model, this happens if the random inward perturbation applied to a vertex pushes it beyond some other boundary of the piece, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig9">9</a>. The result of course is a noisy puzzle with <i>missing</i> pieces.</p><p>In our present work, missing pieces are not yet handled and solving puzzles with missing pieces is left for future work, as it is likely to require a completely different approach. At present, the possibility of missing pieces due to geometric noise can be reduced or even prevented by using a <i>softer</i> noise model based on a smaller adaptive bound (for example, piece-adapted noise bound defined by the piece’s shortest edge).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9" data-title="Fig. 9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig9_HTML.png?as=webp"><img aria-describedby="Fig9" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig9_HTML.png" alt="figure 9" loading="lazy" width="685" height="242"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Example of a triangular piece being <i>disqualified</i> thus <i>erased</i> as a result of being exposed to relatively large noise, applied to each of the piece’s vertices in clockwise order. <b>A</b> The original ’clean’ piece. <b>B</b> Noise is applied to the first vertex, pushing it down. <b>C</b> Noise is applied to the second vertex, pushing it left. <b>D</b> Noise is applied to the last vertex, pushing it right beyond the current piece border, thus eliminating it</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/9" data-track-dest="link:Figure9 Full size image" aria-label="Full size image figure 9" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec14"><span class="c-article-section__title-number">5.5 </span>Pictorial Noisy Puzzles</h3><p>Just like apictorial crossing cuts puzzles, their pictorial counterpart can also be contaminated by geometric noise. A typical pictorial noisy crossing cut puzzle is depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig10">10</a>A and since it is impossible to observe the noise when the pieces are shuffled, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig10">10</a>B puts several pieces in place to demonstrate the consequences. It is easy to observe that even if the pictorial content is immune to image noise, the geometric noise distances the pictorial content that <i>is</i> available in different puzzle pieces and thus complicates the way it can be used to determine plausible mates. We discuss a scheme that addresses the latter challenge in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec30">8</a>.</p></div></div></section><section data-title="Data Synthesis"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15"><span class="c-article-section__title-number">6 </span>Data Synthesis</h2><div class="c-article-section__content" id="Sec15-content"><p>Since there is no previous work on crossing cuts puzzles, no data or benchmark results exist either. Part of our contribution here is a mechanism for data synthesis, as well as the first public dataset of crossing cuts puzzles. Such synthesis tools and datasets facilitate both the exploration of valuable properties of such puzzles and the experimental evaluation of reconstruction algorithms.</p><p>The synthesis process is based on a computational procedure that receives as input a description of the global polygonal shape <i>S</i> (which could be specified by the user or selected at random; see below) and the crossing cuts <span class="mathjax-tex">\(Cuts = \{c_1, \dots c_a\}\)</span> that dissect it. It returns both the <i>puzzle</i>, which can be given as input to reconstruction algorithms and the <i>ground truth solution</i> that can be used to evaluate the performance of puzzle solvers. As discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec7">3</a>, the puzzle is a bag of polygonal pieces <span class="mathjax-tex">\(P=\{p_1, \dots p_n\}\)</span>, each represented properly by its vertices in some coordinate frame of reference. The ground truth solution constitutes a representation of the mating graph (and in particular, the set <i>M</i> of its matings), as well as the Euclidean transformations <span class="mathjax-tex">\(((R_1, t_1), \dots (R_n, t_n))\)</span> that place the pieces correctly in the reconstructed puzzle (or equivalently, the coordinates of the vertices of all pieces).</p><p>The process of synthesizing crossing cuts puzzles thus constitutes several aspects, all of which are described next for the sake of reproducibility. We note that pictorial puzzles are produced similarly to apictorial ones while the global polygonal shape is covered ahead of time by some pictorial content (e.g., from a user-provided image).</p><h3 class="c-article__sub-heading" id="Sec16"><span class="c-article-section__title-number">6.1 </span>A Graph Representation for Planar Divisions</h3><p>Let <span class="mathjax-tex">\(S \subseteq R^2\)</span> be a polygonal puzzle shape. The first stage of data synthesis is to construct a puzzle planar graph <span class="mathjax-tex">\(\mathcal {G}_{puzzle} = (\mathcal {V},\mathcal {E})\)</span> that represents both the boundary of <i>S</i> and the cuts that go through it. Note that <span class="mathjax-tex">\(\mathcal {G}_{puzzle}\)</span> is different from the mating graph and is maintained for the synthesis process only. Toward that end, we first combine both the boundary lines of <i>S</i> (dashed blue lines in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig11">11</a>) and the crossing cuts themselves (dashed red lines in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig11">11</a>) into one set of lines:</p><div id="Equ29" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \mathcal {C}&amp;= Cuts \cup \{\text {edge lines of }S\}\;. \end{aligned}$$</span></div></div><p>The particular representation of lines is secondary, but in our case we represent each of them as a triplet <span class="mathjax-tex">\((a_1, a_2, a_3)\)</span>, where <span class="mathjax-tex">\(a_i\)</span> are the coefficients of the line equation <span class="mathjax-tex">\(a_1 x + a_2 y + a_3 = 0\)</span> in some global coordinate system.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10" data-title="Fig. 10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig10_HTML.jpg?as=webp"><img aria-describedby="Fig10" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig10_HTML.jpg" alt="figure 10" loading="lazy" width="685" height="418"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Example of a noisy pictorial crossing cut puzzle. <b>A</b> A noisy pictorial crossing cuts puzzle is an unordered set of pictorial <i>noisy</i> pieces and recall that the noise is geometrical, not pictorial. The four pieces highlighted in purple are those shown in the next panel. <b>B</b> A closeup on four pictorial neighbors in their original position after they are cut from the original pictorial polygon and then contaminated with geometrical noise. Note how the noise sets the available pictorial content apart, thus complicating the decision about the affinity of the corresponding edges</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/10" data-track-dest="link:Figure10 Full size image" aria-label="Full size image figure 10" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11" data-title="Fig. 11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig11_HTML.png?as=webp"><img aria-describedby="Fig11" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig11_HTML.png" alt="figure 11" loading="lazy" width="685" height="523"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>The stages of representing a crossing cuts puzzle as a planar graph for the purpose of synthesis. In this selected example, the green quadrilateral is the global puzzle shape <i>S</i> whose boundary is defined by four lines (dashed blue). Three additional lines are defined as the crossing cuts (dashed red) and the intersection points of all these 7 lines <i>that also lie inside or on the border of</i> <i>S</i> are considered the nodes of the puzzle’s graph (and therefore <span class="mathjax-tex">\(\{i_1 \dots i_{12}\}\)</span> <i>are</i> nodes in the graph, but <span class="mathjax-tex">\(i_{13}\)</span> is <i>not</i>). The edges of the graph are defined by pairs of nodes that lie closest on the same line, i.e., by a pair of nodes that lie on the same line such that there is no other node in between them. Hence <span class="mathjax-tex">\(\{i_3, i_4\}, \{i_3, i_2\}, \{i_4, i_5\}\)</span> <i>are</i> edges but <span class="mathjax-tex">\(\{i_3, i_5\}\)</span> is <i>not</i></p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/11" data-track-dest="link:Figure11 Full size image" aria-label="Full size image figure 11" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>The nodes of <span class="mathjax-tex">\(\mathcal {G}_{puzzle}\)</span> are the intersection points of any two lines in <span class="mathjax-tex">\(\mathcal {C}\)</span> that rest inside or on the border of <i>S</i> (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig11">11</a>). Formally, this set of nodes is defined as follows:</p><div id="Equ30" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \mathcal {V}&amp;= \left\{ i \in S \Bigm | \exists (c_1, c_2) \in \mathcal {C} \times \mathcal {C}, \quad (c_1 \ne c_2) \wedge \left( i = c_1 \cap c_2 \right) \right\} \;. \end{aligned}$$</span></div></div><p>The set <span class="mathjax-tex">\(\mathcal {E}\)</span> of the edges of <span class="mathjax-tex">\(\mathcal {G}_{puzzle}\)</span> link pairs of nodes that rest on the same line with no other nodes between them, or formally:</p><div id="Equ31" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \mathcal {E}&amp;= \left\{ \{i_1, i_2\} \Bigm | \exists c \in \mathcal {C}, \quad \left( i_1, i_2\in c \cap \mathcal {V} \right) \wedge \left( [i_1, i_2]\cap \mathcal {V} = \emptyset \right) \right\} \end{aligned}$$</span></div></div><p>where <span class="mathjax-tex">\([i_1, i_2]\)</span> is the line segment (as a set of points) between node points <span class="mathjax-tex">\(i_1\)</span> and <span class="mathjax-tex">\(i_2\)</span>.</p><h3 class="c-article__sub-heading" id="Sec17"><span class="c-article-section__title-number">6.2 </span>Generation of Pieces and Ground Truth Matings</h3><p>The extraction of the pieces from graphs that represent planar divisions has been addressed in the graph algorithms community and here we employ the optimal algorithm due to Jiang and Bunke (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Jiang, X., &amp; Bunke, H. (1993). An optimal algorithm for extracting the regions of a plane graph. Pattern Recognition Letters, 14(7), 553–558." href="/article/10.1007/s11263-024-02033-7#ref-CR30" id="ref-link-section-d337817856e10986">1993</a>). This computational process receives the planar graph <span class="mathjax-tex">\(\mathcal {G}_{puzzle}\)</span> from Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec16">6.1</a> and outputs all of the minimal polygonal regions, each represented as the ordered list of nodes that delineate it. One such region in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig11">11</a> is <span class="mathjax-tex">\((i_1, i_2, i_{11}, i_{10})\)</span>.</p><p>The main construct in the algorithm is the notion of <i>wedge</i> (Jiang &amp; Bunke, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Jiang, X., &amp; Bunke, H. (1993). An optimal algorithm for extracting the regions of a plane graph. Pattern Recognition Letters, 14(7), 553–558." href="/article/10.1007/s11263-024-02033-7#ref-CR30" id="ref-link-section-d337817856e11087">1993</a>), defined as a pair of different edges that meet at a node (e.g., <span class="mathjax-tex">\((\{i_1, i_2\}, \{i_2, i_3\})\)</span> so that no other edge is encountered when rotating the first edge towards the second (e.g. <span class="mathjax-tex">\((i_2, i_{11}, i_4)\)</span> in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig11">11</a> is a wedge, but <span class="mathjax-tex">\((i_{10}, i_{11}, i_4)\)</span> is not a wedge). A closed chain of overlapping wedges (e.g <span class="mathjax-tex">\(( (i_1, i_2, i_{11}), (i_2, i_{11}, i_{10}), (i_{11}, i_{10}, i_{1}) )\)</span> in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig11">11</a>) defines a minimal region, and thus a puzzle piece. The sorting scheme that locates the wedge chains was shown to have <span class="mathjax-tex">\(O(|\mathcal {E}| \log (|\mathcal {E}|))\)</span> run-time complexity and <span class="mathjax-tex">\(O(|\mathcal {E}|)\)</span> memory complexity. Please refer to the original paper for more details.</p><p>The application of Jiang and Bunke (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Jiang, X., &amp; Bunke, H. (1993). An optimal algorithm for extracting the regions of a plane graph. Pattern Recognition Letters, 14(7), 553–558." href="/article/10.1007/s11263-024-02033-7#ref-CR30" id="ref-link-section-d337817856e11500">1993</a>) results is a set of puzzle pieces that are positioned in their original puzzle location, and thus, if the generated puzzle is pictorial, this is the point where the geometric representation of the pieces serves to crop the original pictorial content that belongs to each piece. Either case, the segmentation of the original polygon into pieces in their “correct” position is now suitable for the computation and representation of the <i>desired</i> solution for the puzzle, at the very least for the evaluation of solvers output against the ground truth. Indeed, at this point of the synthesis process, any pair of neighboring pieces is positioned such that their mating edges strictly overlap. Hence the extraction of the ground truth mating graph can be done, for example, by finding all <i>overlapping</i> edges <span class="mathjax-tex">\(e_i^j\)</span> and <span class="mathjax-tex">\(e_k^l\)</span> that belong to <i>different</i> pieces. Formally, if <span class="mathjax-tex">\(E_m\)</span> represents all edges of piece <span class="mathjax-tex">\(p_m\)</span> (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec7">3</a>) and thus <span class="mathjax-tex">\(E=\left( \bigcup _{m=1}^n E_m \right) \)</span> is the set of all edges of all pieces, the ground truth matings are</p><div id="Equ32" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} M = \left\{ (e_i^j, e_k^l) \in E \times E \Bigm | (p_i \ne p_k) \wedge e_i^k = e_k^l \right\} \;. \end{aligned}$$</span></div></div><h3 class="c-article__sub-heading" id="Sec18"><span class="c-article-section__title-number">6.3 </span>Piece Randomization and Geometric Noise</h3><p>The final puzzle representation that is submitted to solvers should include no information about the ground truth position of the pieces. But with all pieces generated and the ground truth secured, puzzle pieces can now be shuffled and their Euclidean transformations randomized. To do so we first center each piece about its center of mass, i.e., each vertex is translated by the average of all vertices of the same piece. Then we apply a rotation transformation by some random angle selected uniformly in <span class="mathjax-tex">\([0,2\pi ]\)</span>. Needless to say, for pictorial puzzles the pictorial content is transformed correspondingly. If we denote the random rotation for piece <span class="mathjax-tex">\(p_i\)</span> by <span class="mathjax-tex">\({RR}_i\)</span> and the translation to the center of mass by <span class="mathjax-tex">\(\overrightarrow{tc}_i\)</span>, The ground truth positioning of the pieces is of course the inverse transformation <span class="mathjax-tex">\(\{[RR_i]^{-1}, -(\overrightarrow{tc\,}_i)\}\)</span>.</p><p>If the desired puzzle should be “clean”, the process ends here and the list of randomly ordered and transformed pieces, each in its own coordinate system, serves as the final puzzle representation. However, if a noisy puzzle is required, each vertex of each piece is first translated by a random noise vector that obeys the constraints from Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec10">5.1</a>. If the puzzle is pictorial, the application of the noise also crops the corresponding parts of the pictorial content. Only then the list of pieces is wrapped as the puzzle representation.</p><h3 class="c-article__sub-heading" id="Sec19"><span class="c-article-section__title-number">6.4 </span>Datasets</h3><p>We created several datasets using the procedure just described, where each serves a different purpose. The first dataset is tailored for the empirical exploration of statistical properties of crossing cuts puzzles while the others are designed to facilitate experimental evaluation (and if needed, of training) of crossing cuts solvers. The images for the pictorial content of all puzzles in all pictorial DBs were obtained from <a href="https://unsplash.com/">https://unsplash.com/</a> and <a href="https://www.pexels.com/public-domain-images/">https://www.pexels.com/public-domain-images/</a>, or taken by the authors with a digital camera.</p><p><i>DB1–circular puzzles for statistical properties</i> Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec20">7</a> presents a theoretical analysis of crossing cuts puzzles and their properties. To simplify and facilitate analytical analysis, it is performed on puzzles with circular global shape while the corresponding empirical properties were measured on synthesized puzzles whose shape was a unit triacontadigon (i.e., an approximation of a unit circle as a polygon of 32 sides). The random cuts in this case were selected by sampling two angles <span class="mathjax-tex">\(\phi _1, \phi _2\)</span> and then passing a line though the corresponding points on the circumference of the circle, namely <span class="mathjax-tex">\((\cos \phi _1, \sin \phi _1),(\cos \phi _2, \sin \phi _2)\)</span>.</p><p>Following this procedure we generated a collection of 300 noiseless puzzles, 30 puzzles for 10 different numbers of crossing cuts <span class="mathjax-tex">\(a\in \{10,20,\ldots ,100\}\)</span>. The number of puzzle pieces that resulted from this procedure varied from 36 to 2183. For each “clean” puzzle we then generated several noisy versions, with noise level varying in <span class="mathjax-tex">\(\xi \in [0\%, 0.1\%, 0.25\%, 0.5\%, 1\%, 2\%]\)</span>. Recall that <span class="mathjax-tex">\(\xi \)</span> is the noise bound relative to puzzle diameter, which in DB1’s case is always 2. In absolute terms, the noise in this dataset thus varied up to <span class="mathjax-tex">\(\varepsilon \le 0.04\)</span>, but perhaps more informatively, when considered against the average edge length, the noise could approach <span class="mathjax-tex">\(64\%\)</span> (i.e., <span class="mathjax-tex">\(\bar{\xi } \le 64\%\)</span>, see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec25">7.5</a>).</p><p>With the noisy versions taken into account, the number of puzzles in DB1 thus totaled 1800. For their intended use (i.e., analysis of properties), all puzzles in this dataset need not be pictorial and thus this is an apictorial dataset. Selected examples are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig12">12</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12" data-title="Fig. 12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig12_HTML.png?as=webp"><img aria-describedby="Fig12" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig12_HTML.png" alt="figure 12" loading="lazy" width="685" height="157"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Two selected synthesized circular puzzles for the analysis of puzzle properties. Shown are the puzzle as a bag of pieces and the corresponding ground truth solution. The numbers of cuts used for these examples are 20 and 100 while the corresponding number of pieces are 63 and 1806, respectively</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/12" data-track-dest="link:Figure12 Full size image" aria-label="Full size image figure 12" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13" data-title="Fig. 13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig13_HTML.png?as=webp"><img aria-describedby="Fig13" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig13_HTML.png" alt="figure 13" loading="lazy" width="685" height="201"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>One selected synthesized polygonal puzzle (30 cuts, 200 pieces) from DB2. The left column shows the process of generating the random puzzle shape in the workspace using the convex hull of random sample points. The middle column illustrates the ground truth solution and the right column shows the puzzles as a bag of pieces as provided to potential solvers</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/13" data-track-dest="link:Figure13 Full size image" aria-label="Full size image figure 13" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p><i>DB2–general</i> <i>apictorial</i> <i>puzzles for solvers evaluation</i> Unlike the specifically crafted puzzle shape used for the analysis of puzzle properties, the evaluation of puzzle solvers requires randomly shaped (yet convex) puzzles. To achieve this goal we first sampled a random number (between 4 and 50) of randomly positioned points in some predetermined workspace <span class="mathjax-tex">\([0,W]\times [0,H]\)</span> and then computed their convex hull to generate a random global convex polygonal shape (which in our case ended up having from 3 to 14 sides). <i>W</i> and <i>H</i> are given as parameters to the synthesizer but they bear very little significance. In our case, we fixed them both at <span class="mathjax-tex">\(W=H=100\)</span>.</p><p>The random cuts <span class="mathjax-tex">\(Cuts=\{c_1, \dots c_a\}\)</span> were also selected as uniformly distributed random lines in the same workspace, but to ensure they indeed penetrate the random polygon we first selected two random points <i>inside</i> the polygon and defined the cut as the line that goes between these points.</p><p>While this procedure can be activated on demand and with arbitrary parameter values, we used it to generate a collection of 100 random puzzles, whose number of cuts varies from 5 to 50 (10 instances from each case) and their number of pieces extends from 11 (in the easier puzzles) to 936 (in the more challenging ones). For each “clean” puzzle we also generated several noisy versions, with noise levels varying in <span class="mathjax-tex">\(\xi \in [0\%, 0.1\%, 0.25\%, 0.5\%, 1\%, 2\%]\)</span>. With the noisy versions taken into account, the number of puzzles in DB2 thus totals 600.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig13">13</a> shows one example from DB2 and aspects of its generation process.</p><p><i>DB3–Perturb grid</i> <i>pictorial</i> <i>puzzles for solver evaluation</i> The procedure just described was used also for the generation of a pictorial dataset for evaluation (and if needed, also for training) of pictorial crossing cuts puzzle solvers, where the pictorial content that covers the puzzle (and consequently, it pieces) was provided as an image and handled as described earlier in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec15">6</a>. However, to facilitate a better examination of the contribution of the pictorial content, in this first pictorial dataset, we reduced the role of the geometry by designating crossing cuts that generate edges of relatively similar lengths (both within and between pieces). This was done by defining the cuts to form a perturbed grid over the global polygonal shape, resulting in a narrower histogram of edge lengths and hence many more mating candidates when only geometry is considered. Without pictorial content, such puzzles will consider many more mating candidates, require a solver with significantly more computational resources, and (if the latter are bounded) may completely prohibit a solution unless pictorial considerations are incorporated too. At the same time, with crossing cuts that are roughly parallel, we are also guaranteed that the bounded geometrical noise does not erode pieces completely, a situation that generates puzzles with missing pieces that are outside the scope of our present solver. For all these reasons we tested our pictorial puzzle solver on DB3, but already generated DB4 below for future generalizations.</p><p>Following this scheme, we generate a collection of 600 random perturbed grid pictorial puzzles, whose number of cuts vary from 10 to 100 (with 10 instances from each case) and number of pieces that extends from 35 to 2601. As before, noise level varied in <span class="mathjax-tex">\(\xi \in [0\%, 0.1\%, 0.25\%, 0.5\%, 1\%, 2\%]\)</span>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig14">14</a> shows a selected example.</p><p>In addition to the 3 datasets above, we created two additional datasets for future work by the community. These DBs are described next.</p><p><i>DB4–General</i> <i>pictorial</i> <i>dataset</i> DB4 is another pictorial dataset for future research where the cuts are completely arbitrary and no special care is taken to downplay the role of geometric constraints. The importance of this dataset for future work is twofold. First, since the geometrical information becomes more significant and informative again (compared to DB3, for example), it will take more “aggressive” methods to exploit the pictorial content <i>effectively</i>. Second, in arbitrary crossing cuts puzzles some pieces may turn small enough to completely disappear after the application of the geometrical noise (as indeed happens in <span class="mathjax-tex">\(81.5\%\)</span> of puzzles in this dataset). Thus, this DB4 also facilitates future research on crossing cuts puzzles with <i>missing pieces</i>. Toward that end we generated a collection of 600 random polygonal pictorial puzzles, whose number of cuts vary from 10 to 100 (10 instances from each case), number of pieces extends from 35 to 3907, and noise level in the range <span class="mathjax-tex">\(\xi \in [0\%, 0.1\%, 0.25\%, 0.5\%, 1\%, 2\%]\)</span>. A selected example of such a puzzle is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig15">15</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14" data-title="Fig. 14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig14_HTML.png?as=webp"><img aria-describedby="Fig14" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig14_HTML.png" alt="figure 14" loading="lazy" width="685" height="435"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>An example of a perturbed grid pictorial puzzle (with 8 cuts and 24 pieces), both as a bag of pieces and the corresponding ground truth solution</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/14" data-track-dest="link:Figure14 Full size image" aria-label="Full size image figure 14" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15" data-title="Fig. 15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig15_HTML.png?as=webp"><img aria-describedby="Fig15" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig15_HTML.png" alt="figure 15" loading="lazy" width="685" height="403"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>One selected example of a general pictorial puzzle (with 7 cuts and 18 pieces). Note that some small pieces appear only in the ground truth row as the noise removed them completely from the bag of pieces in the puzzle to solve</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/15" data-track-dest="link:Figure15 Full size image" aria-label="Full size image figure 15" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p><i>DB5–Square piece</i> <i>pictorial</i> <i>dataset</i> As mentioned in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec7">3</a>, from a geometrical point of view, strictly square piece puzzles are a very special case of crossing cuts puzzles where geometry plays no role and the pictorial content is the sole source of information for reconstruction. For “backward compatibility”, and for their more general scheme of representation, using crossing cuts puzzles to represent square piece puzzles may be useful, especially if geometrical noise is to be allowed. We therefore generated such a collection of 3600 random square piece pictorial puzzles, whose number of cuts vary from 20 to 200 (10 instances from each case), number of pieces extends from 100 to 10, 000, and noise level in the range <span class="mathjax-tex">\(\xi \in [0\%, 0.1\%, 0.25\%, 0.5\%, 1\%, 2\%]\)</span>. Naturally, the different number of cuts generated pieces of different sizes, where in our cases extended from <span class="mathjax-tex">\(5 \times 5\)</span> to <span class="mathjax-tex">\(30 \times 30\)</span> pixels, yet another generalization of the prior art in square pieces puzzles that tended to focus on one size of <span class="mathjax-tex">\(28 \times 28\)</span> pixel only (though as mentioned in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec2">2</a>, one exception does exist (Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Son, K., Hays, J., Cooper, &amp; D. B., et al. (2016). Solving small-piece jigsaw puzzles by growing consensus. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1193–1201)." href="/article/10.1007/s11263-024-02033-7#ref-CR68" id="ref-link-section-d337817856e13011">2016</a>)).</p><p>We note that all 5 datasets are open and available for the community at the public-domain portal <span class="u-monospace">icvl.cs.bgu.</span><span class="u-monospace">ac.il\polygonal-puzzle-solving</span>. This portal also will host additional datasets of varying characteristics as they become available.</p></div></div></section><section data-title="Puzzle Properties"><div class="c-article-section" id="Sec20-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec20"><span class="c-article-section__title-number">7 </span>Puzzle Properties</h2><div class="c-article-section__content" id="Sec20-content"><p>One of the advantages of the generation model that defines crossing cuts puzzles is the better ability to analyze their properties. Since the model is stochastic, their properties are typically probabilistic, but nevertheless can provide insights on both the problem itself and about potential solutions (or limitations thereof). Here we explore such properties both analytically and, when needed, empirically. In this section, we assume that the global puzzle shape is a unit circle (or a polygonal approximation thereof), whose symmetry simplifies some of the analytical analyses. Most results, however, are indicative of all crossing cuts puzzles (up to a factor of half of their diameter). Empirical properties are evaluated on the DB1, the circular puzzles dataset that was described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec15">6</a>.</p><h3 class="c-article__sub-heading" id="Sec21"><span class="c-article-section__title-number">7.1 </span>Expected Cut Length</h3><p>The first measure of interest is the length of a random cut <span class="mathjax-tex">\(c_i\)</span> through the global puzzle shape. When the latter is a unit circle, <span class="mathjax-tex">\(c_i\)</span> is determined by two points sampled uniformly on the circumference of the circle. In other words, the cut is determined by the chord between points <span class="mathjax-tex">\(\vec {p_1} = (\cos \phi _1, \sin \phi _1)\)</span> and <span class="mathjax-tex">\(\vec {p_2} = (\cos \phi _2, \sin \phi _2)\)</span>, where the two angles are uniformly distributed random variables <span class="mathjax-tex">\(\phi _1, \phi _2 \sim \text {U}(0, 2 \pi )\)</span>. The length of cut <span class="mathjax-tex">\(c_i\)</span> is therefore another random variable defined by the function <span class="mathjax-tex">\(l_{i} = \Vert \vec {p_2} - \vec {p_1} \Vert \)</span>, and one may seek its expected value.</p><p>Since circles are symmetric, without loss of generality we can align the coordinate system parallel to the cut and consider only horizontal chords that lie in the circle’s upper half, i.e., when both <span class="mathjax-tex">\(\vec {p_1}\)</span> and <span class="mathjax-tex">\(\vec {p_2}\)</span> have identical positive <i>y</i> coordinates, as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig16">16</a>A. If we now assume (w.l.o.g) that <span class="mathjax-tex">\(\phi _2&gt;\phi _1\)</span>, then <span class="mathjax-tex">\(\Theta _i=\phi _2-\phi _1\)</span> is the central angle of the cut and therefore <span class="mathjax-tex">\(l_i = 2 \sin (\Theta _i / 2)\)</span>. Since <span class="mathjax-tex">\(\Theta _i \sim \text {U}(0, \pi )\)</span>, it follows that the expected length of a random cut through the unit circle is</p><div id="Equ33" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E[l_i]&amp;= \int _{0}^{\pi } l_i(t) \cdot f_{\Theta _i}(t) d t = \int _{0}^{\pi } 2 \sin \left( \frac{t}{2}\right) \frac{1}{\pi } d t = \frac{4}{\pi } \approx 1.273\;. \end{aligned}$$</span></div></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16" data-title="Fig. 16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig16_HTML.png?as=webp"><img aria-describedby="Fig16" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig16_HTML.png" alt="figure 16" loading="lazy" width="685" height="408"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Expected cut length and probability of cut intersection. <b>A</b> A unit circle cut <span class="mathjax-tex">\(c_i\)</span> with a central angle <span class="mathjax-tex">\(\Theta _i\)</span> can be considered w.l.o.g to be horizontal, leading to an expected length as in the text. <b>B</b> Two cuts <span class="mathjax-tex">\(c_1\)</span> and <span class="mathjax-tex">\(c_2\)</span> intersect if and only if the vertices of the second cut (in green) lie in different arcs (in blue and orange) generated by the first cut (in red) (Color figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/16" data-track-dest="link:Figure16 Full size image" aria-label="Full size image figure 16" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec22"><span class="c-article-section__title-number">7.2 </span>Probability of Cut Intersections</h3><p>Given two uniformly distributed random cuts <span class="mathjax-tex">\(c_1\)</span> and <span class="mathjax-tex">\(c_2\)</span>, one may seek the probability of their intersection. This question is interesting for understanding how the number of pieces grows with the number of cuts, as intersecting cuts contribute more pieces than non-intersecting ones. Again, we can assume w.l.o.g that one of the cuts, say <span class="mathjax-tex">\(c_1\)</span>, is horizontal and lying in the upper half of the circle (marked red in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig16">16</a>B). Let the central angle of <span class="mathjax-tex">\(c_1\)</span> be <span class="mathjax-tex">\(\Theta _1 \sim \text {U}(0, \pi )\)</span> and note how this cut divides the circle to two arcs - <span class="mathjax-tex">\(arc_1\)</span> of angle <span class="mathjax-tex">\(\Theta _1\)</span> (blue in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig16">16</a>B) and <span class="mathjax-tex">\(arc_2\)</span> of angle <span class="mathjax-tex">\(2\pi - \Theta _1\)</span> (orange in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig16">16</a>B).</p><p>Denoting the vertices of <span class="mathjax-tex">\(c_2\)</span> as <span class="mathjax-tex">\(p_1\)</span> and <span class="mathjax-tex">\(p_2\)</span>, we first note that an intersection between <span class="mathjax-tex">\(c_1\)</span> and <span class="mathjax-tex">\(c_2\)</span> occurs if and only if <span class="mathjax-tex">\(p_1\)</span> belongs to <span class="mathjax-tex">\(arc_1\)</span> and <span class="mathjax-tex">\(p_2\)</span> belongs to <span class="mathjax-tex">\(arc_2\)</span> (or vice versa). Seeking the probability of such an event, let <span class="mathjax-tex">\(I_{c_1, c_2}\)</span> be an indicator function for the intersection between <span class="mathjax-tex">\(c_1\)</span> and <span class="mathjax-tex">\(c_2\)</span>. Clearly, this function depends on the extent (or size) of the two arcs and indeed</p><div id="Equ34" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P(I_{c_1, c_2} | \Theta _1)&amp;= 2 \cdot P(p_1 \in arc_1 | \Theta _1) \cdot P(p_2 \in arc_2 | \Theta _1) \\&amp;= 2 \cdot \frac{\Theta _1}{2\pi } \cdot \frac{2 \pi - \Theta _1}{2 \pi }= \frac{\Theta _1(2\pi - \Theta _1)}{2\pi ^2} \end{aligned}$$</span></div></div><p> It follows that the expected value for the intersection event is</p><div id="Equ35" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E[I_{c_1, c_2}] = P(I_{c_1, c_2})&amp;= \int _{0}^{\pi } f_{\Theta _1}(t) \cdot P(I | \Theta _1 = t) dt\\&amp;= \int _{0}^{\pi } \frac{1}{\pi } \frac{t(2\pi - t)}{2\pi ^2} d t = \frac{1}{3} \;. \end{aligned}$$</span></div></div><p> Hence, we conclude that only 1 out of 3 pairs of random unit circle cuts will intersect, an event perhaps less frequent than intuitively anticipated in such circumstances. An intuitive justification nevertheless arises once we consider 4 endpoints on the shape’s circumference and all 3 combinations of crossing lines they facilitate. Indeed, only one of these combinations induces a crossing.</p><h3 class="c-article__sub-heading" id="Sec23"><span class="c-article-section__title-number">7.3 </span>Expected Total Number of Cut Intersections</h3><p>Following the probability of the cut intersection event (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec22">7.2</a>), we now can seek the total number of intersections expected in a puzzle of <i>a</i> cuts. Clearly, it is simply the sum of all pairs of intersecting cuts, that is</p><div id="Equ36" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} N_{intersect}&amp;= \frac{1}{2} \sum _{i=1}^{a} \sum _{j \ne i} I_{c_i, c_j} \;. \end{aligned}$$</span></div></div><p>The expected value of this random variable, i.e., the expected number of intersections in puzzles with <i>a</i> crossing cuts, thus becomes:</p><div id="Equ37" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E\left[ N_{intersect}\right]&amp;= \left( {\begin{array}{c}a\\ 2\end{array}}\right) \underbrace{ P\left[ I_{c_1, c_2} \right] }_{\frac{1}{3}} = \frac{a(a-1)}{6} \;. \end{aligned}$$</span></div></div><p>Note that this number is far smaller than <span class="mathjax-tex">\(\left( {\begin{array}{c}a\\ 2\end{array}}\right) \)</span>, the maximum number of intersections possible between <i>a</i> cuts.</p><h3 class="c-article__sub-heading" id="Sec24"><span class="c-article-section__title-number">7.4 </span>Expected Number of Edges</h3><p>Given a crossing cuts puzzle generated by <i>a</i> crossing cuts, we next wish to express the number of piece edges in the entire puzzle. This measure is fundamental to the number of matings and therefore is a substrate of the computational complexity of reconstruction algorithms.</p><p>First, observe that each edge is a subset of some cut between two consecutive intersections along its length. In particular, if a cut <span class="mathjax-tex">\(c_i\)</span> is intersected <i>k</i> times, the number of edges that emerge from this cut will be <span class="mathjax-tex">\(k + 1\)</span>. To obtain the total number of edges <span class="mathjax-tex">\(N_{edges}\)</span> in the puzzle one needs to sum up the edges on all cuts, i.e.,</p><div id="Equ4" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} N_{edges}&amp;= \sum _{i=1}^{a} \left( 1+ \sum _{c_j \ne c_i} I_{c_i, c_j} \right) \nonumber \\&amp;= a + \sum _{c_i} \sum _{c_j \ne c_i} I_{c_i, c_j} = a + 2 N_{intersect} \;. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (4)
                </div></div><p> Since <span class="mathjax-tex">\(I_{c_i, c_j}\)</span> is a random function, so is <span class="mathjax-tex">\(N_{edges}\)</span>. We can therefore seek its expected value, i.e., the expected number of edges in the entire puzzle:</p><div id="Equ5" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E[N_{edges}]&amp;= E\left[ 2 \cdot N_{intersect} \right] + a \nonumber \\&amp;= 2 \cdot \frac{a(a-1)}{6} + a = \frac{a^2+2a}{3} \;. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (5)
                </div></div><h3 class="c-article__sub-heading" id="Sec25"><span class="c-article-section__title-number">7.5 </span>Expected Edge Length</h3><p>With the expected number of edges resolved, we can now seek the expected edge length as the expected ratio between the accumulated edge lengths to their number. Fortunately, the former is simply the summed length of all cuts and thus, if the puzzle constitutes <i>a</i> cuts, we obtain an average edge length of</p><div id="Equ38" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} l_{avg} = \frac{\sum _{i=1}^a l_i}{N_{edges}} \;, \end{aligned}$$</span></div></div><p>where <span class="mathjax-tex">\(l_i\)</span> was obtained in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec21">7.1</a> and <span class="mathjax-tex">\(N_{edges}\)</span> was derived in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec24">7.4</a>. While the expected value of a ratio is <i>not</i> the ratio of expected values, it <i>is</i> its first-order Taylor approximation (Benaroya &amp; Han, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Benaroya, H., &amp; Han, S. Probability models in engineering and science." href="/article/10.1007/s11263-024-02033-7#ref-CR6" id="ref-link-section-d337817856e16047">2013</a>). Thus:</p><div id="Equ6" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E[l_{avg}]&amp;= E\left[ \frac{\sum l_i}{N_{edges}} \right] \approx \frac{E\left[ \sum l_i \right] }{E\left[ N_{edges} \right] } = \frac{12}{\pi (a + 2)} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (6)
                </div></div><p>which conforms well with the empirical results of the same measure as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig17">17</a>. The second-order Taylor approximation</p><div id="Equ39" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E[l_{avg}] \approx \underbrace{ \frac{E\left[ \sum l_i \right] }{E\left[ N_{edges} \right] } }_{\text {First order terms}} - \underbrace{ \frac{ Cov(\sum l_i, N_{edges}) }{ (E[N_{edges}])^2 } + \frac{ Var( N_{edges}) \cdot E\left[ \sum l_i \right] }{ ( E[N_{edges}] )^3 } }_{\text {Second order term}} \end{aligned}$$</span></div></div><p>constitutes two second-order terms that turn out to cancel each other to a diminishing sum as the number of cuts increases, thus facilitating the approximation in Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ6">6</a>. This also is exemplified empirically in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig17">17</a>. As mentioned in the introduction to this section, empirical results are evaluated on DB1, the circular puzzles dataset, described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec15">6</a></p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17" data-title="Fig. 17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig17_HTML.png?as=webp"><img aria-describedby="Fig17" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig17_HTML.png" alt="figure 17" loading="lazy" width="685" height="480"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p>Empirical average edge length with a growing number of cuts, as evaluated on DB1, compared to the first-order theoretical behavior from Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ6">6</a> that improves in prediction power as the number of cuts increases. Error bars are <span class="mathjax-tex">\(\pm 1\)</span> SE. The green line shows the diminishing second-order terms of the Taylor approximation (Color figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/17" data-track-dest="link:Figure17 Full size image" aria-label="Full size image figure 17" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-18" data-title="Fig. 18"><figure><figcaption><b id="Fig18" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 18</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/18" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig18_HTML.png?as=webp"><img aria-describedby="Fig18" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig18_HTML.png" alt="figure 18" loading="lazy" width="685" height="252"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-18-desc"><p>Probability density of edge length in crossing cuts puzzles. <b>A</b> Empirical distribution for growing number of cuts, as evaluated on <i>noisy</i> puzzles from DB1. Note how the distribution gets narrower with the number of crossing cuts, as depicted by a steeper slope in the log scale. <b>B</b> Empirical edge length distribution of perturbed square puzzles with a growing number of cuts, as evaluated on DB3. Observe how the distribution of edge lengths in these puzzles is no longer exponential, with a modal behavior that is dominated by a particular edge length</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/18" data-track-dest="link:Figure18 Full size image" aria-label="Full size image figure 18" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec26"><span class="c-article-section__title-number">7.6 </span>Edge Length Distribution</h3><p>While the expected edge length can be computed analytically, it is far more complicated to do so for the entire distribution of edge lengths. The importance of this distribution lies in how it influences the number of possible mates under geometric noise, a quantity that is likely to increase the narrower the distribution becomes. We have therefore measured this property empirically using our synthesized datasets and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig18">18</a>A reports these findings. Note how in general the distribution is exponential, preferring shorter edges and (not surprisingly) becoming narrower with a larger number of cuts. Clearly, when cuts are no longer selected uniformly, the distribution can definitely change shape. For example, strictly square noiseless puzzles will of course have a delta distribution for their edge lengths. Perturbed square noisy puzzles, i.e., those in our DB3, exhibit the distribution shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig18">18</a>B.</p><h3 class="c-article__sub-heading" id="Sec27"><span class="c-article-section__title-number">7.7 </span>Min, Max, and Expected Number of Pieces</h3><p>One of the significant properties of jigsaw puzzles that clearly affects the complexity of their representation (and thus of possible solutions) is their number of pieces. Clearly, even if the number of crossing cuts is set, different cut patterns can create puzzles with varying numbers of pieces. To estimate this number, and inspired by Moore (Moore, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1991" title="Moore, T. L. (1991). Using euler’s formula to solve plane separation problems. The College Mathematics Journal, 22(2), 125–130." href="/article/10.1007/s11263-024-02033-7#ref-CR46" id="ref-link-section-d337817856e16600">1991</a>), we use Euler’s Formula for planar graphs:</p>
                  <h3 class="c-article__sub-heading" id="FPar1">Theorem 1</h3>
                  <p>(Euler’s Formula) If <span class="mathjax-tex">\(G = (V, E)\)</span> is any planar graph, then G has <span class="mathjax-tex">\(|E| - |V| + 2\)</span> regions where |<i>E</i>| is the number of links in the graph and |<i>V</i>| is the number of nodes.</p>
                <p>Note that in our crossing cuts puzzle case, the number of nodes for Euler’s formula is the number of inner intersections (<span class="mathjax-tex">\(N_{intersect}\)</span>) plus the 2<i>a</i> intersections of the cuts with the boundary of the puzzle. The number of links is the number of internal edges (<span class="mathjax-tex">\(N_{edges}\)</span>) plus the 2<i>a</i> piece sides generated by the cuts along the puzzle boundary. Using Euler’s formula, and applying Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ4">4</a>, we thus get</p><div id="Equ7" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} N_{pieces}&amp;= \underbrace{ (N_{edges} + 2a)}_{|E|} - \underbrace{ (N_{intersect} + 2a) }_{|V|} + 2 - 1 \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (7)
                </div></div><div id="Equ8" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;= N_{intersect} + a + 1 \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (8)
                </div></div><p>Note that the subtraction of the last 1 in Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ7">7</a> is required since Euler’s formula also counts the region outside the puzzle/graph.</p><p>With this in mind, we next observe that one extreme case includes puzzles where no cut intersects others (<span class="mathjax-tex">\(N_{intersect}=0\)</span>), and thus the minimal number of pieces is <span class="mathjax-tex">\(N_{pieces}=a+1\)</span>. At the other extreme, every cut intersects all others, and the <span class="mathjax-tex">\(\left( {\begin{array}{c}a\\ 2\end{array}}\right) \)</span> intersections yield the following quadratic upper bound on the number of pieces (which is exactly the Lazy caterer’s sequence)</p><div id="Equ40" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \max _{c_i, \dots c_a} N_{pieces}&amp;= \left( {\begin{array}{c}a\\ 2\end{array}}\right) + a + 1 = \frac{a^2}{2} + \frac{a}{2} + 1\;\;. \end{aligned}$$</span></div></div><p>However, with <span class="mathjax-tex">\(N_{intersect}\)</span> being a random variable (that depends on the random cuts), it is more interesting to examine the <i>expected</i> number of pieces:</p><div id="Equ9" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E\left[ N_{pieces} \right]&amp;= E[N_{intersect}] +a +1 \nonumber \\&amp;= \frac{a(a-1)}{6} +a +1 = \frac{a^2}{6} + \frac{5a}{6} + 1 \;. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (9)
                </div></div><p>This behavior can also be verified empirically, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig19">19</a>. Finally, as the number of cuts increases, and when <span class="mathjax-tex">\(a \rightarrow \infty \)</span>, the ratio between the expected and the maximum number of pieces becomes</p><div id="Equ41" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \lim _{a\rightarrow \infty } \frac{E[N_{pieces}]}{\max N_{pieces}} = \frac{1}{3} \end{aligned}$$</span></div></div><p>which is the same as the probability for cut intersection found in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec22">7.2</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-19" data-title="Fig. 19"><figure><figcaption><b id="Fig19" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 19</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/19" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig19_HTML.png?as=webp"><img aria-describedby="Fig19" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig19_HTML.png" alt="figure 19" loading="lazy" width="685" height="468"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-19-desc"><p>The empirical expected number of puzzle pieces with a growing number of cuts, compared to the theoretically expected behavior (Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ8">8</a>). Error bars are <span class="mathjax-tex">\(\pm 1\)</span> SE</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/19" data-track-dest="link:Figure19 Full size image" aria-label="Full size image figure 19" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec28"><span class="c-article-section__title-number">7.8 </span>Expected Number of Edges Per Piece</h3><p>As discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec7">3</a>, the crossing cuts puzzle model cuts the puzzle shape into convex polygonal pieces. Clearly, these pieces can have a different number of edges and there is no a-priori inherent limit to this number (except the number of cuts, of course).</p><p>To explore this property we conducted an empirical evaluation on DB1, i.e., by using the 30 synthesized circular crossing cuts puzzles synthesized for each of the different number of cuts. Empirically, the most frequent pieces are either quadrilateral or triangular, depending on the number of cuts, whereas asymptotically, quadrilaterals are the most abundant. The probability of encountering puzzle pieces with more than 6 edges is diminishing quickly from <span class="mathjax-tex">\(10\%\)</span> in puzzles with few cuts, to approximately <span class="mathjax-tex">\(2\%\)</span> as the number of cuts increases. The results up are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig20">20</a> and demonstrate that the distribution converges quickly and then remains stable from approximately 60 cuts.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-20" data-title="Fig. 20"><figure><figcaption><b id="Fig20" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 20</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/20" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig20_HTML.png?as=webp"><img aria-describedby="Fig20" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig20_HTML.png" alt="figure 20" loading="lazy" width="685" height="475"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-20-desc"><p>Expected ratios of pieces with a particular number of edges as a function of the number of crossing cuts. Note how quadrilaterals are always the majority, followed closely by triangular pieces and the less frequent pentagons. These three classes of polygons quickly converge to account for approximately 95% of all pieces. Note how the ratios converge quickly and remain essentially invariant to the number of cuts. Shaded bands represent <span class="mathjax-tex">\(\pm 1\)</span>SE</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/20" data-track-dest="link:Figure20 Full size image" aria-label="Full size image figure 20" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec29"><span class="c-article-section__title-number">7.9 </span>Number of Potential Matings Per Edge</h3><p>Since any puzzle reconstruction algorithm will seek (as part of its different computations) to match the edge of a given piece to edges of other pieces, the complexity of such an algorithm will relate intimately to the number of potential matings each edge may have. Clearly, the higher the number of admissible candidate mates, the more difficult the identification of the correct one is likely to be. Following the discussion in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec10">5.1</a>, the raw number of geometrically admissible mates each edge may have is determined by the two mating constraints <span class="mathjax-tex">\(\tilde{C}_1\)</span> and <span class="mathjax-tex">\(\tilde{C}_2\)</span> and it is naturally affected by the level of the noise. In fact, since the number of expected edges in the puzzle is quadratic in the number of cuts (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec24">7.4</a>), a naive extension of Algorithm 1 from Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec8">4</a> that also incorporates backtracking when wrong matings are identified, will grow intractably in complexity by a factor of <span class="mathjax-tex">\(O\left( k^{a^2} \right) \)</span> if the number of potential matings per edge is <i>k</i>.</p><p>We empirically explored the expected average number of matings by counting the average number of possible matings for each puzzle in DB1 while employing <span class="mathjax-tex">\(\tilde{C}_1\)</span> and <span class="mathjax-tex">\(\tilde{C}_2\)</span>. Not unexpectedly, the results provided in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig21">21</a>A indicate that the noise level affects the number of potential mates very rapidly and very drastically (where the decline after the peak is because greater noise erodes more pieces completely, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig21">21</a>B).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-21" data-title="Fig. 21"><figure><figcaption><b id="Fig21" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 21</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/21" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig21_HTML.png?as=webp"><img aria-describedby="Fig21" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig21_HTML.png" alt="figure 21" loading="lazy" width="685" height="258"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-21-desc"><p><b>A</b> The average number of geometrically admissible matings for each edge as a function of noise level. Each graph shows the potential number of mates that satisfy both <span class="mathjax-tex">\(\tilde{C}_1\)</span> and <span class="mathjax-tex">\(\tilde{C}_2\)</span>, summed over all edges. Both the initial rapid growth and the subsequent gradual decline (which is particularly visible in puzzles with more cuts) indicate the harmful effect of noise. Shaded bands are <span class="mathjax-tex">\(\pm 1\)</span> SE. <b>B</b> The average ratio of completely eroded pieces due to applied noise, out of the puzzles’ original (noiseless) number of pieces. As expected, the application of larger noise completely erodes more pieces, thus also decreasing the number of potential matings per edge</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/21" data-track-dest="link:Figure21 Full size image" aria-label="Full size image figure 21" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Here it is also worth re-emphasizing that the noise levels in our model are measured relative to the puzzle size, or its <i>diameter</i>, and therefore might appear small. In reality, they are not small at all, because noise affects individual pieces, that typically are very much smaller than the entire puzzle. Thus, considering also the average edge length (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec25">7.5</a>), noise level <span class="mathjax-tex">\(\xi \)</span> relative to the puzzle diameter is comparable to the following bound</p><div id="Equ10" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \bar{\xi } = \frac{4 \cdot \xi \cdot \pi (a + 2)}{12} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (10)
                </div></div><p>relative to average edge length, which is perhaps a more tangible and informative measure. For example, in a puzzle of 20 crossing cuts (84 pieces on average) and a noise level of <span class="mathjax-tex">\(\xi =1\%\)</span>, the noise relative to average edge length is <span class="mathjax-tex">\(\bar{\xi } \approx 10\%\)</span>, namely a rather significant noise.</p><p>Indeed, the high number of potential matings in the presence of noise suggests a similarly high branching factor in a naive “search and backtrack” algorithm, which will clearly become intractable for handling noisy (i.e., realistic) crossing cuts puzzles, even if the number of cuts is modest. Our goal is to seek heuristics that make the reconstruction more manageable after all, and as we will see later on, this can be achieved by utilizing multiple geometric constraints <i>simultaneously</i>, and by leveraging the <i>pictorial</i> content to generate and apply yet more constraints on the matings.</p></div></div></section><section data-title="Puzzle Reconstruction Under Noisy Conditions"><div class="c-article-section" id="Sec30-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec30"><span class="c-article-section__title-number">8 </span>Puzzle Reconstruction Under Noisy Conditions</h2><div class="c-article-section__content" id="Sec30-content"><p>Recall that a “realistic” crossing cuts puzzle constitutes a representation of the input pieces (and some bound on the erosion noise), and it seeks as output both the correct matings and the geometric transformation of each piece. As mentioned above, at first sight one may wish to extend the initial greedy Algorithm 1 from Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec8">4</a> while using the relaxed “noisy” constraints (<span class="mathjax-tex">\(\tilde{C}_1\)</span> and <span class="mathjax-tex">\(\tilde{C}_2\)</span>) to find candidate matings, and if needed employ backtracking upon failures (e.g., piece collisions). However, as analyzed above, the expected number of candidate matings per edge (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec29">7.9</a>) clearly makes this naive extension intractable. Moreover, under noise, it is unclear what is the desired position (i.e., Euclidean transformation) of each piece, or how to compute it in the first place, even if the mating relationships are resolved correctly. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig22">22</a> illustrates some of these challenges.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-22" data-title="Fig. 22"><figure><figcaption><b id="Fig22" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 22</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/22" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig22_HTML.png?as=webp"><img aria-describedby="Fig22" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig22_HTML.png" alt="figure 22" loading="lazy" width="685" height="199"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-22-desc"><p>The placement of noisy pieces can be ambiguous. When noise is applied to this simple crossing cuts puzzle (<b>A</b>, <b>B</b>), there could be different placements of the noisy pieces that might count as “correct” (<b>C</b>, <b>D</b>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/22" data-track-dest="link:Figure22 Full size image" aria-label="Full size image figure 22" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>To address these difficulties we approach the problem in stages, and in particular, we begin with the simpler problem of solving the puzzle <i>when the correct matings are given also</i>. More concretely, we first suggest a solution to this sub-problem by representing it as a multi-body spring-mass system where energy minimization is sought while the spring attractive forces apply between corresponding vertices. The solutions obtained this way are then used as scores for searching and determining the correct matings while incorporating a hierarchical (and progressively growing) set of circular constraints among adjacent pieces. For pictorial puzzles, we also add another set of pictorial constraints on top of the geometrical ones.</p><h3 class="c-article__sub-heading" id="Sec31"><span class="c-article-section__title-number">8.1 </span>Noisy Puzzle Solving with <i>Known</i> Matings</h3><p>Let <span class="mathjax-tex">\(P=\{p_1,p_2,\ldots ,p_n\}\)</span> be the set of pieces and let <span class="mathjax-tex">\(M=\{m_1,\ldots ,m_{|M|}\}\)</span> be a set of (known) pairwise matings <span class="mathjax-tex">\(m_q=\{ e_i^j, e_k^l \}\)</span> between their corresponding edges. We seek a computational scheme that obeys the given matings and places the pieces in some “optimal” or “good” way next to each other. Intuitively, we would like to do so in a way that minimizes the total distance, i.e., the <span class="mathjax-tex">\(L_2\)</span> displacement error, between corresponding mating vertices, or more formally, to find the set of Euclidean transformations <span class="mathjax-tex">\((R_i,\vec {t}_i)\)</span> that satisfy</p><div id="Equ11" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \underset{\left( R_i, \vec {t\,}_i\right) }{\textrm{argmin}}\;\; \sum _{(\vec {v\,}_i^j, \vec {v\,}_k^l)} \left\Vert \left( R_i \vec {v}_i^j + \vec {t}_i\right) - \left( R_k \vec {v}_k^l + \vec {t}_k\right) \right\Vert ^2 \;, \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (11)
                </div></div><p>where <span class="mathjax-tex">\(\vec {v\,}_i^j\)</span> and <span class="mathjax-tex">\(\vec {v\,}_k^l\)</span> are the corresponding vertices of the matings defined by <i>M</i> while <span class="mathjax-tex">\((R_i, t_i)\)</span> and <span class="mathjax-tex">\((R_k, t_k)\)</span> are the euclidean transformations of pieces <span class="mathjax-tex">\(p_i\)</span> and <span class="mathjax-tex">\(p_k\)</span> that own these vertices. Unfortunately, this is no simple least squares minimization, as the unknowns include rotation matrices and the sought-after transformations must satisfy the constraint that they are <i>identical for all vertices of the same piece</i>.</p><p>As a result of its specifications, this optimization problem defies analytical solutions and we therefore resort to tools from other disciplines. In particular, we propose to abstract the rearrangement problem as a <i>multi-body spring-mass system</i>. To do so we first represent our puzzle pieces as 2D rigid bodies with uniform density, and therefore with mass that is proportional to their area. We then connect all pairs of corresponding vertices (i.e., those matched by the matings) with springs of zero length and identical elasticity (i.e., having the same <i>spring constants</i>). Since the elastic potential energy of such a spring-mass system is <span class="mathjax-tex">\(U(x) = \sum _{l} \frac{1}{2} k x_l^2\)</span>, where <span class="mathjax-tex">\(x_l\)</span> is the displacement from equilibrium length of spring <i>l</i>, it is identical (up to a constant) to our objective function in Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ11">11</a>. We therefore apply numerical methods for solving multi-body spring-mass problems, while the initial pose (position and rotation) of each piece is chosen randomly inside the arena. The physical system is then set loose and with some damping (i.s., loss of energy due to friction) it converges to its minimal energetic state, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig23">23</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-23" data-title="Fig. 23"><figure><figcaption><b id="Fig23" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 23</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/23" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig23_HTML.png?as=webp"><img aria-describedby="Fig23" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig23_HTML.png" alt="figure 23" loading="lazy" width="685" height="135"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-23-desc"><p>The puzzle with given matings is abstracted as a spring-mass system that evolves over time towards a convergence state. If the pieces are far apart (left), the springs pull them closer. When the pieces overlap (middle), the springs pull them apart again. With some damping (i.s., loss of energy due to friction), the system eventually converges to a state of minimal energy</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/23" data-track-dest="link:Figure23 Full size image" aria-label="Full size image figure 23" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>In practice there are off-the-shelf tools to solve the above system numerically, practically simulating the dynamical process that the system undergoes from initial condition until convergence, and here we use the Box2D physics engine [13]. For puzzles, it is undesired to obtain solutions with overlapping pieces, but adding this constraint to a random initial state is unstable numerically. We therefore run the process first while allowing the pieces to overlap. The convergence state of this run is energetically minimal but might include small overlaps. We then use it as the initial state for a second run, this time while forbidding overlaps. The end result is our solution and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig24">24</a> shows several snapshots from this dynamical process.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-24" data-title="Fig. 24"><figure><figcaption><b id="Fig24" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 24</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/24" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig24_HTML.png?as=webp"><img aria-describedby="Fig24" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig24_HTML.png" alt="figure 24" loading="lazy" width="685" height="172"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-24-desc"><p>Several snapshots of the numerical simulation for a noisy puzzle of 25 cuts and 940 pieces. <b>A</b> Initial state. <b>B</b> Intermediate state. <b>C</b> Final state. <b>D</b> A zoomed section of the region marked in the final state shows the approximated final placement due to the noise</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/24" data-track-dest="link:Figure24 Full size image" aria-label="Full size image figure 24" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec32"><span class="c-article-section__title-number">8.2 </span>Noisy Puzzle Solving with <i>Unknown</i> Matings</h3><p>Let <span class="mathjax-tex">\(P=\{p_1, \dots p_n\}\)</span> be the set of puzzle pieces and let <span class="mathjax-tex">\(\varepsilon \)</span> denote the noise level. Unlike the conditions in the previous section, we now assume no knowledge of the matings and thus our goal is twofold: to find the correct matings <span class="mathjax-tex">\(M=\{m_1,\ldots ,m_{|M|}\}\)</span> between the edges <i>and</i> the geometrical transformation of each piece. To do so, we endow the basic constraint matching procedure (based on <span class="mathjax-tex">\(\tilde{C}_1\)</span> and <span class="mathjax-tex">\(\tilde{C}_2\)</span>) with a modified version of a hierarchical loops scheme (Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR67" id="ref-link-section-d337817856e19296">2018</a>), where the mass-spring minimization approach from Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec31">8.1</a> is used to score the loops based on their success to position the pieces properly, as defined below. If the puzzle is pictorial, we also rank and filter those matches using the pictorial content next to the geometrical one.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec33"><span class="c-article-section__title-number">8.2.1 </span>Hierarchical Layered Loops</h4><p>As is usually done in jigsaw puzzle solvers, we start by finding candidate mates for each edge by aggregating the set of all unordered pairs of edges that satisfy the constraints <span class="mathjax-tex">\(\tilde{C}_1, \tilde{C}_2\)</span> (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec10">5.1</a>). We denote this set by <span class="mathjax-tex">\(\tilde{M}\)</span></p><div id="Equ42" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \tilde{M} = \left\{ \{e_i^j, e_k^l\} \Bigm | e_i^j, e_k^l \in E \;\wedge \; \tilde{C}_1\left( e_i^j, e_k^l\right) \;\wedge \; \tilde{C}_2\left( e_i^j, e_k^l\right) \right\} \;, \end{aligned}$$</span></div></div><p> and recall that the higher the noise level, the more numerous are the potential matings, as analyzed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec29">7.9</a>.</p><p>As mentioned earlier, in crossing cuts puzzles with uniformly distributed random cuts, the probability of more than two cuts meeting at a point is nil (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec8">4</a>). It directly follows that all <i>inner</i> puzzle junctions constitute exactly four pieces. We utilize this property to identify ordered lists of 4 mating candidates that form such junctions, or <i>loops</i>, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig25">25</a>. Formally, a mating loop in the <i>clockwise</i> direction is a 4-tuple</p><div id="Equ12" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;(m_1, m_2, m_3, m_4) = \nonumber \\&amp;\left( \left\{ e_A^{j_A}, e_B^{i_B}\right\} , \left\{ e_B^{j_B}, e_C^{i_C}\right\} , \left\{ e_C^{j_C}, e_D^{i_D}\right\} , \left\{ e_D^{j_D}, e_A^{i_A}\right\} \right) \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (12)
                </div></div><p> such that <span class="mathjax-tex">\(m_k \in \tilde{M}\; \forall k=1..4\)</span> and the following conditions hold: </p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">Cond 1:</span>
                      
                        <p>No piece appears twice, i.e. <span class="mathjax-tex">\(p_A \ne p_B \ne p_C \ne p_D\)</span> (i.e., <span class="mathjax-tex">\(A\ne B\ne C\ne D\)</span>).</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">Cond 2:</span>
                      
                        <p>If a mating in the loop “enters” a piece <i>p</i> though its <span class="mathjax-tex">\(e_p^i\)</span> edge, the consecutive mating “exists” the same piece through the adjacent edge <span class="mathjax-tex">\(e_p^j=e_p^{(i-1) \mod N_p}\)</span>, where <span class="mathjax-tex">\(N_p\)</span> is the number of <i>p</i>’s edges (and also vertices; cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec7">3</a>). In other words, it “exits” through an edge immediately <i>counterclockwise</i> to <span class="mathjax-tex">\(e_p^i\)</span> along the piece border. See edges <span class="mathjax-tex">\(e_{B}^4\)</span> and <span class="mathjax-tex">\(e_{B}^3\)</span> in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig25">25</a>B for an example.</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">Cond 3:</span>
                      
                        <p>The loop begins and ends with the same piece. This is in fact true by the definition in Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ12">12</a> as both the first and last matings contain the same edge of piece <span class="mathjax-tex">\(p_A\)</span>.</p>
                      
                    </li>
                  </ol><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-25" data-title="Fig. 25"><figure><figcaption><b id="Fig25" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 25</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/25" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig25_HTML.png?as=webp"><img aria-describedby="Fig25" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig25_HTML.png" alt="figure 25" loading="lazy" width="685" height="295"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-25-desc"><p>0-loops formation from pairwise matings. <b>A</b> A bag <span class="mathjax-tex">\(\tilde{M}\)</span> of 5 potential matings, of which <span class="mathjax-tex">\((e_A^1, e_E^0)\)</span> is wrong but included because it satisfied both <span class="mathjax-tex">\(\tilde{C}_1\)</span> and <span class="mathjax-tex">\(\tilde{C}_2\)</span>. <b>B</b> The loop <span class="mathjax-tex">\((e_A^1, e_B^4) \rightarrow (e_B^3, e_C^2) \rightarrow (e_C^1, e_D^2)\rightarrow (e_D^1, e_A^2)\)</span> is identified and supports the plausibility of its constituent matings. Note that the path ending with <span class="mathjax-tex">\((e_A^1, e_E^0)\)</span> does not close a loop because the mating <span class="mathjax-tex">\((e_E^{2}, e_C^2)\)</span> is not present in the bag</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/25" data-track-dest="link:Figure25 Full size image" aria-label="Full size image figure 25" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Since these basic loops are the building blocks for the puzzle reconstruction, and since their number is polynomial in the number of candidate matings, we search for them exhaustively among all <span class="mathjax-tex">\(O\left( |\tilde{M}|^4 \right) \)</span> possible mating 4-tuples, keeping only those that satisfy all of the above constraints. However, to nevertheless spare <span class="mathjax-tex">\(75\%\)</span> of combinations and avoid searching and storing all 4 circular shift permutations of the same loop, we force loops to start with the edge having the lowest index.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-26" data-title="Fig. 26"><figure><figcaption><b id="Fig26" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 26</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/26" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig26_HTML.png?as=webp"><img aria-describedby="Fig26" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig26_HTML.png" alt="figure 26" loading="lazy" width="685" height="201"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-26-desc"><p>Hierarchical loops formation. Shown left to right, top to bottom, the formation of a higher-level loop (in this case, 1-loop) is done by scanning the boundary of the lower-level loop (in this case, 0-loop) until looping all around it with consistent 0-loops that match existing matings and pieces. In particular, the last added 0-loop much also match the first added one</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/26" data-track-dest="link:Figure26 Full size image" aria-label="Full size image figure 26" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Let now <span class="mathjax-tex">\(\mathcal {L}\)</span> be the bag of basic loops computed as above. We now exploit partial <i>overlaps</i> between loops to identify <i>correct</i> matings more robustly instead of relying on <span class="mathjax-tex">\(\tilde{M}\)</span> matings alone. More specifically, the next stage of the puzzle reconstruction algorithm is searching for “higher-order” loops, i.e., loops of loops, or <i>hierarchical loops</i> (Son et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. IEEE Transactions on Pattern Analysis and Machine Intelligence." href="/article/10.1007/s11263-024-02033-7#ref-CR67" id="ref-link-section-d337817856e20753">2018</a>). Denoting the basic 4-tuple loops in <span class="mathjax-tex">\(\mathcal {L}\)</span> as 0-loops, we now seek all possible <i>x</i>-loops by trying to <i>fully enclose</i> <span class="mathjax-tex">\((x\!\!-\!\!1)\)</span>-loops with partially overlapping 0-loops, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig26">26</a>. Toward that end, let <span class="mathjax-tex">\((e_1,e_2\dots e_k)\)</span> be the list of edges along the boundary of some <span class="mathjax-tex">\((x\!\!-\!\!1)\)</span>-loop. For example, the boundary of the 0-loop in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig25">25</a>B is <span class="mathjax-tex">\((e_A^0, e_B^0,e_B^1, e_B^2, e_C^0, e_D^3,e_D^3, e_D^4, e_D^5)\)</span>. Starting with <span class="mathjax-tex">\(e_1\)</span> and ending with <span class="mathjax-tex">\(e_k\)</span>, we progressively construct a higher level <i>x</i>-loop by searching and merging a proper0-loop from <span class="mathjax-tex">\(\mathcal {L}\)</span> that matches a <i>sub-loop</i> of the current <i>x</i>-loop around <span class="mathjax-tex">\(e_i\)</span>. For example, if we start from the boundary edge <span class="mathjax-tex">\(e_A^0\)</span> in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig25">25</a>B, we look for 0-loops that not only include that edge but also include edges from piece <span class="mathjax-tex">\(p_B\)</span>, i.e., the mating <span class="mathjax-tex">\(\left\{ e_B^4, e_A^1 \right\} \)</span> and the edge <span class="mathjax-tex">\(e_B^0\)</span>. As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig26">26</a>, the loop that was found in this particular example constitutes <span class="mathjax-tex">\( \left( \left\{ e_{A}^0, e_F^0 \right\} , \left\{ e_{F}^3, e_G^1 \right\} ,\left\{ e_{G}^0, e_B^0 \right\} ,\left\{ e_{B}^4, e_A^1 \right\} \right) \)</span>. Typically, and unless it is near the corner of the <span class="mathjax-tex">\((x\!\!-\!\!1)\)</span>-loop, the 0-loops that are identified for merging will need to match an existing sub-loop of at least 3 edges and at least one mating. And yet, despite these multiple constraints, it is possible that more than one 0-loop in <span class="mathjax-tex">\(\mathcal {L}\)</span> will match around some boundary edge of the current <span class="mathjax-tex">\((x\!\!-\!\!1)\)</span>-loop, and consequently, it is possible that more than one <i>x</i>-loop will fit around a given <span class="mathjax-tex">\((x\!\!-\!\!1)\)</span>-loop. In such cases, we generate and store them all for subsequent processing.</p><p>The process just described constructs the hierarchical loops in “layers” to produce a bag of <i>x</i>-loops for each layer <i>x</i>. Each of the 0-loops in <span class="mathjax-tex">\(\mathcal {L}\)</span> may produce several 1-loops, each of them may produce several 2-loops, and so forth, until a layered representation is established, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig27">27</a>A. This process terminates at level <span class="mathjax-tex">\(x_{\max }\)</span> if not even a single <span class="mathjax-tex">\((x_{\max }\!\!+\!\!1\)</span>)-loop can be constructed, an event likely to happen if such loops overflow beyond the true (though unknown) puzzle boundary.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec34"><span class="c-article-section__title-number">8.2.2 </span>Ranking Hierarchical Loops</h4><p>Although hierarchical loops require simultaneous consensus between growing numbers of participating matings, and thereby reduce significantly the possibility of wrong combinations, false positives are still possible due to the noise. To rank better and worse loops, we utilize the fact that each of them is a small noisy puzzle of pieces <span class="mathjax-tex">\(P_{loop}\)</span> and (known) matings <span class="mathjax-tex">\(M_{loop}\)</span> (cf. Sect. 6.1), and that “correct” loops can be “solved” for their spatial transformations with little to no overlaps even when collisions are allowed when we follow the multi-body spring-mass mechanism from Sec <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec31">8.1</a>. We therefore employ this scheme and rank the different <i>x</i>-loops by their convergence state. We first define the following “quality” measure</p><div id="Equ13" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;Q_{overlap}(P_{loop}, M_{loop}) \nonumber \\&amp;\quad = \sum _{p_i\in P_{loop}} \frac{ \left| A(p_i) \cap \left( \bigcup _{p_j \ne p_i}A(p_j) \right) \right| }{\left| A(p_i) \right| } \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (13)
                </div></div><p>where <span class="mathjax-tex">\(A(p_i)\)</span> represents the <i>region</i> (as a set of points) of piece <span class="mathjax-tex">\(p_i\)</span> in its final pose <span class="mathjax-tex">\((R_i,\vec {t\,}_i)\)</span> and the measure as whole is a modified Dice coefficient (Dice, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1945" title="Dice, L. R. (1945). Measures of the amount of ecologic association between species. Ecology, 26(3), 297–302." href="/article/10.1007/s11263-024-02033-7#ref-CR18" id="ref-link-section-d337817856e22002">1945</a>) between each piece and the rest of the pieces. Since the distance between all adjacent vertices in “correct” loops also must be small, we also consider the distances between corresponding vertices as defined by <span class="mathjax-tex">\(M_{loop}\)</span> measured <i>after</i> collisions are prohibited:</p><div id="Equ43" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} Q_{dist}(P_{loop}, M_{loop})&amp;= \sum _{\vec {v\,}_i, \vec {v\,}_{i'}} \Vert \vec {v\,}_i - \vec {v\,}_{i'} \Vert ^2 \;. \end{aligned}$$</span></div></div><p>Combining both scores into one rank we get:</p><div id="Equ44" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} Q_{loop}(P_{loop}, M_{loop}) =&amp;w_1 \cdot Q_{overlap}(P_{loop}, M_{loop}) + \nonumber \\&amp;w_2 \cdot Q_{dist}(P_{loop}, M_{loop}) \end{aligned}$$</span></div></div><p>and while the weights can prioritize one score over the other, in our evaluation we found that <span class="mathjax-tex">\(w_1=w_2=1\)</span> produces excellent results and that sensitivity to these values is very small.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-27" data-title="Fig. 27"><figure><figcaption><b id="Fig27" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 27</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/27" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig27_HTML.png?as=webp"><img aria-describedby="Fig27" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig27_HTML.png" alt="figure 27" loading="lazy" width="685" height="238"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-27-desc"><p>The outline of the reconstruction process. <b>A</b> Hierarchical loops of all levels are found, where each level is used as a starting point to search for the next level. Note that the max-level loop may not cover the entire puzzle. <b>B</b> The hierarchical loops are merged by iterating over the loop levels in decreasing order. Each level is merged in increasing order based on the score. <b>C</b> The merged pieces are positioned using the spring-mass system</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/27" data-track-dest="link:Figure27 Full size image" aria-label="Full size image figure 27" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec35"><span class="c-article-section__title-number">8.2.3 </span>Merging Hierarchical Loops</h4><p>Even with the best hierarchical loop found at the maximum level, the process of puzzle reconstruction is not yet finished since the maximum level of hierarchical loops does not necessarily cover the entire puzzle (e.g. the 2-loop in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig27">27</a>A). To complete the process and obtain the matings for the complete puzzle we now attempt to merge hierarchical loops. The <i>x</i>-loops are first sorted at each level <i>x</i> according to their rank <i>Q</i> (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec34">8.2.2</a>), and this list is then scanned from the best and highest level loops (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig27">27</a>B).</p><p>More formally, let <span class="mathjax-tex">\(P_{agg}, M_{agg}\)</span> denote the pieces and matings of the merging (or aggregation) process, initialized to be the best <span class="mathjax-tex">\(x_{max}\)</span>-loop. Scanning now the sorted list of all <i>x</i>-loops, each is merged into the aggregated structure if several conditions hold. Assuming the pieces of the current <i>x</i>-loop under consideration are <span class="mathjax-tex">\(P_{loop}\)</span>, and they are connected with <span class="mathjax-tex">\(M_{loop}\)</span> matings, this loop is merged into <span class="mathjax-tex">\(P_{agg}, M_{agg}\)</span> if</p><ul class="u-list-style-bullet">
                    <li>
                      <p>at least one piece is shared with the aggregated structure, i.e <span class="mathjax-tex">\(P_{agg} \cap P_{loop} \ne \emptyset \)</span>,</p>
                    </li>
                    <li>
                      <p>at least one piece is novel, i.e <span class="mathjax-tex">\(P_{agg} \cup P_{loop} \ne P_{agg}\)</span>, and</p>
                    </li>
                    <li>
                      <p>there is no contradiction between the matings in <span class="mathjax-tex">\(M_{agg}\)</span> and <span class="mathjax-tex">\(M_{loop}\)</span>, i.e. if <span class="mathjax-tex">\(\{e_A^i, e_{B}^j\} \in M_{loop}\)</span> then either <span class="mathjax-tex">\(\{ e_A^i, e_{B}^j\} \in M_{agg}\)</span> <i>or</i> none of the matings in <span class="mathjax-tex">\(M_{agg}\)</span> contains edges <span class="mathjax-tex">\(e_A^i\)</span> or <span class="mathjax-tex">\(e_B^j\)</span>.</p>
                    </li>
                  </ul><p>The merging process continues through the lowest ranked 0-loop, and is then repeated from the start until <span class="mathjax-tex">\(M_{agg}\)</span> no longer changes during a full scan. This process must converge since the aggregation can include each possible mating at most once.</p><p>After the aggregated structure converges, the multi-body spring-mass process is performed one last time to position all the pieces <span class="mathjax-tex">\(P_{agg}\)</span> properly based on the obtained mating <span class="mathjax-tex">\(M_{agg}\)</span>. The result is the final reconstructed crossing cuts puzzle.</p><h3 class="c-article__sub-heading" id="Sec36"><span class="c-article-section__title-number">8.3 </span>Incorporating <i>Pictorial</i> Constraints</h3><p>As the analysis of puzzle properties showed, larger geometrical noise increases rapidly the number of potential mates that are found using the geometrical constraints (<span class="mathjax-tex">\(\tilde{C}_1\)</span> and <span class="mathjax-tex">\(\tilde{C}_2\)</span>) (cf. Sec <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec29">7.9</a>). Similar effect is induced by increasing the number of cuts. In these cases, using the pictorial content of the piece can provide a big advantage. In particular, while the initial set <span class="mathjax-tex">\(\tilde{M}\)</span> of potential matings can be obtained using geometrical constraint, scoring and ranking these matings based on pictorial content may drastically reduce admissible matings and thus the computational effort of the reconstruction algorithm discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec32">8.2</a>.</p><p>It should be emphasized from the outset that, unlike geometrical constraints, pictorial content alone cannot exclude matings with full certainty, as two genuinely neighboring pieces may legitimately have drastically different pictorial content even along their abutting boundaries. A solver can thus ”take risks” and heuristically excludes pictorial matches below some predefined fidelity threshold, but strictly speaking, the pictorial content can help only in <i>prioritizing</i> certain matings over others, and therefore it can merge naturally into the ranking process described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec32">8.2</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-28" data-title="Fig. 28"><figure><figcaption><b id="Fig28" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 28</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/28" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig28_HTML.png?as=webp"><img aria-describedby="Fig28" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig28_HTML.png" alt="figure 28" loading="lazy" width="685" height="283"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-28-desc"><p>Extrapolation of visual information. <b>A</b> An original piece. <b>B</b> A geometrically noisy piece. <b>C</b> The extrapolated piece for extrapolation radius of <span class="mathjax-tex">\(\varepsilon =25\)</span> pixels</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/28" data-track-dest="link:Figure28 Full size image" aria-label="Full size image figure 28" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Similar to methods proposed for solving other pictorial puzzles in the literature, mostly in the context of square jigsaw puzzles (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec2">2</a>), a pictorial compatibility score can be based on some dissimilarity measure of the colors along the <i>edges</i> or <i>margins</i> of puzzle pieces, while paying less attention to the pictorial information deeper inside each piece. However, unlike in the common case studied in the square jigsaw puzzle literature, here our setting is far more challenging, for several reasons. First, pieces in crossing cuts puzzles are essentially never aligned with the pixel grid, making both the representation of the pictorial content and its use in a comparison measure, ill-defined and prone to aliasing (among other problems). Second, and even more critical, is the fact that the geometric noise renders the information that is vital for the comparison simply missing. In fact, it forces us to do what the square jigsaw puzzle literature has usually been avoiding deliberately, namely to use pictorial information <i>further away</i> from the piece boundaries. And third, the geometric noise also introduces uncertainty about the proper offset between neighboring pieces in the direction of the mates. In addition to Gur and Ben-Shahar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Gur, S., &amp; Ben-Shahar, O. (2017). From square pieces to brick walls: The next challenge in solving jigsaw puzzles. In Proceedings of the IEEE international conference on computer vision (pp. 4029–4037)." href="/article/10.1007/s11263-024-02033-7#ref-CR28" id="ref-link-section-d337817856e23331">2017</a>), who introduced the last consideration in their brick wall puzzle setup, only a handful of works address square piece puzzles with gaps between their pieces (i.e., eroded pieces that might have no direct contact), including Paumard et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Paumard, M.-M., Picard, D., &amp; Tabia, H. (2020). Deepzzle: Solving visual jigsaw puzzles with deep learning and shortest path optimization. IEEE Transactions on Image Processing, 29, 3569–3581." href="/article/10.1007/s11263-024-02033-7#ref-CR55" id="ref-link-section-d337817856e23335">2020</a>) that employes a deep network to predict the position of the pieces, and Song et al.. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2023" title="Song, X., Yang, X., Ren, J., Bai, R., &amp; Jiang, X. (2023). Solving jigsaw puzzle of large eroded gaps using puzzlet discriminant network. In ICASSP 2023 - 2023 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 1–5)." href="/article/10.1007/s11263-024-02033-7#ref-CR69" id="ref-link-section-d337817856e23338">2023</a>) that employs two types of deep networks and a genetic algorithm.</p><p>To deal with all these problems simultaneously, and inspired by similar ideas in the literature (Liu et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Liu, H., Cao, S., &amp; Yan, S. (2011). Automated assembly of shredded pieces from multiple photos. IEEE Transactions on Multimedia, 13(5), 1154–1162." href="/article/10.1007/s11263-024-02033-7#ref-CR39" id="ref-link-section-d337817856e23344">2011</a>; Derech et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Derech, N., Tal, A., &amp; Shimshoni, I. (2021). Solving archaeological puzzles. Pattern Recognition, 108065." href="/article/10.1007/s11263-024-02033-7#ref-CR17" id="ref-link-section-d337817856e23347">2021</a>), we score a candidate mating <span class="mathjax-tex">\(m = \{e_i^j, e_k^l\}\)</span> by extrapolating the information of the two corresponding puzzle pieces <span class="mathjax-tex">\(p_i\)</span> and <span class="mathjax-tex">\(p_k\)</span> to a spatial band beyond their boundaries and thus obtaining ”dilated” pictorial pieces on which a compatibility measure can be applied more safely. There are many ways of doing such extrapolation, but most of those we experimented with perform too poorly to provide a reliable visual outcome that in turn can facilitate reliable pictorial compatibility score <span class="mathjax-tex">\(S(m) = S(\{e_i^j, e_k^l\})\)</span> for mating <i>m</i>. In our work, we first applied the basic inpainting method due to Telea (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Telea, A. (01 2004). An image inpainting technique based on the fast marching method. Journal of Graphics Tools 9." href="/article/10.1007/s11263-024-02033-7#ref-CR71" id="ref-link-section-d337817856e23518">2004</a>). We then fed the results, after resizing and padding, to a pre-trained deep Stable-Diffusion network (Rombach et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2022" title="Rombach, R., Blattmann, A., Lorenz, D., Esser, P., &amp; Ommer, B. (June 2022). High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR) (pp. 10684–10695)." href="/article/10.1007/s11263-024-02033-7#ref-CR60" id="ref-link-section-d337817856e23521">2022</a>) to extrapolate the pieces beyond their original boundaries, as far as a band whose thickness is defined by the bound <span class="mathjax-tex">\(\varepsilon \)</span> on the geometric noise. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig28">28</a> illustrates a selected result of the pictorial extrapolation and compares it to the original pictorial content. It goes without saying that in our case the available information is taken from the <span class="mathjax-tex">\(\varepsilon \)</span>-noisy (i.e., “eroded”) piece while the pictorially extrapolated (i.e., “diluted”) piece usually extends even beyond the boundaries of the original noiseless piece.</p><p>With the extrapolated pieces computed, one can conceive many different ways to measure the compatibility of any two mates even without knowing the details of the geometric noise that affected them. For example, we note that by design of the extrapolation procedure, there must be some overlapping content between the two extrapolated pieces. Hence, one can attempt to register the two pieces and find the relative Euclidean transformation that places them next to each other with proper pictorial overlap along the extrapolated boundaries. This also may provide some information about the localization of pieces in the reconstructed puzzle, but at the same time, this approach is very sensitive and prone to errors (as the overlapping extrapolated pictorial information available for registration is both scarce and hypothetical) and therefore does not make the global optimization from Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec31">8.1</a> redundant. Because of such observations, it may be more effective to design a scoring mechanism that does not pretend to localize the pieces but is rather <i>invariant</i> to the relative transformation, for example by producing a <i>scalar</i> score for the dissimilarity embodied in any candidate mating. And while numerous such measures can be developed, we currently elected to implement the following simple scheme.</p><p>Given a candidate mating <span class="mathjax-tex">\(m=\{e_i^j, e_k^l\}\)</span> from two different pieces <span class="mathjax-tex">\(p_i\)</span> and <span class="mathjax-tex">\(p_k\)</span>, we wish to compare the pictorial information around different corresponding points along <span class="mathjax-tex">\(e_i^j\)</span> and <span class="mathjax-tex">\(e_k^l\)</span>. For that, we sample both edges an equal number of times from one end to the other and compare visual windows around corresponding samples. More specifically, denote by <span class="mathjax-tex">\(W(\vec {v}) \in \mathcal {R}^{h \times h}\)</span> the square pixel window around position <span class="mathjax-tex">\(\vec {v}\)</span> and let <span class="mathjax-tex">\(F(\vec {v}) \in \mathcal {R}\)</span> be its average color across the channels, i.e.,</p><div id="Equ45" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} F(\vec {v}) = \frac{1}{|W| \cdot 3} \sum _{\vec {w} \in W(\vec {v})} \left( R(\vec {w}) + G(\vec {w}) + B(\vec {w}) \right) \;. \end{aligned}$$</span></div></div><p> To evaluate the pictorial affinity of the two edges, we sample both <span class="mathjax-tex">\(e_i^j\)</span> and <span class="mathjax-tex">\(e_k^l\)</span> evenly <span class="mathjax-tex">\(G+1\)</span> times, including at their vertices <span class="mathjax-tex">\((v_i^{j},v_i^{j + 1})\)</span> and <span class="mathjax-tex">\((v_k^{l },v_k^{l + 1})\)</span>. We next consider all the mean color values of the windows <span class="mathjax-tex">\(W(\vec {v})\)</span> along either <span class="mathjax-tex">\(e_i^j\)</span> and <span class="mathjax-tex">\(e_k^l\)</span> as two vectors in a <span class="mathjax-tex">\(G+1\)</span> dimensional space and compute the <span class="mathjax-tex">\(L_1\)</span> norm of their difference. The result serves as our measure of dissimilarity <i>S</i>(<i>m</i>). Formally,</p><div id="Equ46" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} S(m)&amp;= \,\sum _{k = 0}^{G} \left| F\left( \frac{k}{G} \cdot v_i^{i + 1} + \left( 1 - \frac{k}{G} \right) \cdot v_i^{i} \right) \right. \\&amp;\qquad \quad \left. - F\left( \frac{k}{G} \cdot v_k^{l} + \left( 1 - \frac{k}{G} \right) \cdot v_k^{l + 1} \right) \right| \;. \end{aligned}$$</span></div></div><p>Note that the running windows may not be completely synchronized in relative position since the edges may have slightly different noisy lengths. In addition, the possibly different transformations of the two pieces suggest that the two pictorial windows will exhibit different aliasing and thus slightly different pixel values. However, the low pass filtering embedded implicitly in <i>S</i>(<i>m</i>) and the fact that a pictorial descriptor based on scalar window averages is invariant to the different relative transformations of each piece, provide robustness to both confounds. Clearly, one can conceive numerous other ways of implementing compatibilities for polygonal pieces and future work is likely to put additional attention on this challenge. However, despite being relatively simple, the <i>S</i>(<i>m</i>) measure is already descriptive enough to allow effective pictorial scoring of matings. A depiction of this process is provided in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig29">29</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-29" data-title="Fig. 29"><figure><figcaption><b id="Fig29" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 29</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/29" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig29_HTML.png?as=webp"><img aria-describedby="Fig29" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig29_HTML.png" alt="figure 29" loading="lazy" width="685" height="329"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-29-desc"><p>The pictorial scoring process in action. Two running windows (in green) are simultaneously scanning the extrapolated pictorial content of the two candidate mates (in orange). The sample points are shown in black. The differences in window averages at all corresponding locations are aggregated into a <span class="mathjax-tex">\(G+1\)</span> dimensional vector, whose <span class="mathjax-tex">\(L_1\)</span> norm serves as the dissimilarity measure <i>S</i>(<i>m</i>). Note that the pictorial descriptor based on these window averages is invariant to the relative transformation, and although being simple it is descriptive enough to allow effective scoring and filtering or matings</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/29" data-track-dest="link:Figure29 Full size image" aria-label="Full size image figure 29" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>With a pictorial score for each candidate mating, and keeping in mind that <span class="mathjax-tex">\(\tilde{M}\)</span> denotes all matings that satisfy the noisy <i>geometric</i> constraints, we now define the <i>pictorially constrained mating set</i> <span class="mathjax-tex">\(\tilde{M}_p\)</span> by considering for each edge pair only the <i>T</i> matings that scored the best (i.e., lowest) <i>S</i>(<i>m</i>), with <i>T</i> being some predefined number or an absolute percentile, that could depend on available computational or time resources. Formally, if <span class="mathjax-tex">\(H_T(X)\)</span> denotes the set of <i>T</i> matings with the lowest <i>S</i>(<i>m</i>) score in a given set <span class="mathjax-tex">\(X \subseteq \tilde{M}\)</span>, then <span class="mathjax-tex">\(\tilde{M}_p\)</span> is defined as follows</p><div id="Equ47" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \tilde{M}_p = \bigcup _{\{e \in E\}} H_T(\{m | m \in \tilde{M} \wedge e \in m\})\;\;. \end{aligned}$$</span></div></div><p>It goes without saying that the higher the geometrical noise (expressed by its bounds <span class="mathjax-tex">\(\varepsilon \)</span> or alternatively, <span class="mathjax-tex">\(\xi \)</span>), the more significant the pictorial compatibility and pictorial mating filtering become. This quickly allows a drastic (typically an order of magnitude or larger) decrease in the number of potential matings, thus making much larger puzzles potentially solvable. Once the pictorially constrained set <span class="mathjax-tex">\(\tilde{M}_p\)</span> is computed, the reconstruction process can proceed exactly as described for the apictorial case (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec30">8</a>), including the global considerations encapsulated in the hierarchical layered loopy constraints (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec32">8.2</a>).</p></div></div></section><section data-title="Evaluation Metrics and Experimental Results"><div class="c-article-section" id="Sec37-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec37"><span class="c-article-section__title-number">9 </span>Evaluation Metrics and Experimental Results</h2><div class="c-article-section__content" id="Sec37-content"><p>This paper presented a new visual puzzle model, analyzed its properties, and suggested a solution scheme for both apictorial and pictorial variants. To test our approach, and having no prior work on crossing cuts or polygonal puzzles in the literature, our experimental evaluation focus on the formulation of performance metrics and reporting qualitative and quantitative results on the novel benchmark datasets presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec15">6</a>. Note that these datasets include both pictorial and apictorial puzzles with varying global shape, different numbers of crossing cuts, and a range of noise levels. Results of the naive algorithm for “clean” puzzles are not reported as it always reconstructs the puzzles perfectly.</p><h3 class="c-article__sub-heading" id="Sec38"><span class="c-article-section__title-number">9.1 </span>Evaluation Metrics</h3><p>As mentioned in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec30">8</a>, under geometric noise it is unclear what is the desired position (i.e., Euclidean transformation) of each piece in the reconstructed puzzle, and the multi-body spring-mass system aspires to obtain a solution that optimizes an intuitive objective. It still remains to score such solutions as to allow their quantitative evaluation and comparison, and for that purpose, one can assume the availability of a ground truth solution against which the evaluation is performed. As discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec7">3</a>, any solution, be it the ground truth or one computed by a solver, constitutes both a mating graph and the Euclidean transformation of each piece, and thus the evaluation must take both into account. Unfortunately, this is not a straightforward task.</p><p>The evaluation of the mating graph is perhaps clearer, as we wish to compare two graph structures that could differ only in their set of links.<sup><a href="#Fn6"><span class="u-visually-hidden">Footnote </span>6</a></sup> Inspired by the Neighbor Comparison Metric from the square jigsaw puzzle literature (e.g., Cho et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Cho, T. S., Avidan, S., &amp; Freeman, W. T. (2010). A probabilistic image jigsaw puzzle solver. In 2010 IEEE computer society conference on computer vision and pattern recognition (pp. 183–190). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR13" id="ref-link-section-d337817856e25029">2010</a>; Pomeranz et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Pomeranz, D., Shemesh, M., &amp; Ben-Shahar, O. (2011). A fully automated greedy square jigsaw puzzle solver. In CVPR 2011, (pp. 9–16). IEEE." href="/article/10.1007/s11263-024-02033-7#ref-CR57" id="ref-link-section-d337817856e25032">2011</a>, Sholomon et al.,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Sholomon, D., David, O., &amp; Netanyahu, N. S. (2013). A genetic algorithm-based solver for very large jigsaw puzzles. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1767–1774)." href="/article/10.1007/s11263-024-02033-7#ref-CR63" id="ref-link-section-d337817856e25035">2013</a>) we therefore define an evaluation metric for the computed matings as an area-weighted precision and recall measures of the computed matings:</p><div id="Equ14" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} Q_{precision}&amp;= \frac{ \sum _{{e_i^j, e_k^l} \in M_{gt} \cap M_{sol}}{ \left( \left| A(p_i) \right| + \left| A(p_j)\right| \right) } }{ \sum _{{e_i^j, e_k^l} \in M_{gt}}{ \left( \left| A(p_i)\right| + \left| A(p_j)\right| \right) } } \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (14)
                </div></div><div id="Equ15" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} Q_{recall}&amp;= \frac{ \sum _{{e_i^j, e_k^l} \in M_{gt} \cap M_{sol}}{ \left( \left| A(p_i)\right| + \left| A(p_j)\right| \right) } }{ \sum _{{e_i^j, e_k^l} \in M_{sol}}{ \left( \left| A(p_i)\right| + \left| A(p_j)\right| \right) } } \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (15)
                </div></div><p>where <span class="mathjax-tex">\(M_{gt}\)</span> are the ground truth matings, <span class="mathjax-tex">\(M_{sol}\)</span> are the matings of the solution found by the reconstruction algorithm, and <span class="mathjax-tex">\(A(p_i)\)</span> represents the <i>region</i> (i.e., set of points) of piece <span class="mathjax-tex">\(p_i\)</span> in its final pose, as in Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ13">13</a>.</p><p>The scoring of the Euclidean transformation of pieces is more tricky. For example, we observe that even qualitatively perfect solutions by the spring-mass system may differ by a global Euclidean transformation due to arbitrary choice of a coordinate system in the representation of the pieces (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec7">3</a> and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig3">3</a>A). The situation becomes significantly more ambiguous once the solutions are not perfect (as is always the case under noise) and scoring needs to consider the placement of each and every piece of the puzzle separately.</p><p>With such challenges in mind, assume we have a solution we wish to score, i.e., the mating graph and the Euclidean transformation of all pieces in a reconstructed puzzle. Let <span class="mathjax-tex">\(\vec {u\,}_i^j\)</span> be the vertices of piece <span class="mathjax-tex">\(p_i\)</span> in the ground truth and <span class="mathjax-tex">\(\vec {v\,}_i^{j}\)</span> the corresponding vertices of <span class="mathjax-tex">\(\tilde{p}_i\)</span> in the obtained solution. We first globally align the obtained solution with the ground truth before comparing the placement of individual pieces. In other words, we wish to find a global Euclidean transformation <span class="mathjax-tex">\((R^*,t^*)\)</span> that aligns the reconstructed pieces “as close as possible” to the ground truth so they can be compared. To do so we employ SVD for Least-Squares Rigid Motion (Sorkine-Hornung &amp; Rabinovich, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Sorkine-Hornung, O., &amp; Rabinovich, M. (2017). Least-squares rigid motion using svd. Computing, 1, 1." href="/article/10.1007/s11263-024-02033-7#ref-CR70" id="ref-link-section-d337817856e25804">2017</a>) to solve the following weighted minimization</p><div id="Equ16" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} (R^*,t^*) = \underset{(R,t)}{\textrm{argmin}} \sum _{i=1}^n \sum _{j=1}^{N_i} w_i \Vert (R \vec {v\,}_i^{j} + t) - \vec {u\,}^j_i \Vert ^2 \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (16)
                </div></div><p>where the weights <span class="mathjax-tex">\(w_i\)</span> are set to be proportional to the area of each piece to reflect the greater importance of larger pieces on the shape of the puzzle, i.e.,</p><div id="Equ17" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} w_i = \frac{\left| A(p_i)\right| }{\sum _{k=1}^n \left| A(p_k) \right| }\;. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (17)
                </div></div><p>Qualitatively, the more similar the mating graphs of the reconstructed puzzle and the ground truth, the better the global alignment will be and thus a better (i.e., smaller) score will be achieved by the optimal global transformation <span class="mathjax-tex">\((R^*,t^*)\)</span>. However, Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ16">16</a> in itself is not a convenient metric for the quality of the overall solution since it depends on the specific puzzle evaluated. In that sense, that score may allow the comparison of different solutions (say by different solvers) to the <i>same</i> puzzle, but it provides hardly any insights about the solution quality to an arbitrary puzzle, it does not allow ordering the solutions of different puzzles, and it prohibits aggregation of many solutions into statistical measures on whole datasets.</p><p>To overcome all these difficulties, we seek a more informative measure that is <i>normalized</i> to some canonical range (say [0, 1]). We therefore consider the degree of area overlaps between the pieces in the solution vs. their ground truth counterpart, after the two solutions have been aligned with Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ16">16</a>. Formally, if <span class="mathjax-tex">\(\tilde{p}_i'\)</span> is the noisy piece <span class="mathjax-tex">\(\tilde{p}_i\)</span> <i>after</i> being placed in the reconstructed puzzle, i.e.,</p><div id="Equ48" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \tilde{p}_i' = \left\{ R_i \cdot \vec {v\,}_i^1 + \vec {t\,}_i, R_i \cdot \vec {v\,}_i^2 + \vec {t\,}_i,\ldots , R_i \cdot \vec {v\,}_i^{N_i} + \vec {t\,}_i\right\} \end{aligned}$$</span></div></div><p>then we define</p><div id="Equ18" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} Q_{pos}(R_1, t_1 ,\dots R_n t_n) = \sum _{i=1}^n w_i \cdot \frac{ \left| A(p_i) \cap A(\tilde{p}_i') \right| ) }{ \left| A(\tilde{p}_i) \right| } \;\;. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (18)
                </div></div><p> where the weights are as defined in Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ17">17</a>. This measure is conservative, in the sense that high scores always imply good solutions, but good solutions do not always receive high scores, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig30">30</a>. Future research may wish to explore improved metrics for such circumstances.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-30" data-title="Fig. 30"><figure><figcaption><b id="Fig30" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 30</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/30" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig30_HTML.png?as=webp"><img aria-describedby="Fig30" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig30_HTML.png" alt="figure 30" loading="lazy" width="685" height="363"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-30-desc"><p>Being conservative, the performance metric can score a solution low even if intuitively it is good. In this 30-cut and 326-piece noisy puzzle, the reconstructed solution is qualitatively similar to the noiseless ground truth and should be considered a success. And yet, this solution scores just 0.56/1.00 by Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ18">18</a> because the noise is rather big, the gaps created between the eroded pieces is significant, and the springs tend to pull the pieces closer over the gaps and clump them in the center of the noiseless puzzle boundary (dashed line)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/30" data-track-dest="link:Figure30 Full size image" aria-label="Full size image figure 30" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-31" data-title="Fig. 31"><figure><figcaption><b id="Fig31" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 31</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/31" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig31_HTML.png?as=webp"><img aria-describedby="Fig31" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig31_HTML.png" alt="figure 31" loading="lazy" width="685" height="229"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-31-desc"><p>Qualitative performance of piece positioning for known matings. Since pictorial information plays no role in this test, we omit pictorial examples. <b>A</b> Initial random placement of pieces. Keep in mind that despite the messy organization the mates (i.e., the springs) are set correctly and we are interested to examine whether such a random initial state can lead to undesired local minima. <b>B</b> Ground truth assembly. <b>C</b> Computed assembly after convergence of the second phase of the spring-mass system. The circle marks the area shown in the closeup section in the next column. <b>D</b> A closeup on the original ground truth. <b>E</b> A closeup on the corresponding section of the noised ground truth. <b>F</b> A closeup on the corresponding section of the reconstructed assembly</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/31" data-track-dest="link:Figure31 Full size image" aria-label="Full size image figure 31" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-32" data-title="Fig. 32"><figure><figcaption><b id="Fig32" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 32</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/32" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig32_HTML.png?as=webp"><img aria-describedby="Fig32" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig32_HTML.png" alt="figure 32" loading="lazy" width="685" height="216"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-32-desc"><p>Quantitative performance of piece positioning for known matings. The dotted lines show the value of <span class="mathjax-tex">\(\bar{\xi }\)</span> to appreciate how high it can get. <b>A</b> Average positioning score of the two-phase dynamical system as a function of noise level, computed from 10 random puzzles for selected numbers of crossing cuts/pieces. Shaded bands are <span class="mathjax-tex">\(\pm 1\)</span> SE. <b>B</b> Positioning score after the application of the second phase of the dynamical system from the ground truth initial positions. <b>C</b> The difference of the first two graphs indicates that in most cases the initial state of the positioning systems has no effect, except possibly for small noise cases</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/32" data-track-dest="link:Figure32 Full size image" aria-label="Full size image figure 32" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>In summary, we use the mating measures <span class="mathjax-tex">\(Q_{precision}\)</span> and <span class="mathjax-tex">\(Q_{recall}\)</span> from Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ15">15</a> and the positions metric <span class="mathjax-tex">\(Q_{pos}\)</span> from Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ18">18</a> as our quantitative measures for evaluating puzzle solutions. Next, we apply them to different test cases.</p><h3 class="c-article__sub-heading" id="Sec39"><span class="c-article-section__title-number">9.2 </span>Experimental Evaluation of Piece Positioning</h3><p>We first tested our crossing cuts solver for positioning puzzle pieces while assuming the matings are known, i.e., we only evaluated the degree to which the abstraction as a multi-body spring-mass system (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec31">8.1</a>) provides desired results, both qualitatively and quantitatively. Clearly, for this evaluation, it is irrelevant if the puzzle is pictorial or apictorial.</p><p>To implement this test we extracted from DB2 and DB3 puzzles their set <span class="mathjax-tex">\(\tilde{P}\)</span> of noisy pieces <i>and</i> the ground truth matings <span class="mathjax-tex">\(M_{gt}\)</span>, applied the positioning system (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec31">8.1</a>) and obtained the euclidean transformation <span class="mathjax-tex">\((R_i, t_i)\)</span> of each piece <span class="mathjax-tex">\(\tilde{p}_i\)</span> in the solution. Evaluation of the result was then based on Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ18">18</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-33" data-title="Fig. 33"><figure><figcaption><b id="Fig33" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 33</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/33" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig33_HTML.png?as=webp"><img aria-describedby="Fig33" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig33_HTML.png" alt="figure 33" loading="lazy" width="685" height="254"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-33-desc"><p>Examples of successful reconstruction results. <b>A</b> The unordered bag of puzzle pieces that the solver receives as input. <b>B</b> The ground truth assembly of (noiseless) pieces <b>C</b> The reconstruction result of the noisy puzzle. <b>D, E, F</b> A zoomed area of the noiseless ground truth, the noisy ground truth, and the solution. Unlike in the ground truth, the pieces in the noisy ground truth and in the solution do not abut each other, as would be expected because of the noise in their shape. In the solution, the gaps are determined automatically by the multi-body mechanical system while minimizing the global elastic energy of the springs</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/33" data-track-dest="link:Figure33 Full size image" aria-label="Full size image figure 33" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-34" data-title="Fig. 34"><figure><figcaption><b id="Fig34" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 34</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/34" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig34_HTML.png?as=webp"><img aria-describedby="Fig34" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig34_HTML.png" alt="figure 34" loading="lazy" width="685" height="178"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-34-desc"><p>Reconstruction results on selected puzzles from DB2. <b>A</b> Results tested on 4 subsets of DB2, each containing 10 selected puzzles, sampled randomly from the original dataset with 5–50 cuts, <span class="mathjax-tex">\(\xi \)</span> (noise level relative to the puzzle diameter) varying between 0 to 0.25% and <span class="mathjax-tex">\(\bar{\xi }\)</span> (noise level relative to the average edge length) varying between 0 to 1.36%. The results show the positioning score (in blue), precision score (in orange), and recall score of the matings (in green). <b>B–D</b>An uncommon reconstruction failure. Shown are the unordered bag puzzle pieces that the solver receives as input (B), the ground truth solution (C), and the faulty reconstruction result (D) (Color figure online)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/34" data-track-dest="link:Figure34 Full size image" aria-label="Full size image figure 34" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>The first of these evaluations examined the ability of the spring-mass system to converge to the desired spatial configuration from the same initial state suggested by the algorithm, namely with the initial pose (position and rotation) of each piece chosen randomly inside the arena. Recall that the first run of the dynamical system allows pieces to overlap (a near-certain event under random piece positions). Upon convergence the same system is restarted but now while piece overlaps are prohibited. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig31">31</a> shows the initial and final configurations next to the ground truth of selected puzzles, and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig32">32</a>A presents the quantitative score <span class="mathjax-tex">\(Q_{pos}\)</span> for puzzles with various noise levels. We were particularly interested in examining if the system might converge to improper local minima that depart qualitatively from the desired organization of pieces. This never happened and as shown in the examples, convergence is qualitatively correct even in the most complex cases.</p><p>The second test aims to empirically quantify a lower bound on the deviation from ground truth positions induced by the spring-mass system. To do so we applied the positioning computational to the same set of puzzles, though this time the initial state of the pieces was the ground truth position of the noisy pieces (where <span class="mathjax-tex">\(Q_{pos}=1\)</span>), and the only computational step executed is the second phase where overlaps are prohibited. Intuitively, there could not be a better initial state for the pieces before the computation begins and thus Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig32">32</a>B represents the best positioning scores possible. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig32">32</a>C shows the performance difference between an optimal and a random initial states, thus representing how the deviation from the optimal positions is reflected in the positioning score. Note that in most cases the initial state of the positioning systems has negligible effect.</p><h3 class="c-article__sub-heading" id="Sec40"><span class="c-article-section__title-number">9.3 </span>Experimental Evaluation of <i>Apictorial</i> Puzzle Solutions</h3><p>With a system to evaluate the solutions by the multi-body spring-mass system established, we turn to evaluate the full algorithmic solution under <i>unknown</i> matings (Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec32">8.2</a>), where the input is just the noisy pieces <span class="mathjax-tex">\(\tilde{P}\)</span> (and the bound on the noise level <span class="mathjax-tex">\(\xi \)</span>) while the output includes both the matings graph <i>M</i> and the Euclidean transformations <span class="mathjax-tex">\((R_i, t_i)\)</span> of each piece <span class="mathjax-tex">\(\tilde{p}_i\)</span> in the solution. Here we first focus on apictorial puzzles and seek to evaluate both parts of the solution using the two evaluation measures, i.e., both the precision and recall from Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ15">15</a> and <span class="mathjax-tex">\(Q_{pos}\)</span> from Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ18">18</a>.</p><p>First qualitatively, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig33">33</a> presents visual examples of successful reconstructions of selected puzzles of different global shapes, number of cuts, and noise levels. Note how the solution remains loyal to the (unknown) ground truth puzzle both in terms of its global shape and he organization of the pieces. The closeup insets show how the positioning system places the pieces at some distance, as would be desired due to the noise. Indeed, the configuration is not necessarily identical and in fact slightly perturbed relative to the ground truth, where the vertices’ position (and thus the gaps) are determined automatically by the multi-body mechanical system while minimizing the energy of the springs.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-35" data-title="Fig. 35"><figure><figcaption><b id="Fig35" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 35</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/35" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig35_HTML.png?as=webp"><img aria-describedby="Fig35" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig35_HTML.png" alt="figure 35" loading="lazy" width="685" height="596"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-35-desc"><p>Selected examples of pictorial puzzle solutions (<b>A, B</b> - perturbed square jigsaw puzzles, <b>C, D</b> - general crossing cuts puzzles) having various numbers of cuts, piece size, noise levels, and visual contents. Top row shows the original image/puzzle. The second row represents the puzzle that was submitted to the solver, and the bottom row shows the solution (slightly scaled down to fit the allotted space). Recall that solutions can be perfect up to a global Euclidean transformation. <b>D</b> shows one unusual failure caused by <i>T</i> being too restrictive thus excluding the correct mating</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/35" data-track-dest="link:Figure35 Full size image" aria-label="Full size image figure 35" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-36" data-title="Fig. 36"><figure><figcaption><b id="Fig36" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 36</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/36" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig36_HTML.png?as=webp"><img aria-describedby="Fig36" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-024-02033-7/MediaObjects/11263_2024_2033_Fig36_HTML.png" alt="figure 36" loading="lazy" width="685" height="230"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-36-desc"><p>Pooled quantitative performance on pictorial puzzles. <b>A</b> Averaged on 10 DB3 puzzles, applying the pictorial constraints (P) on top of the geometrical ones (G) saves <span class="mathjax-tex">\(\sim 20\%\)</span> of the original potential matings to test. This rate is of course based on the method used to filter the potential matings, based on their pictorial compatibility scores, and may vary accordingly. In this case, all of the potential matings scored above a certain value (30%) were kept. <b>B</b> Precision and recall (Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ15">15</a>) and position score (Eq. <a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s11263-024-02033-7#Equ18">18</a>) for the pictorial puzzles from DB3. It should be noted that in cases where real puzzle matings had an unusually low pictorial compatibility score, they were filtered out of the potential matings, leading the solver to eventually fail to reconstruct the puzzle as a whole</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11263-024-02033-7/figures/36" data-track-dest="link:Figure36 Full size image" aria-label="Full size image figure 36" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig34">34</a>A shows aggregated quantitative performance selected subsets of DB2. These results indicate that the mechanism based on the hierarchical loops, loop ranking, and loop merging obtains excellent results. Still, since the problem is intractable we cannot expect the heuristics to provide a perfect solution always, and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig34">34</a>B–D exemplifies one such unlikely failure.</p><p>It should also be mentioned that although the jigsaw problem is NP-complete, and thus complete or optimal solvers are expected to be exponential, relying on the crossing cuts geometrical constraints, and the looping and merging heuristics, can decrease the practical complexity significantly. Several of the steps become polynomial, and in particular, establishing 0-loops is bounded by a <span class="mathjax-tex">\(4^{th}\)</span> order polynomial of the number of pieces. However, <i>in the noisy case</i> the number of possible mating combinations and the search in the merging step (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec32">8.2</a>) remain exponential, where in practice they are influenced by the noise bound (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec29">7.9</a>) and the number of cuts (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec20">7</a>). This is why pictorial constraints are so valuable, and the better they can be utilized and reduce the number of candidate matings, the more efficient the solver can become for a given puzzle.</p><h3 class="c-article__sub-heading" id="Sec41"><span class="c-article-section__title-number">9.4 </span>Experimental Evaluation of <i>Pictorial</i> Puzzle Solutions</h3><p>We finally turn to examine the reconstruction of pictorial puzzles and assess the role of pictorial constraints using puzzles from DB3 and DB4. Recall from Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s11263-024-02033-7#Sec15">6</a> that DB4 is a general pictorial puzzle set, while DB3 is designed to play down the role of geometrical constraints by having pieces whose edge length histogram is sharper (a condition that implies that each mate will have many more geometrically compatible matches). In such puzzles, the number of matings that satisfy constraints <span class="mathjax-tex">\(\tilde{C}_1\)</span> and <span class="mathjax-tex">\(\tilde{C}_2\)</span> is approaching the unfiltered set of matings, and thus the number of 0-loops, hierarchical loops, and possible geometrical solutions has easily overwhelmed the memory resources of the hardware we used for evaluation, which was a desktop computer with a 12th Gen Intel(R) Core(TM) i7-12700K Processor with a base clock speed of 3.60 GHz, and 32.0 GB RAM. Towards this end, we tested 10 puzzles from DB3 and DB4, all of which were solved only when the pictorial content was considered too. Selected qualitative solutions are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig35">35</a> while the average saving in potential matings due to the pictorial constraints are depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig36">36</a>A. These results are designated preliminary both because the pictorial filter is still simple, and because our present algorithm is not designed to deal with missing pieces, a condition that applies to many puzzles in DB4, once the level of the applied noise is increased.</p><p>Next to several successful solutions, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig35">35</a> shows one rare failure result. Failures such as this could happen when the value of <i>T</i> is too small and correct matings are discarded by the pictorial filter. Indeed, although the filter eliminated many mating candidates, the aggregated quantitative performance on the tested puzzles from both DBs is good, as reported in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11263-024-02033-7#Fig36">36</a>B, C. Performance on DB3 puzzles is slightly lower since as implied above, they can hardly utilize the geometrical constraints.</p></div></div></section><section data-title="Conclusions and Future Work"><div class="c-article-section" id="Sec42-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec42"><span class="c-article-section__title-number">10 </span>Conclusions and Future Work</h2><div class="c-article-section__content" id="Sec42-content"><p>We introduced a new jigsaw puzzle model and analyzed its properties and the inherent challenges in solving them once pieces are perturbed with noise. To cope with such difficulties and keep the problem tractable, we abstracted it as a multi-body spring-mass dynamical system method endowed with hierarchical loop constraints and a merging process of layered puzzle loops. Results exhibit excellent solving power but also suggest that future work should utilize pictorial data on the pieces much more strongly to drastically reduce the number of potential mates per edge and turn the problem more tractable and thus truly suited for real-life applications. This work also introduces a new class of puzzle generation models that are partially constrained, well formulated, and have enough expressive power to allow more real-life applications while being subjected to more rigorous analysis. We hope this type of thinking about “restricted modeled puzzles” can expand puzzle-solving literature to new directions, where future work should also address even more general (but formal) generation processes and noise models, as well as how to handle missing pieces in all these cases.</p></div></div></section>
                                </div>
                        
                    

                    <section data-title="Notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1" data-counter="1."><div class="c-article-footnote--listed__content"><p>It is becoming more common in recent times to find commercial jigsaw puzzles that deviate from these rules. However, we are unaware of corresponding computational literature that addresses such variations and thus ignore them here.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2" data-counter="2."><div class="c-article-footnote--listed__content"><p>We note that one could apply crossing cuts to an arbitrary <i>non polygonal</i> convex shape, but then the curved edges would serve as a major clue for reconstruction, a relief we preferred to avoid in this work.</p></div></li><li class="c-article-footnote--listed__item" id="Fn3" data-counter="3."><div class="c-article-footnote--listed__content"><p>Each number <i>f</i>(<i>n</i>) in the Lazy caterer’s sequence, also known as the central polygonal numbers, is the <i>maximal</i> number of cake pieces a caterer can obtain by cutting the cake (or more abstractly, a disk) exactly <i>n</i> cuts. To do so a caterer must be “lazy” since the cuts cannot all intersect the center of the disk, as is usually done while slicing cakes.</p></div></li><li class="c-article-footnote--listed__item" id="Fn4" data-counter="4."><div class="c-article-footnote--listed__content"><p>In some sense, the caterer in our case is even “lazier” than the “lazy caterer”, as she does not need to take measures to choose her cuts to maximize the number of pieces.</p></div></li><li class="c-article-footnote--listed__item" id="Fn5" data-counter="5."><div class="c-article-footnote--listed__content"><p>To avoid terminological confusion, we use the term ’links’ for the edges of the mating graph, while we reserve the term ’edges’ for the boundary segments of puzzle pieces.</p></div></li><li class="c-article-footnote--listed__item" id="Fn6" data-counter="6."><div class="c-article-footnote--listed__content"><p>Recall that we reserved the term ’edges’ for the boundary segments of the puzzle pieces while the edges of the mating graph are termed ‘links’ to avoid confusion.</p></div></li></ol></div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ul class="c-article-references" data-track-component="outbound reference" data-track-context="references section"><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR1">Adluru, N., Yang, X., &amp; Latecki, L. J. (2015). Sequential monte carlo for maximum weight subgraphs with application to solving image jigsaw puzzles. <i>International Journal of Computer Vision,</i> <i>112</i>(3), 319–341.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s11263-014-0766-9" data-track-item_id="10.1007/s11263-014-0766-9" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s11263-014-0766-9" aria-label="Article reference 1" data-doi="10.1007/s11263-014-0766-9">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Sequential%20monte%20carlo%20for%20maximum%20weight%20subgraphs%20with%20application%20to%20solving%20image%20jigsaw%20puzzles&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1007%2Fs11263-014-0766-9&amp;volume=112&amp;issue=3&amp;pages=319-341&amp;publication_year=2015&amp;author=Adluru%2CN&amp;author=Yang%2CX&amp;author=Latecki%2CLJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR2">Alajlan, N. (2009). Solving square jigsaw puzzles using dynamic programming and the Hungarian procedure. <i>American Journal of Applied Sciences,</i> <i>6</i>(11), 1941.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3844/ajassp.2009.1941.1947" data-track-item_id="10.3844/ajassp.2009.1941.1947" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3844%2Fajassp.2009.1941.1947" aria-label="Article reference 2" data-doi="10.3844/ajassp.2009.1941.1947">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Solving%20square%20jigsaw%20puzzles%20using%20dynamic%20programming%20and%20the%20Hungarian%20procedure&amp;journal=American%20Journal%20of%20Applied%20Sciences&amp;doi=10.3844%2Fajassp.2009.1941.1947&amp;volume=6&amp;issue=11&amp;publication_year=2009&amp;author=Alajlan%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR3">Ali, F. A. B. H., &amp; Karim, F. B. (2014). Development of captcha system based on puzzle. In <i>2014 international conference on computer, communications, and control technology (I4CT)</i> (pp. 426–428). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR4">Andalo, F., Taubin, G., &amp; Goldenstein, S. (2016). PSQP: Puzzle solving by quadratic programming. <i>IEEE PAMI,</i> <i>39</i>(2), 385–396.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/TPAMI.2016.2547394" data-track-item_id="10.1109/TPAMI.2016.2547394" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FTPAMI.2016.2547394" aria-label="Article reference 4" data-doi="10.1109/TPAMI.2016.2547394">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=PSQP%3A%20Puzzle%20solving%20by%20quadratic%20programming&amp;journal=IEEE%20PAMI&amp;doi=10.1109%2FTPAMI.2016.2547394&amp;volume=39&amp;issue=2&amp;pages=385-396&amp;publication_year=2016&amp;author=Andalo%2CF&amp;author=Taubin%2CG&amp;author=Goldenstein%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR5">Andaló, F. A., Carneiro, G., Taubin, G., Goldenstein, S., &amp; Velho, L. (2016). <i>Automatic reconstruction of ancient Portuguese tile panels</i>. Graphics Appl: IEEE Comput.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR6">Benaroya, H., &amp; Han, S. Probability models in engineering and science.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR7">Brandão, S., &amp; Marques, M. (2016). Hot tiles: A heat diffusion based descriptor for automatic tile panel assembly. In <i>European conference on computer vision</i> (pp. 768–782). Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR8">Brown, B. J., Laken, L., Dutré, P., Gool, L., Rusinkiewicz, S., &amp; Weyrich, T. (2012). Tools for virtual reassembly of fresco fragments. <i>International Journal of Heritage in the Digital Era,</i> <i>1</i>, 313–329.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1260/2047-4970.1.2.313" data-track-item_id="10.1260/2047-4970.1.2.313" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1260%2F2047-4970.1.2.313" aria-label="Article reference 8" data-doi="10.1260/2047-4970.1.2.313">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Tools%20for%20virtual%20reassembly%20of%20fresco%20fragments&amp;journal=International%20Journal%20of%20Heritage%20in%20the%20Digital%20Era&amp;doi=10.1260%2F2047-4970.1.2.313&amp;volume=1&amp;pages=313-329&amp;publication_year=2012&amp;author=Brown%2CBJ&amp;author=Laken%2CL&amp;author=Dutr%C3%A9%2CP&amp;author=Gool%2CL&amp;author=Rusinkiewicz%2CS&amp;author=Weyrich%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR9">Bunke, H., &amp; Kaufmann, G. (1993). Jigsaw puzzle solving using approximate string matching and best-first search. In <i>International conference on computer analysis of images and patterns</i> (pp. 299–308). Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR10">Burdea, B., &amp; Wolfson, H. J. (1989). Solving jigsaw puzzles by a robot. <i>IEEE Transactions on Robotics and Automation,</i> <i>5</i>(6), 752–764.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/70.88097" data-track-item_id="10.1109/70.88097" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2F70.88097" aria-label="Article reference 10" data-doi="10.1109/70.88097">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Solving%20jigsaw%20puzzles%20by%20a%20robot&amp;journal=IEEE%20Transactions%20on%20Robotics%20and%20Automation&amp;doi=10.1109%2F70.88097&amp;volume=5&amp;issue=6&amp;pages=752-764&amp;publication_year=1989&amp;author=Burdea%2CB&amp;author=Wolfson%2CHJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR11">Castañeda, A., Brown, B. J., Rusinkiewicz, S., Funkhouser, T., &amp; Weyrich, T. (2011). Global consistency in the automatic assembly of fragmented artefacts. In <i>VAST</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR12">Catto, E. Box2d. <a href="https://github.com/erincatto/Box2D" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://github.com/erincatto/Box2D">https://github.com/erincatto/Box2D</a>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR13">Cho, T. S., Avidan, S., &amp; Freeman, W. T. (2010). A probabilistic image jigsaw puzzle solver. In <i>2010 IEEE computer society conference on computer vision and pattern recognition</i> (pp. 183–190). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR14">Chung, M. G., Fleck, M. M., &amp; Forsyth, D. A. (1998). Jigsaw puzzle solver using shape and color. In <i>ICSP’98. 1998 Fourth international conference on signal processing (Cat. No. 98TH8344)</i> (Vol. 2, pp. 877–880). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR15">De Bock, J., De Smet, R., Philips, W., &amp; D’Haeyer, J. (2004). Constructing the topological solution of jigsaw puzzles. In <i>2004 International conference on image processing, 2004. ICIP’04.</i> (Vol. 3, pp. 2127–2130). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR16">Demaine, E. D., &amp; Demaine, M. L. (2007). Jigsaw puzzles, edge matching, and polyomino packing: Connections and complexity. <i>Graphs and Combinatorics,</i> <i>23</i>(1), 195–208.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s00373-007-0713-4" data-track-item_id="10.1007/s00373-007-0713-4" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s00373-007-0713-4" aria-label="Article reference 16" data-doi="10.1007/s00373-007-0713-4">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="mathscinet reference" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2320628" aria-label="MathSciNet reference 16">MathSciNet</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Jigsaw%20puzzles%2C%20edge%20matching%2C%20and%20polyomino%20packing%3A%20Connections%20and%20complexity&amp;journal=Graphs%20and%20Combinatorics&amp;doi=10.1007%2Fs00373-007-0713-4&amp;volume=23&amp;issue=1&amp;pages=195-208&amp;publication_year=2007&amp;author=Demaine%2CED&amp;author=Demaine%2CML">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR17">Derech, N., Tal, A., &amp; Shimshoni, I. (2021). Solving archaeological puzzles. <i>Pattern Recognition</i>, 108065.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR18">Dice, L. R. (1945). Measures of the amount of ecologic association between species. <i>Ecology,</i> <i>26</i>(3), 297–302.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.2307/1932409" data-track-item_id="10.2307/1932409" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.2307%2F1932409" aria-label="Article reference 18" data-doi="10.2307/1932409">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Measures%20of%20the%20amount%20of%20ecologic%20association%20between%20species&amp;journal=Ecology&amp;doi=10.2307%2F1932409&amp;volume=26&amp;issue=3&amp;pages=297-302&amp;publication_year=1945&amp;author=Dice%2CLR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR19">Fei, N., Zhuang, F., Renqiang, L., Qixin, C., &amp; Yanzheng, Z. (2007). An image processing approach for jigsaw puzzle assembly. <i>Assembly Automation,</i> <i>27</i>(1), 25–30.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1108/01445150710724676" data-track-item_id="10.1108/01445150710724676" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1108%2F01445150710724676" aria-label="Article reference 19" data-doi="10.1108/01445150710724676">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20image%20processing%20approach%20for%20jigsaw%20puzzle%20assembly&amp;journal=Assembly%20Automation&amp;doi=10.1108%2F01445150710724676&amp;volume=27&amp;issue=1&amp;pages=25-30&amp;publication_year=2007&amp;author=Fei%2CN&amp;author=Zhuang%2CF&amp;author=Renqiang%2CL&amp;author=Qixin%2CC&amp;author=Yanzheng%2CZ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR20">Freeman, H., &amp; Garder, L. (1964). Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition. <i>IEEE Transactions on Electronic Computers,</i> <i>2</i>, 118–127.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/PGEC.1964.263781" data-track-item_id="10.1109/PGEC.1964.263781" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FPGEC.1964.263781" aria-label="Article reference 20" data-doi="10.1109/PGEC.1964.263781">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Apictorial%20jigsaw%20puzzles%3A%20The%20computer%20solution%20of%20a%20problem%20in%20pattern%20recognition&amp;journal=IEEE%20Transactions%20on%20Electronic%20Computers&amp;doi=10.1109%2FPGEC.1964.263781&amp;volume=2&amp;pages=118-127&amp;publication_year=1964&amp;author=Freeman%2CH&amp;author=Garder%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR21">Funkhouser, T., Shin, H., Toler-Franklin, C., Castañeda, A., Brown, B. J., Dobkin, D., Rusinkiewicz, S., &amp; Weyrich, T. (2011). Learning how to match fresco fragments. <i>ACM Journal on Computing and Cultural Heritage,</i> <i>4</i>, 7:1-7:13.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20how%20to%20match%20fresco%20fragments&amp;journal=ACM%20Journal%20on%20Computing%20and%20Cultural%20Heritage&amp;volume=4&amp;pages=7%3A1-7%3A13&amp;publication_year=2011&amp;author=Funkhouser%2CT&amp;author=Shin%2CH&amp;author=Toler-Franklin%2CC&amp;author=Casta%C3%B1eda%2CA&amp;author=Brown%2CBJ&amp;author=Dobkin%2CD&amp;author=Rusinkiewicz%2CS&amp;author=Weyrich%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR22">Gallagher, A. C. (2012). Jigsaw puzzles with pieces of unknown orientation. In <i>2012 IEEE conference on computer vision and pattern recognition</i> (pp. 382–389). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR23">Gao, H., Yao, D., Liu, H., Liu, X., &amp; Wang, L. (2010). A novel image based captcha using jigsaw puzzle. In <i>2010 13th IEEE international conference on computational science and engineering</i> (pp. 351–356). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR24">Gassner, N., Baase, W., &amp; Matthews, B. (1996). A test of the “jigsaw puzzle’’ model for protein folding by multiple methionine substitutions within the core of t4 lysozyme. <i>Proceedings of the National Academy of Sciences,</i> <i>93</i>(22), 12155–12158.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1073/pnas.93.22.12155" data-track-item_id="10.1073/pnas.93.22.12155" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.93.22.12155" aria-label="Article reference 24" data-doi="10.1073/pnas.93.22.12155">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20test%20of%20the%20%E2%80%9Cjigsaw%20puzzle%E2%80%9D%20model%20for%20protein%20folding%20by%20multiple%20methionine%20substitutions%20within%20the%20core%20of%20t4%20lysozyme&amp;journal=Proceedings%20of%20the%20National%20Academy%20of%20Sciences&amp;doi=10.1073%2Fpnas.93.22.12155&amp;volume=93&amp;issue=22&amp;pages=12155-12158&amp;publication_year=1996&amp;author=Gassner%2CN&amp;author=Baase%2CW&amp;author=Matthews%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR25">Gioe, D. (2017). ‘The more things change’: HUMINT in the cyber age. In <i>The Palgrave handbook of security, risk and intelligence</i> (pp. 213–227). Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR26">Goldberg, D., Malon, C., &amp; Bern, M. (2002). A global approach to automatic solution of jigsaw puzzles. In <i>Proceedings of the eighteenth annual symposium on Computational geometry</i> (pp. 82–87). ACM.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR27">Grosman, L. (2016). Reaching the point of no return: The computational revolution in archaeology. <i>Annual Review of Anthropology,</i> <i>45</i>, 129–145.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1146/annurev-anthro-102215-095946" data-track-item_id="10.1146/annurev-anthro-102215-095946" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-anthro-102215-095946" aria-label="Article reference 27" data-doi="10.1146/annurev-anthro-102215-095946">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Reaching%20the%20point%20of%20no%20return%3A%20The%20computational%20revolution%20in%20archaeology&amp;journal=Annual%20Review%20of%20Anthropology&amp;doi=10.1146%2Fannurev-anthro-102215-095946&amp;volume=45&amp;pages=129-145&amp;publication_year=2016&amp;author=Grosman%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR28">Gur, S., &amp; Ben-Shahar, O. (2017). From square pieces to brick walls: The next challenge in solving jigsaw puzzles. In <i>Proceedings of the IEEE international conference on computer vision</i> (pp. 4029–4037).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR29">Huang, Q., Flöry, S., Gelfand, N., Hofer, M., &amp; Pottmann, H. (2006). Reassembling fractured objects by geometric matching. <i>ACM Transaction Graph.,</i> <i>25</i>, 569–578.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1145/1141911.1141925" data-track-item_id="10.1145/1141911.1141925" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1145%2F1141911.1141925" aria-label="Article reference 29" data-doi="10.1145/1141911.1141925">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Reassembling%20fractured%20objects%20by%20geometric%20matching&amp;journal=ACM%20Transaction%20Graph.&amp;doi=10.1145%2F1141911.1141925&amp;volume=25&amp;pages=569-578&amp;publication_year=2006&amp;author=Huang%2CQ&amp;author=Fl%C3%B6ry%2CS&amp;author=Gelfand%2CN&amp;author=Hofer%2CM&amp;author=Pottmann%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR30">Jiang, X., &amp; Bunke, H. (1993). An optimal algorithm for extracting the regions of a plane graph. <i>Pattern Recognition Letters,</i> <i>14</i>(7), 553–558.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/0167-8655(93)90104-L" data-track-item_id="10.1016/0167-8655(93)90104-L" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2F0167-8655%2893%2990104-L" aria-label="Article reference 30" data-doi="10.1016/0167-8655(93)90104-L">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20optimal%20algorithm%20for%20extracting%20the%20regions%20of%20a%20plane%20graph&amp;journal=Pattern%20Recognition%20Letters&amp;doi=10.1016%2F0167-8655%2893%2990104-L&amp;volume=14&amp;issue=7&amp;pages=553-558&amp;publication_year=1993&amp;author=Jiang%2CX&amp;author=Bunke%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR31">Kleber, F., &amp; Sablatnig, R (2009). Scientific puzzle solving: Current techniques and applications. In <i>CAA</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR32">Kleber, F., &amp; Sablatnig, R. (2009). A survey of techniques for document and archaeology artefact reconstruction. In <i>ICDAR</i> (pp. 1061–1065).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR33">Koller, D., &amp; Levoy, M. (2006). Computer-aided reconstruction and new matches in the forma urbis romae. <i>Bullettino Della Commissione Archeologica Comunale di Roma,</i> <i>2</i>, 103–125.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer-aided%20reconstruction%20and%20new%20matches%20in%20the%20forma%20urbis%20romae&amp;journal=Bullettino%20Della%20Commissione%20Archeologica%20Comunale%20di%20Roma&amp;volume=2&amp;pages=103-125&amp;publication_year=2006&amp;author=Koller%2CD&amp;author=Levoy%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR34">Kong, W., &amp; Kimia, B. B. (2001). On solving 2d and 3d puzzles using curve matching. In <i>Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001</i> (Vol. 2, pp. II–II). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR35">Kosiba, D. A., Devaux, P. M., Balasubramanian, S., Gandhi, T. L., &amp; Kasturi, K. (1994). An automatic jigsaw puzzle solver. In <i>Proceedings of 12th international conference on pattern recognition</i>, (Vol. 1, pp. 616–618). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR36">Le, C., &amp; Li, X. (2019). Jigsawnet: Shredded image reassembly using convolutional neural network and loop-based composition. <i>IEEE Transactions on Image Processing</i> .</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR37">Li, Q., Geng, G., &amp; Zhou, M. (2020). Pairwise matching for 3d fragment reassembly based on boundary curves and concave-convex patches. <i>IEEE Access,</i> <i>8</i>, 6153–6161.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/ACCESS.2019.2961391" data-track-item_id="10.1109/ACCESS.2019.2961391" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FACCESS.2019.2961391" aria-label="Article reference 37" data-doi="10.1109/ACCESS.2019.2961391">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Pairwise%20matching%20for%203d%20fragment%20reassembly%20based%20on%20boundary%20curves%20and%20concave-convex%20patches&amp;journal=IEEE%20Access&amp;doi=10.1109%2FACCESS.2019.2961391&amp;volume=8&amp;pages=6153-6161&amp;publication_year=2020&amp;author=Li%2CQ&amp;author=Geng%2CG&amp;author=Zhou%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR38">Lindström, M. (2019). The geological development of the arctic. In <i>The Arctic</i> (pp. 3–25). Routledge.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR39">Liu, H., Cao, S., &amp; Yan, S. (2011). Automated assembly of shredded pieces from multiple photos. <i>IEEE Transactions on Multimedia,</i> <i>13</i>(5), 1154–1162.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/TMM.2011.2160845" data-track-item_id="10.1109/TMM.2011.2160845" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FTMM.2011.2160845" aria-label="Article reference 39" data-doi="10.1109/TMM.2011.2160845">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Automated%20assembly%20of%20shredded%20pieces%20from%20multiple%20photos&amp;journal=IEEE%20Transactions%20on%20Multimedia&amp;doi=10.1109%2FTMM.2011.2160845&amp;volume=13&amp;issue=5&amp;pages=1154-1162&amp;publication_year=2011&amp;author=Liu%2CH&amp;author=Cao%2CS&amp;author=Yan%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR40">Makridis, M., &amp; Papamarkos, N. (2006). A new technique for solving a jigsaw puzzle. In <i>2006 international conference on image processing</i> (pp. 2001–2004). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR41">Marande, W., &amp; Burger, G. (2007). Mitochondrial dna as a genomic jigsaw puzzle. <i>Science,</i> <i>318</i>(5849), 415–415.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1126/science.1148033" data-track-item_id="10.1126/science.1148033" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1148033" aria-label="Article reference 41" data-doi="10.1126/science.1148033">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Mitochondrial%20dna%20as%20a%20genomic%20jigsaw%20puzzle&amp;journal=Science&amp;doi=10.1126%2Fscience.1148033&amp;volume=318&amp;issue=5849&amp;pages=415-415&amp;publication_year=2007&amp;author=Marande%2CW&amp;author=Burger%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR42">Markaki, S., &amp; Panagiotakis, C. (2023). Jigsaw puzzle solving techniques and applications: A survey. <i>The Visual Computer,</i> <i>39</i>(10), 4405–4421.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s00371-022-02598-9" data-track-item_id="10.1007/s00371-022-02598-9" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s00371-022-02598-9" aria-label="Article reference 42" data-doi="10.1007/s00371-022-02598-9">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Jigsaw%20puzzle%20solving%20techniques%20and%20applications%3A%20A%20survey&amp;journal=The%20Visual%20Computer&amp;doi=10.1007%2Fs00371-022-02598-9&amp;volume=39&amp;issue=10&amp;pages=4405-4421&amp;publication_year=2023&amp;author=Markaki%2CS&amp;author=Panagiotakis%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR43">Mavridis, P., Andreadis, A., &amp; Papaioannou, G. (2015). Fractured object reassembly via robust surface registration. In <i>Eurographics</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR44">Mellado, N., Reuter, P., &amp; Schlick, C. (2010). Semi-automatic geometry-driven reassembly of fractured archeological objects. In <i>VAST</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR45">Mondal, D., Wang, Y., &amp; Durocher, S. (2013). Robust solvers for square jigsaw puzzles. In <i>2013 international conference on computer and robot vision</i>(pp. 249–256). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR46">Moore, T. L. (1991). Using euler’s formula to solve plane separation problems. <i>The College Mathematics Journal,</i> <i>22</i>(2), 125–130.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/07468342.1991.11973368" data-track-item_id="10.1080/07468342.1991.11973368" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F07468342.1991.11973368" aria-label="Article reference 46" data-doi="10.1080/07468342.1991.11973368">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20euler%E2%80%99s%20formula%20to%20solve%20plane%20separation%20problems&amp;journal=The%20College%20Mathematics%20Journal&amp;doi=10.1080%2F07468342.1991.11973368&amp;volume=22&amp;issue=2&amp;pages=125-130&amp;publication_year=1991&amp;author=Moore%2CTL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR47">Murakami, T., Toyama, F., Shoji, K., &amp; Miyamichi, J. (2008). Assembly of puzzles by connecting between blocks. In <i>2008 19th international conference on pattern recognition</i> (pp. 1–4). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR48">Nielsen, T. R., Drewsen, P., &amp; Hansen, K. (2008). Solving jigsaw puzzles using image features. <i>Pattern Recognition Letters,</i> <i>29</i>(14), 1924–1933.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.patrec.2008.05.027" data-track-item_id="10.1016/j.patrec.2008.05.027" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.patrec.2008.05.027" aria-label="Article reference 48" data-doi="10.1016/j.patrec.2008.05.027">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Solving%20jigsaw%20puzzles%20using%20image%20features&amp;journal=Pattern%20Recognition%20Letters&amp;doi=10.1016%2Fj.patrec.2008.05.027&amp;volume=29&amp;issue=14&amp;pages=1924-1933&amp;publication_year=2008&amp;author=Nielsen%2CTR&amp;author=Drewsen%2CP&amp;author=Hansen%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR49">Oxholm, G., &amp; Nishino, K. (2011). Reassembling thin artifacts of unknown geometry. In <i>VAST</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR50">Paikin, G., &amp; Tal, A. (2015). Solving multiple square jigsaw puzzles with missing pieces. In <i>Proceedings of the IEEE conference on computer vision and pattern recognition</i> (pp. 4832–4839).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR51">Palmas, G., Pietroni, N., Cignoni, P., &amp; Scopigno, R. (2013). A computer-assisted constraint-based system for assembling fragmented objects. <i>2013 Digital Heritage International Congress (DigitalHeritage),</i> <i>1</i>, 529–536.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/DigitalHeritage.2013.6743793" data-track-item_id="10.1109/DigitalHeritage.2013.6743793" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FDigitalHeritage.2013.6743793" aria-label="Article reference 51" data-doi="10.1109/DigitalHeritage.2013.6743793">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20computer-assisted%20constraint-based%20system%20for%20assembling%20fragmented%20objects&amp;journal=2013%20Digital%20Heritage%20International%20Congress%20%28DigitalHeritage%29&amp;doi=10.1109%2FDigitalHeritage.2013.6743793&amp;volume=1&amp;pages=529-536&amp;publication_year=2013&amp;author=Palmas%2CG&amp;author=Pietroni%2CN&amp;author=Cignoni%2CP&amp;author=Scopigno%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR52">Papaioannou, G., &amp; Karabassi, E.-A. (2003). On the automatic assemblage of arbitrary broken solid artefacts. <i>Image and Vision Computing,</i> <i>21</i>, 401–412.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/S0262-8856(03)00008-8" data-track-item_id="10.1016/S0262-8856(03)00008-8" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2FS0262-8856%2803%2900008-8" aria-label="Article reference 52" data-doi="10.1016/S0262-8856(03)00008-8">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20automatic%20assemblage%20of%20arbitrary%20broken%20solid%20artefacts&amp;journal=Image%20and%20Vision%20Computing&amp;doi=10.1016%2FS0262-8856%2803%2900008-8&amp;volume=21&amp;pages=401-412&amp;publication_year=2003&amp;author=Papaioannou%2CG&amp;author=Karabassi%2CE-A">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR53">Papaioannou, G., Karabassi, E.-A., &amp; Theoharis, T. (2001). Virtual archaeologist: Assembling the past. <i>IEEE Computer Graphics and Applications,</i> <i>21</i>, 53–59.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/38.909015" data-track-item_id="10.1109/38.909015" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2F38.909015" aria-label="Article reference 53" data-doi="10.1109/38.909015">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=Virtual%20archaeologist%3A%20Assembling%20the%20past&amp;journal=IEEE%20Computer%20Graphics%20and%20Applications&amp;doi=10.1109%2F38.909015&amp;volume=21&amp;pages=53-59&amp;publication_year=2001&amp;author=Papaioannou%2CG&amp;author=Karabassi%2CE-A&amp;author=Theoharis%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR54">Papaodysseus, C., Panagopoulos, T., Exarhos, M., Triantafillou, C., Fragoulis, D., &amp; Doumas, C. (2002). Contour-shape based reconstruction of fragmented, 1600 bc wall paintings. <i>IEEE Transactions on Signal Processing,</i> <i>50</i>, 1277–1288.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/TSP.2002.1003053" data-track-item_id="10.1109/TSP.2002.1003053" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FTSP.2002.1003053" aria-label="Article reference 54" data-doi="10.1109/TSP.2002.1003053">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=Contour-shape%20based%20reconstruction%20of%20fragmented%2C%201600%20bc%20wall%20paintings&amp;journal=IEEE%20Transactions%20on%20Signal%20Processing&amp;doi=10.1109%2FTSP.2002.1003053&amp;volume=50&amp;pages=1277-1288&amp;publication_year=2002&amp;author=Papaodysseus%2CC&amp;author=Panagopoulos%2CT&amp;author=Exarhos%2CM&amp;author=Triantafillou%2CC&amp;author=Fragoulis%2CD&amp;author=Doumas%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR55">Paumard, M.-M., Picard, D., &amp; Tabia, H. (2020). Deepzzle: Solving visual jigsaw puzzles with deep learning and shortest path optimization. <i>IEEE Transactions on Image Processing,</i> <i>29</i>, 3569–3581.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/TIP.2019.2963378" data-track-item_id="10.1109/TIP.2019.2963378" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FTIP.2019.2963378" aria-label="Article reference 55" data-doi="10.1109/TIP.2019.2963378">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=Deepzzle%3A%20Solving%20visual%20jigsaw%20puzzles%20with%20deep%20learning%20and%20shortest%20path%20optimization&amp;journal=IEEE%20Transactions%20on%20Image%20Processing&amp;doi=10.1109%2FTIP.2019.2963378&amp;volume=29&amp;pages=3569-3581&amp;publication_year=2020&amp;author=Paumard%2CM-M&amp;author=Picard%2CD&amp;author=Tabia%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR56">Pintus, R., Pal, K., Yang, Y., Weyrich, T., Gobbetti, E., &amp; Rushmeier, H. E. (2014) Geometric analysis in cultural heritage. In <i>GCH</i>, pp. 117–133.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR57">Pomeranz, D., Shemesh, M., &amp; Ben-Shahar, O. (2011). A fully automated greedy square jigsaw puzzle solver. In <i>CVPR 2011</i>, (pp. 9–16). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR58">Radack, G. M., &amp; Badler, N. I. (1982). Jigsaw puzzle matching using a boundary-centered polar encoding. <i>Computer Graphics and Image Processing,</i> <i>19</i>(1), 1–17.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/0146-664X(82)90111-3" data-track-item_id="10.1016/0146-664X(82)90111-3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2F0146-664X%2882%2990111-3" aria-label="Article reference 58" data-doi="10.1016/0146-664X(82)90111-3">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=Jigsaw%20puzzle%20matching%20using%20a%20boundary-centered%20polar%20encoding&amp;journal=Computer%20Graphics%20and%20Image%20Processing&amp;doi=10.1016%2F0146-664X%2882%2990111-3&amp;volume=19&amp;issue=1&amp;pages=1-17&amp;publication_year=1982&amp;author=Radack%2CGM&amp;author=Badler%2CNI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR59">Rika, D., Sholomon, D., David, E. O., &amp; Netanyahu, N. S. (2019). A novel hybrid scheme using genetic algorithms and deep learning for the reconstruction of portuguese tile panels. In <i>Proceedings of the genetic and evolutionary computation conference</i>, (pp. 1319–1327). ACM.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR60">Rombach, R., Blattmann, A., Lorenz, D., Esser, P., &amp; Ommer, B. (June 2022). High-resolution image synthesis with latent diffusion models. In <i>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</i> (pp. 10684–10695).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR61">Sağıroğlu, M. Ş, &amp; Erçil, A. (2010). Optimization for automated assembly of puzzles. <i>Top,</i> <i>18</i>(2), 321–338.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s11750-010-0156-6" data-track-item_id="10.1007/s11750-010-0156-6" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s11750-010-0156-6" aria-label="Article reference 61" data-doi="10.1007/s11750-010-0156-6">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="mathscinet reference" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2748605" aria-label="MathSciNet reference 61">MathSciNet</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 61" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimization%20for%20automated%20assembly%20of%20puzzles&amp;journal=Top&amp;doi=10.1007%2Fs11750-010-0156-6&amp;volume=18&amp;issue=2&amp;pages=321-338&amp;publication_year=2010&amp;author=Sa%C4%9F%C4%B1ro%C4%9Flu%2CM%C5%9E&amp;author=Er%C3%A7il%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR62">Shin, H., Doumas, C., Funkhouser, T., Rusinkiewicz, S., Steiglitz, K., Vlachopoulos, A., &amp; Weyrich, T. (2012). Analyzing and simulating fracture patterns of theran wall paintings. <i>Journal on Computing and Cultural Heritage (JOCCH),</i> <i>5</i>(3), 10.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=Analyzing%20and%20simulating%20fracture%20patterns%20of%20theran%20wall%20paintings&amp;journal=Journal%20on%20Computing%20and%20Cultural%20Heritage%20%28JOCCH%29&amp;volume=5&amp;issue=3&amp;publication_year=2012&amp;author=Shin%2CH&amp;author=Doumas%2CC&amp;author=Funkhouser%2CT&amp;author=Rusinkiewicz%2CS&amp;author=Steiglitz%2CK&amp;author=Vlachopoulos%2CA&amp;author=Weyrich%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR63">Sholomon, D., David, O., &amp; Netanyahu, N. S. (2013). A genetic algorithm-based solver for very large jigsaw puzzles. In <i>Proceedings of the IEEE conference on computer vision and pattern recognition</i> (pp. 1767–1774).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR64">Sholomon, D., David, O. E., &amp; Netanyahu, N. S. (2014). A generalized genetic algorithm-based solver for very large jigsaw puzzles of complex types. In <i>Twenty-eighth AAAI conference on artificial intelligence</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR65">Sizikova, E., &amp; Funkhouser, T. A. (2016). Wall painting reconstruction using a genetic algorithm. <i>Journal on Computing and Cultural Heritage (JOCCH),</i> <i>11</i>, 1–17.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=Wall%20painting%20reconstruction%20using%20a%20genetic%20algorithm&amp;journal=Journal%20on%20Computing%20and%20Cultural%20Heritage%20%28JOCCH%29&amp;volume=11&amp;pages=1-17&amp;publication_year=2016&amp;author=Sizikova%2CE&amp;author=Funkhouser%2CTA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR66">Son, K., Hays, J., &amp; Cooper, D. B. (2014). Solving square jigsaw puzzles with loop constraints. In <i>European conference on computer vision</i>, (pp. 32–46). Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR67">Son, K., Hays, J., &amp; Cooper, D. B. (2018). Solving square jigsaw puzzle by hierarchical loop constraints. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR68">Son, K., Hays, J., Cooper, &amp; D. B., et al. (2016). Solving small-piece jigsaw puzzles by growing consensus. In <i>Proceedings of the IEEE conference on computer vision and pattern recognition</i> (pp. 1193–1201).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR69">Song, X., Yang, X., Ren, J., Bai, R., &amp; Jiang, X. (2023). Solving jigsaw puzzle of large eroded gaps using puzzlet discriminant network. In <i>ICASSP 2023 - 2023 IEEE international conference on acoustics, speech and signal processing (ICASSP)</i> (pp. 1–5).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR70">Sorkine-Hornung, O., &amp; Rabinovich, M. (2017). Least-squares rigid motion using svd. <i>Computing,</i> <i>1</i>, 1.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 70" href="http://scholar.google.com/scholar_lookup?&amp;title=Least-squares%20rigid%20motion%20using%20svd&amp;journal=Computing&amp;volume=1&amp;publication_year=2017&amp;author=Sorkine-Hornung%2CO&amp;author=Rabinovich%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR71">Telea, A. (01 2004). An image inpainting technique based on the fast marching method. <i>Journal of Graphics Tools</i> <i>9</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR72">Toler-Franklin, C., Brown, B. J., Weyrich, T., Funkhouser, T., &amp; Rusinkiewicz, S. (2010). Multi-feature matching of fresco fragments. In <i>SIGGRAPH 2010</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR73">Toyama, F., Fujiki, Y., Shoji, K., &amp; Miyamichi, J. (2002). Assembly of puzzles using a genetic algorithm. In <i>Object recognition supported by user interaction for service robots</i> (Vol. 4, IEEE, pp. 389–392).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR74">Tsamoura, E., &amp; Pitas, I. (2009). Automatic color based reassembly of fragmented images and paintings. <i>IEEE Transactions on Image Processing,</i> <i>19</i>(3), 680–690.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/TIP.2009.2035840" data-track-item_id="10.1109/TIP.2009.2035840" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FTIP.2009.2035840" aria-label="Article reference 74" data-doi="10.1109/TIP.2009.2035840">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="mathscinet reference" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2750536" aria-label="MathSciNet reference 74">MathSciNet</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 74" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20color%20based%20reassembly%20of%20fragmented%20images%20and%20paintings&amp;journal=IEEE%20Transactions%20on%20Image%20Processing&amp;doi=10.1109%2FTIP.2009.2035840&amp;volume=19&amp;issue=3&amp;pages=680-690&amp;publication_year=2009&amp;author=Tsamoura%2CE&amp;author=Pitas%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR75">Warren, L., Quaglio, F., Riccomini, C., Simões, M., Poiré, D., Strikis, N., Anelli, L., &amp; Strikis, P. (2014). The puzzle assembled: Ediacaran guide fossil Cloudina reveals an old proto-Gondwana seaway. <i>Geology 42,</i> <i>5</i>, 391–394.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 75" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20puzzle%20assembled%3A%20Ediacaran%20guide%20fossil%20Cloudina%20reveals%20an%20old%20proto-Gondwana%20seaway&amp;journal=Geology%2042&amp;volume=5&amp;pages=391-394&amp;publication_year=2014&amp;author=Warren%2CL&amp;author=Quaglio%2CF&amp;author=Riccomini%2CC&amp;author=Sim%C3%B5es%2CM&amp;author=Poir%C3%A9%2CD&amp;author=Strikis%2CN&amp;author=Anelli%2CL&amp;author=Strikis%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR76">Webster, R. W., LaFollette, P. S., &amp; Stafford, R. L. (1991). Isthmus critical points for solving jigsaw puzzles in computer vision. <i>IEEE Transactions on Systems, Man, and Cybernetics,</i> <i>21</i>(5), 1271–1278.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR77">Wetzel, J. E. (1978). On the division of the plane by lines. <i>The American Mathematical Monthly,</i> <i>85</i>(8), 647–656.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR78">Willis, A., &amp; Cooper, D. (2008). Computational reconstruction of ancient artifacts. <i>IEEE Signal Processing Magazine</i>. <i>25</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR79">Wolfson, H., Schonberg, E., Kalvin, A., &amp; Lamdan, Y. (1988). Solving jigsaw puzzles by computer. <i>Annals of Operations Research,</i> <i>12</i>(1), 51–64.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/BF02186360" data-track-item_id="10.1007/BF02186360" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/BF02186360" aria-label="Article reference 79" data-doi="10.1007/BF02186360">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="mathscinet reference" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=948037" aria-label="MathSciNet reference 79">MathSciNet</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 79" href="http://scholar.google.com/scholar_lookup?&amp;title=Solving%20jigsaw%20puzzles%20by%20computer&amp;journal=Annals%20of%20Operations%20Research&amp;doi=10.1007%2FBF02186360&amp;volume=12&amp;issue=1&amp;pages=51-64&amp;publication_year=1988&amp;author=Wolfson%2CH&amp;author=Schonberg%2CE&amp;author=Kalvin%2CA&amp;author=Lamdan%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR80">Yaglom, A. M., &amp; Yaglom, I. M. (1987). <i>Challenging Mathematical Problems with Elementary Solutions</i>, vol. 1. Dover Publications.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR81">Yang, X., Adluru, N., &amp; Latecki, L. J. (2011). Particle filter with state permutations for solving image jigsaw puzzles. In <i>CVPR 2011</i>, (pp. 2873–2880). IEEE.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR82">Yao, F.-H., &amp; Shao, G.-F. (2003). A shape and image merging technique to solve jigsaw puzzles. <i>Pattern Recognition Letters,</i> <i>24</i>(12), 1819–1835.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/S0167-8655(03)00006-0" data-track-item_id="10.1016/S0167-8655(03)00006-0" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2FS0167-8655%2803%2900006-0" aria-label="Article reference 82" data-doi="10.1016/S0167-8655(03)00006-0">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 82" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20shape%20and%20image%20merging%20technique%20to%20solve%20jigsaw%20puzzles&amp;journal=Pattern%20Recognition%20Letters&amp;doi=10.1016%2FS0167-8655%2803%2900006-0&amp;volume=24&amp;issue=12&amp;pages=1819-1835&amp;publication_year=2003&amp;author=Yao%2CF-H&amp;author=Shao%2CG-F">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR83">Yu, R., Russell, C., &amp; Agapito, L. (2015). Solving jigsaw puzzles with linear programming. arXiv preprint <a href="http://arxiv.org/abs/1511.04472" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="http://arxiv.org/abs/1511.04472">arXiv:1511.04472</a>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR84">Ylmaz, S., &amp; Nabiyev, V. V. (2023). Comprehensive survey of the solving puzzle problems. <i>Computer Science Review,</i> <i>50</i>, 100586.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.cosrev.2023.100586" data-track-item_id="10.1016/j.cosrev.2023.100586" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cosrev.2023.100586" aria-label="Article reference 84" data-doi="10.1016/j.cosrev.2023.100586">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="mathscinet reference" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=4632659" aria-label="MathSciNet reference 84">MathSciNet</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 84" href="http://scholar.google.com/scholar_lookup?&amp;title=Comprehensive%20survey%20of%20the%20solving%20puzzle%20problems&amp;journal=Computer%20Science%20Review&amp;doi=10.1016%2Fj.cosrev.2023.100586&amp;volume=50&amp;publication_year=2023&amp;author=Ylmaz%2CS&amp;author=Nabiyev%2CVV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR85">Zhang, K., &amp; Li, X. (2014). A graph-based optimization algorithm for fragmented image reassembly. <i>Graphical Models,</i> <i>76</i>(5), 484–495.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.gmod.2014.03.001" data-track-item_id="10.1016/j.gmod.2014.03.001" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.gmod.2014.03.001" aria-label="Article reference 85" data-doi="10.1016/j.gmod.2014.03.001">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 85" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20graph-based%20optimization%20algorithm%20for%20fragmented%20image%20reassembly&amp;journal=Graphical%20Models&amp;doi=10.1016%2Fj.gmod.2014.03.001&amp;volume=76&amp;issue=5&amp;pages=484-495&amp;publication_year=2014&amp;author=Zhang%2CK&amp;author=Li%2CX">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR86">Zhao, F., He, X., Zhang, Y., Lei, W., Ma, W., Zhang, C., &amp; Song, H. (2020). A jigsaw puzzle inspired algorithm for solving large-scale no-wait flow shop scheduling problems. <i>Applied Intelligence,</i> <i>50</i>, 87–100.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s10489-019-01497-2" data-track-item_id="10.1007/s10489-019-01497-2" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s10489-019-01497-2" aria-label="Article reference 86" data-doi="10.1007/s10489-019-01497-2">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 86" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20jigsaw%20puzzle%20inspired%20algorithm%20for%20solving%20large-scale%20no-wait%20flow%20shop%20scheduling%20problems&amp;journal=Applied%20Intelligence&amp;doi=10.1007%2Fs10489-019-01497-2&amp;volume=50&amp;pages=87-100&amp;publication_year=2020&amp;author=Zhao%2CF&amp;author=He%2CX&amp;author=Zhang%2CY&amp;author=Lei%2CW&amp;author=Ma%2CW&amp;author=Zhang%2CC&amp;author=Song%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR87">Zhao, Y.-X., Su, M.-C., Chou, Z.-L., &amp; Lee, J. (2007). A puzzle solver and its application in speech descrambling. In <i>WSEAS international conference on computer engineering and applications</i> (pp. 171–176).</p></li></ul><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/s11263-024-02033-7?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>This work has been funded in part by the European Union’s Horizon 2020 research and innovation programme under grant agreement No 964854 (the RePAIR project). We also thank the Helmsley Charitable Trust through the ABC Robotics Initiative and the Frankel Fund of the Computer Science Department at Ben-Gurion University for their generous support.</p></div></div></section><section data-title="Funding"><div class="c-article-section" id="Fun-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Fun">Funding</h2><div class="c-article-section__content" id="Fun-content"><p>Open access funding provided by Ben-Gurion University.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel</p><p class="c-article-author-affiliation__authors-list">Peleg Harel, Ofir Itzhak Shahar &amp; Ohad Ben-Shahar</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Peleg-Harel-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Peleg Harel</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Peleg%20Harel" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">You can also search for this author in</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Peleg%20Harel" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Peleg%20Harel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Ofir_Itzhak-Shahar-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Ofir Itzhak Shahar</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Ofir%20Itzhak%20Shahar" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">You can also search for this author in</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ofir%20Itzhak%20Shahar" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ofir%20Itzhak%20Shahar%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Ohad-Ben_Shahar-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Ohad Ben-Shahar</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Ohad%20Ben-Shahar" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">You can also search for this author in</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ohad%20Ben-Shahar" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ohad%20Ben-Shahar%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:ben-shahar@cs.bgu.ac.il">Ohad Ben-Shahar</a>.</p></div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p>Communicated by Jiri Matas.</p><h3 class="c-article__sub-heading">Publisher's Note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section aria-labelledby="appendices"><div class="c-article-section" id="appendices-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="appendices">Appendix: Glossary</h2><div class="c-article-section__content" id="appendices-content"><h3 class="c-article__sub-heading u-visually-hidden" id="App1">Appendix: Glossary</h3><p>The following summarizes the different symbols and notations used in the paper, sorted alphabetically when applicable. </p><div class="c-article-table-container"><div class="c-article-table-border c-table-scroll-wrapper"><div class="c-table-scroll-wrapper__content" data-component-scroll-wrapper=""><table class="data last-table"><thead class="c-article-table-head"><tr><th class="u-text-left "><p>Symbol</p></th><th class="u-text-left "><p>Meaning</p></th></tr></thead><tbody><tr><td class="u-text-left "><p><i>a</i></p></td><td class="u-text-left "><p>Number of crossing cuts that generate a puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(A(p_i)\)</span></p></td><td class="u-text-left "><p>The spatial region of piece <span class="mathjax-tex">\(p_i\)</span> in its pose <span class="mathjax-tex">\((R_i,\vec {t\,}_i\)</span> in the puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(c_i\)</span></p></td><td class="u-text-left "><p>cut <i>i</i> that participated in generating the puzzle</p></td></tr><tr><td class="u-text-left "><p><i>Cuts</i></p></td><td class="u-text-left "><p>The set of cuts that generated a puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\({C}_1,\tilde{C}_1 \)</span></p></td><td class="u-text-left "><p>The mate length constraint under ideal and noisy conditions</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\({C}_2,\tilde{C}_2\)</span></p></td><td class="u-text-left "><p>The mate angle constraint under ideal and noisy conditions</p></td></tr><tr><td class="u-text-left "><p><i>D</i></p></td><td class="u-text-left "><p>puzzle diameter (distance between furthest vertices)</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\Delta \Theta _e(L, \varepsilon )\)</span></p></td><td class="u-text-left "><p>The bound of the orientation difference between <span class="mathjax-tex">\(\measuredangle \tilde{e}\)</span>and <span class="mathjax-tex">\(\measuredangle e\)</span>, i.e., between the orientation of the <span class="mathjax-tex">\(\varepsilon \)</span>-noisy edge and its original noiseless edge of length <i>L</i></p></td></tr><tr><td class="u-text-left "><p><i>E</i></p></td><td class="u-text-left "><p>The set of all piece edges of the puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(E_i\)</span></p></td><td class="u-text-left "><p>The set of edges of piece <i>i</i> of the puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(e_i^j\)</span></p></td><td class="u-text-left "><p>Edge <i>j</i> from <span class="mathjax-tex">\(\vec {v\,}_i^j\)</span> to <span class="mathjax-tex">\(\vec {v\,}_i^{j+1}\)</span> of piece <i>i</i> of the puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\mathcal {E}\)</span></p></td><td class="u-text-left "><p>The edges (line segments between nodes) of <span class="mathjax-tex">\(\mathcal {G}_{puzzle}\)</span></p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\varepsilon \)</span></p></td><td class="u-text-left "><p>Bound on geometric noise in absolute units</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\vec {\epsilon \,}_i^j\)</span></p></td><td class="u-text-left "><p>Perturbation vector of vertex <i>j</i> of piece <i>i</i> due to the geometric noise</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(G_M\)</span></p></td><td class="u-text-left "><p>The mating graph of the puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\mathcal {G}_{puzzle}\)</span></p></td><td class="u-text-left "><p>The planar graph that represents a synthesized crossing graph puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(L,\tilde{L}\)</span></p></td><td class="u-text-left "><p>The length of a clean and noisy edge, respectively</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\mathcal {L}\)</span></p></td><td class="u-text-left "><p>The bag of puzzle loops obeying the geometrical constraints</p></td></tr><tr><td class="u-text-left "><p><i>M</i></p></td><td class="u-text-left "><p>The set of all matings that constitute a mating graph <span class="mathjax-tex">\(G_M\)</span></p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(M_{loop}\)</span></p></td><td class="u-text-left "><p>The set of all matings in a hierarchical loop</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\tilde{M}\)</span></p></td><td class="u-text-left "><p>The set of all matings candidates that satisfy <span class="mathjax-tex">\(\tilde{C}_1, \tilde{C}_2\)</span></p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\tilde{M}_p\)</span></p></td><td class="u-text-left "><p>The set of all matings candidates that satisfy <span class="mathjax-tex">\(\tilde{C}_1, \tilde{C}_2\)</span> and ranked best pictorially</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(m_q\)</span></p></td><td class="u-text-left "><p>Mating <i>q</i> in a mating graph</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(N_i\)</span></p></td><td class="u-text-left "><p>Number of vertices (and edges) in piece <i>i</i> of the puzzle</p></td></tr><tr><td class="u-text-left "><p><i>P</i></p></td><td class="u-text-left "><p>The set of puzzle pieces</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(P_{loop}\)</span></p></td><td class="u-text-left "><p>The set of pieces of an <i>x</i>-loop</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(p_i\)</span></p></td><td class="u-text-left "><p>Piece <i>i</i> of the puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\tilde{p}_i\)</span></p></td><td class="u-text-left "><p><span class="mathjax-tex">\(\varepsilon \)</span>-noisy piece <i>i</i> of the puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(Q_{loop}\)</span></p></td><td class="u-text-left "><p>The quality score of a hierarchical loop</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(Q_{pos}\)</span></p></td><td class="u-text-left "><p>The normalized quality score (in [0, 1]) for piece positions in a puzzle solution</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(R_i\)</span></p></td><td class="u-text-left "><p>The rotation (matrix) applied to the vertices of piece <i>i</i></p></td></tr><tr><td class="u-text-left "><p><i>S</i>(<i>m</i>)</p></td><td class="u-text-left "><p>Pictorial compatibility score of mating <i>m</i></p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\vec {t\,}_i\)</span></p></td><td class="u-text-left "><p>The translation (vector) applied to the vertices of piece <i>i</i></p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(V_i\)</span></p></td><td class="u-text-left "><p>The set of vertices of pieces <i>i</i> of the puzzle</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\vec {v\,}_i^j\)</span></p></td><td class="u-text-left "><p>Vertex <i>j</i> of piece <i>i</i> of the puzzle, ordered clockwise</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\measuredangle \vec {v}\)</span></p></td><td class="u-text-left "><p>Angle of the vector <span class="mathjax-tex">\(\vec {v}\)</span></p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\mathcal {V}\)</span></p></td><td class="u-text-left "><p>The nodes (intersection points) of <span class="mathjax-tex">\(\mathcal {G}_{puzzle}\)</span></p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\xi \)</span></p></td><td class="u-text-left "><p>Bound of geometric noise relative to puzzle diameter</p></td></tr><tr><td class="u-text-left "><p><span class="mathjax-tex">\(\bar{\xi }\)</span></p></td><td class="u-text-left "><p>Bound of geometric noise relative to average (expected) edge length</p></td></tr></tbody></table></div></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Pictorial%20and%20Apictorial%20Polygonal%20Jigsaw%20Puzzles%20from%20Arbitrary%20Number%20of%20Crossing%20Cuts&amp;author=Peleg%20Harel%20et%20al&amp;contentID=10.1007%2Fs11263-024-02033-7&amp;copyright=The%20Author%28s%29&amp;publication=0920-5691&amp;publicationDate=2024-03-22&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s11263-024-02033-7" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s11263-024-02033-7" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Harel, P., Shahar, O.I. &amp; Ben-Shahar, O. Pictorial and Apictorial Polygonal Jigsaw Puzzles from Arbitrary Number of Crossing Cuts.
                    <i>Int J Comput Vis</i> <b>132</b>, 3428–3462 (2024). https://doi.org/10.1007/s11263-024-02033-7</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/s11263-024-02033-7?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-12-23">23 December 2021</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2024-02-11">11 February 2024</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2024-03-22">22 March 2024</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2024-09">September 2024</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1007/s11263-024-02033-7</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span><a href="/search?query=Computational%20jigsaw%20puzzle%20solving&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Computational jigsaw puzzle solving</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Lazy%20caterer&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Lazy caterer</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Crossing%20cuts&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Crossing cuts</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Pictorial%20and%20apictorial%20puzzles&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Pictorial and apictorial puzzles</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Loopy%20constraints&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Loopy constraints</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Hierarchical%20loops&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Hierarchical loops</a></span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>

                    

                    
                </div>
            </main>

            <div class="c-article-sidebar u-text-sm u-hide-print l-with-sidebar__sidebar" id="sidebar"
                 data-container-type="reading-companion" data-track-component="reading companion">
                <aside aria-label="reading companion">
                    
                        
    <div class="app-card-service" data-test="article-checklist-banner">
        <div>
            <a class="app-card-service__link" data-track="click_presubmission_checklist" data-track-context="article page top of reading companion" data-track-category="pre-submission-checklist" data-track-action="clicked article page checklist banner test 2 old version" data-track-label="link" href="https://beta.springernature.com/pre-submission?journalId=11263"
            data-test="article-checklist-banner-link">
            <span class="app-card-service__link-text">Use our pre-submission checklist</span>
            <svg class="app-card-service__link-icon" aria-hidden="true" focusable="false"><use xlink:href="#icon-eds-i-arrow-right-small"></use></svg>
            </a>
            <p class="app-card-service__description">Avoid common mistakes on your manuscript.</p>
        </div>
        <div class="app-card-service__icon-container">
            <svg class="app-card-service__icon" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-eds-i-clipboard-check-medium"></use>
            </svg>
        </div>
    </div>

                    

                    
                        <div data-test="collections">
                            
    

                        </div>
                    

                    <div data-test="editorial-summary">
                        
                    </div>

                    <div class="c-reading-companion">
                        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky"
                             data-test="reading-companion-sticky">
                            

                            
                                
                            

                            <div
                                class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active"
                                id="tabpanel-sections">
                                <div class="u-lazy-ad-wrapper u-mt-16 u-hide"
                                     data-component-mpu><div class="c-ad c-ad--300x250">
    <div class="c-ad__inner">
        <p class="c-ad__label">Advertisement</p>
        <div id="div-gpt-ad-MPU1"
             class="div-gpt-ad grade-c-hide"
             data-pa11y-ignore
             data-gpt
             data-gpt-unitpath="/270604982/springerlink/11263/article"
             data-gpt-sizes="300x250" data-test="MPU1-ad"
             data-gpt-targeting="pos=MPU1;articleid=s11263-024-02033-7;">
        </div>
    </div>
</div>

</div>
                            </div>
                            <div
                                class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width"
                                id="tabpanel-figures"></div>
                            <div
                                class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width"
                                id="tabpanel-references"></div>
                        </div>
                    </div>
                </aside>
            </div>
        </div>
    </article>
    <div class="app-elements">
    <nav aria-label="expander navigation">



    
        <div class="eds-c-header__expander eds-c-header__expander--search" id="eds-c-header-popup-search">
            <h2 class="eds-c-header__heading">Search</h2>
            <div class="u-container">
                <search class="eds-c-header__search" role="search" aria-label="Search from the header">
                    <form method="GET" action="//link.springer.com/search"
                        
                            data-test="header-search"
                        
                            data-track="search"
                        
                            data-track-context="search from header"
                        
                            data-track-action="submit search form"
                        
                            data-track-category="unified header"
                        
                            data-track-label="form"
                        
					>
                        <label for="eds-c-header-search" class="eds-c-header__search-label">Search by keyword or author</label>
                        <div class="eds-c-header__search-container">
                            <input id="eds-c-header-search" class="eds-c-header__search-input" autocomplete="off" name="query" type="search" value="" required>
                            <button class="eds-c-header__search-button" type="submit">
                                <svg class="eds-c-header__icon" aria-hidden="true" focusable="false">
                                    <use xlink:href="#icon-eds-i-search-medium"></use>
                                </svg>
                                <span class="u-visually-hidden">Search</span>
                            </button>
                        </div>
                    </form>
                </search>
            </div>
        </div>
    


<div class="eds-c-header__expander eds-c-header__expander--menu" id="eds-c-header-nav">
    
        <h2 class="eds-c-header__heading">Navigation</h2>
        <ul class="eds-c-header__list">
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://link.springer.com/journals/"
                        
                            data-track="nav_find_a_journal"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click find a journal"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Find a journal
                    </a>
                </li>
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://www.springernature.com/gp/authors"
                        
                            data-track="nav_how_to_publish"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click publish with us link"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Publish with us
                    </a>
                </li>
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://link.springernature.com/home/"
                        
                            data-track="nav_track_your_research"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click track your research"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Track your research
                    </a>
                </li>
            
        </ul>
    
</div>
</nav>
    <footer >
	<div class="eds-c-footer"
		
	>
		
			
				<div class="eds-c-footer__container">
		<div class="eds-c-footer__grid eds-c-footer__group--separator">
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Discover content</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/journals/a/1" data-track="nav_journals_a_z" data-track-action="journals a-z" data-track-context="unified footer" data-track-label="link">Journals A-Z</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/books/a/1" data-track="nav_books_a_z" data-track-action="books a-z" data-track-context="unified footer" data-track-label="link">Books A-Z</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Publish with us</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/journals" data-track="nav_journal_finder" data-track-action="journal finder" data-track-context="unified footer" data-track-label="link">Journal finder</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/authors" data-track="nav_publish_your_research" data-track-action="publish your research" data-track-context="unified footer" data-track-label="link">Publish your research</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/open-research/about/the-fundamentals-of-open-access-and-open-research" data-track="nav_open_access_publishing" data-track-action="open access publishing" data-track-context="unified footer" data-track-label="link">Open access publishing</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Products and services</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/products" data-track="nav_our_products" data-track-action="our products" data-track-context="unified footer" data-track-label="link">Our products</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/librarians" data-track="nav_librarians" data-track-action="librarians" data-track-context="unified footer" data-track-label="link">Librarians</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/societies" data-track="nav_societies" data-track-action="societies" data-track-context="unified footer" data-track-label="link">Societies</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/partners" data-track="nav_partners_and_advertisers" data-track-action="partners and advertisers" data-track-context="unified footer" data-track-label="link">Partners and advertisers</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Our brands</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springer.com/" data-track="nav_imprint_Springer" data-track-action="Springer" data-track-context="unified footer" data-track-label="link">Springer</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.nature.com/" data-track="nav_imprint_Nature_Portfolio" data-track-action="Nature Portfolio" data-track-context="unified footer" data-track-label="link">Nature Portfolio</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.biomedcentral.com/" data-track="nav_imprint_BMC" data-track-action="BMC" data-track-context="unified footer" data-track-label="link">BMC</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.palgrave.com/" data-track="nav_imprint_Palgrave_Macmillan" data-track-action="Palgrave Macmillan" data-track-context="unified footer" data-track-label="link">Palgrave Macmillan</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.apress.com/" data-track="nav_imprint_Apress" data-track-action="Apress" data-track-context="unified footer" data-track-label="link">Apress</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/brands/discover" data-track="nav_imprint_Discover" data-track-action="Discover" data-track-context="unified footer" data-track-label="link">Discover</a></li>
					
				</ul>
			</div>
			
		</div>
	</div>

		
		
		<div class="eds-c-footer__container">
	
		<nav aria-label="footer navigation">
			<ul class="eds-c-footer__links">
				
					<li class="eds-c-footer__item">
						
						
							<button class="eds-c-footer__link" data-cc-action="preferences"
								 data-track="dialog_manage_cookies" data-track-action="Manage cookies" data-track-context="unified footer" data-track-label="link"><span class="eds-c-footer__button-text">Your privacy choices/Manage cookies</span></button>
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://www.springernature.com/gp/legal/ccpa"
								 data-track="nav_california_privacy_statement" data-track-action="california privacy statement" data-track-context="unified footer" data-track-label="link">Your US state privacy rights</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://www.springernature.com/gp/info/accessibility"
								 data-track="nav_accessibility_statement" data-track-action="accessibility statement" data-track-context="unified footer" data-track-label="link">Accessibility statement</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/termsandconditions"
								 data-track="nav_terms_and_conditions" data-track-action="terms and conditions" data-track-context="unified footer" data-track-label="link">Terms and conditions</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/privacystatement"
								 data-track="nav_privacy_policy" data-track-action="privacy policy" data-track-context="unified footer" data-track-label="link">Privacy policy</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://support.springernature.com/en/support/home"
								 data-track="nav_help_and_support" data-track-action="help and support" data-track-context="unified footer" data-track-label="link">Help and support</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/legal-notice"
								 data-track="nav_legal_notice" data-track-action="legal notice" data-track-context="unified footer" data-track-label="link">Legal notice</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://support.springernature.com/en/support/solutions/articles/6000255911-subscription-cancellations"
								 data-track-action="cancel contracts here">Cancel contracts here</a>
						
						
					</li>
				
			</ul>
		</nav>
	
	
		
			<div class="eds-c-footer__user">
				<p class="eds-c-footer__user-info">
					
					<span data-test="footer-user-ip">77.124.55.169</span>
				</p>
				<p class="eds-c-footer__user-info" data-test="footer-business-partners">Not affiliated</p>
			</div>
		
	
	
		<a href="https://www.springernature.com/" class="eds-c-footer__link">
			<img src="/oscar-static/images/logo-springernature-white-19dd4ba190.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
		</a>
	
	<p class="eds-c-footer__legal" data-test="copyright">&copy; 2025 Springer Nature</p>
</div>

	</div>
</footer>
</div>


    </body>
</html>


